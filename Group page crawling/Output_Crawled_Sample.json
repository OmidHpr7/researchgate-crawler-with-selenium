{
    "paper1": {
        "id": "317558625",
        "title": "Attention Is All You Need",
        "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
        "date": "2017",
        "authers": [
            "Ashish Vaswani",
            "Noam Shazeer",
            "Niki Parmar",
            "Jakob Uszkoreit"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305334466_Recurrent_Neural_Network_Grammars",
            "https://www.researchgate.net/publication/269416998_Empirical_Evaluation_of_Gated_Recurrent_Neural_Networks_on_Sequence_Modeling",
            "https://www.researchgate.net/publication/266376373_Fast_and_Accurate_Shift-Reduce_Constituent_Parsing",
            "https://www.researchgate.net/publication/265252627_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate",
            "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/221013135_Self-Training_PCFG_Grammars_with_Latent_Annotations_Across_Languages",
            "https://www.researchgate.net/publication/220873863_Learning_Accurate_Compact_and_Interpretable_Tree_Annotation",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.researchgate.net/publication/322584145_Massive_Exploration_of_Neural_Machine_Translation_Architectures"
        ]
    },
    "paper2": {
        "id": "286512696",
        "title": "Deep Residual Learning for Image Recognition",
        "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\nThe depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
        "date": "2015",
        "authers": [
            "Kaiming He",
            "Xiangyu Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/269935397_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/265908778_Deeply-Supervised_Nets",
            "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding",
            "https://www.researchgate.net/publication/260126867_On_the_Number_of_Linear_Regions_of_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/259440750_Exact_solutions_to_the_nonlinear_dynamics_of_learning_in_deep_linear_neural_networks",
            "https://www.researchgate.net/publication/234119846_Pushing_Stochastic_Gradient_towards_Second-Order_Methods_--_Backpropagation_Learning_with_Transformations_in_Nonlinearities"
        ]
    },
    "paper3": {
        "id": "333444574",
        "title": "EfficientNet Rethinking Model Scaling for Convolutional Neural Networks",
        "abstract": "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.",
        "date": "2019",
        "authers": [
            "Mingxing Tan",
            "Quoc V. Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/328110752_AMC_AutoML_for_Model_Compression_and_Acceleration_on_Mobile_Devices",
            "https://www.researchgate.net/publication/319622446_The_Expressive_Power_of_Neural_Networks_A_View_from_the_Width",
            "https://www.researchgate.net/publication/314282992_On_the_Expressive_Power_of_Overlapping_Architectures_of_Deep_Learning",
            "https://www.researchgate.net/publication/313641935_Sigmoid-Weighted_Linear_Units_for_Neural_Network_Function_Approximation_in_Reinforcement_Learning",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/348350592_ResNet_with_one-neuron_hidden_layers_is_a_Universal_Approximator",
            "https://www.researchgate.net/publication/329740202_Squeeze-and-Excitation_Networks",
            "https://www.researchgate.net/publication/329740172_ShuffleNet_An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices",
            "https://www.researchgate.net/publication/322950113_Regularized_Evolution_for_Image_Classifier_Architecture_Search",
            "https://www.researchgate.net/publication/320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions"
        ]
    },
    "paper4": {
        "id": "352015995",
        "title": "SegFormer Simple and Efficient Design for Semantic Segmentation with Transformers",
        "abstract": "We present SegFormer, a simple, efficient yet powerful semantic segmentation framework which unifies Transformers with lightweight multilayer perception (MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a novel hierarchically structured Transformer encoder which outputs multiscale features. It does not need positional encoding, thereby avoiding the interpolation of positional codes which leads to decreased performance when the testing resolution differs from training. 2) SegFormer avoids complex decoders. The proposed MLP decoder aggregates information from different layers, and thus combining both local attention and global attention to render powerful representations. We show that this simple and lightweight design is the key to efficient segmentation on Transformers. We scale our approach up to obtain a series of models from SegFormer-B0 to SegFormer-B5, reaching significantly better performance and efficiency than previous counterparts. For example, SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x smaller and 2.2% better than the previous best method. Our best model, SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows excellent zero-shot robustness on Cityscapes-C. Code will be released at: github.com/NVlabs/SegFormer.",
        "date": "2021",
        "authers": [
            "Enze Xie",
            "Wenhai Wang",
            "Zhiding Yu",
            "Anima Anandkumar"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/338503872_Fast_Neural_Architecture_Search_of_Compact_Semantic_Segmentation_Models_via_Auxiliary_Cells",
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/329442528_DenseASPP_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/347030093_Improving_Semantic_Segmentation_via_Decoupled_Body_and_Edge_Supervision",
            "https://www.researchgate.net/publication/346022004_End-to-End_Object_Detection_with_Transformers",
            "https://www.researchgate.net/publication/345324756_SegFix_Model-Agnostic_Boundary_Refinement_for_Segmentation",
            "https://www.researchgate.net/publication/343466461_Learning_Dynamic_Routing_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/343456450_Joint_Semantic_Segmentation_and_Boundary_Detection_Using_Iterative_Pyramid_Contexts"
        ]
    },
    "paper5": {
        "id": "354891122",
        "title": "PASS An ImageNet replacement for self-supervised pretraining without humans",
        "abstract": "Computer vision has long relied on ImageNet and other large datasets of images sampled from the Internet for pretraining models. However, these datasets have ethical and technical shortcomings, such as containing personal information taken without consent, unclear license usage, biases, and, in some cases, even problematic image content. On the other hand, state-of-the-art pretraining is nowadays obtained with unsupervised methods, meaning that labelled datasets such as ImageNet may not be necessary, or perhaps not even optimal, for model pretraining. We thus propose an unlabelled dataset PASS: Pictures without humAns for Self-Supervision. PASS only contains images with CC-BY license and complete attribution metadata, addressing the copyright issue. Most importantly, it contains no images of people at all, and also avoids other types of images that are problematic for data protection or ethics. We show that PASS can be used for pretraining with methods such as MoCo-v2, SwAV and DINO. In the transfer learning setting, it yields similar downstream performances to ImageNet pretraining even on tasks that involve humans, such as human pose estimation. PASS does not make existing datasets obsolete, as for instance it is insufficient for benchmarking. However, it shows that model pretraining is often possible while using safer data, and it also provides the basis for a more robust evaluation of pretraining methods.",
        "date": "2021",
        "authers": [
            "Yuki M. Asano",
            "Christian Rupprecht",
            "Andrew Zisserman",
            "Andrea Vedaldi"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/352224617_Excavating_AI_the_politics_of_images_in_machine_learning_training_sets",
            "https://www.researchgate.net/publication/343463185_PULSE_Self-Supervised_Photo_Upsampling_via_Latent_Space_Exploration_of_Generative_Models",
            "https://www.researchgate.net/publication/356869040_ObjectNet_A_large-scale_bias-controlled_dataset_for_pushing_the_limits_of_object_recognition_models",
            "https://www.researchgate.net/publication/355882923_Exploring_Simple_Siamese_Representation_Learning",
            "https://www.researchgate.net/publication/355882623_Propagate_Yourself_Exploring_Pixel-Level_Consistency_for_Unsupervised_Visual_Representation_Learning",
            "https://www.researchgate.net/publication/352398842_Large_image_datasets_A_pyrrhic_win_for_computer_vision",
            "https://www.researchgate.net/publication/347459139_Towards_fairer_datasets_filtering_and_balancing_the_distribution_of_the_people_subtree_in_the_ImageNet_hierarchy",
            "https://www.researchgate.net/publication/344753035_Between_Subjectivity_and_Imposition_Power_Dynamics_in_Data_Annotation_for_Computer_Vision",
            "https://www.researchgate.net/publication/343465745_Self-Supervised_Learning_of_Pretext-Invariant_Representations",
            "https://www.researchgate.net/publication/343461321_Learning_Representations_by_Predicting_Bags_of_Visual_Words"
        ]
    },
    "paper6": {
        "id": "328230984",
        "title": "BERT Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.",
        "date": "2018",
        "authers": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/334116365_Universal_Language_Model_Fine-tuning_for_Text_Classification",
            "https://www.researchgate.net/publication/304506026_Bridging_Nonlinearities_and_Stochastic_Regularizers_with_Gaussian_Error_Linear_Units",
            "https://www.researchgate.net/publication/304018244_SQuAD_100000_Questions_for_Machine_Comprehension_of_Text",
            "https://www.researchgate.net/publication/284576917_Glove_Global_Vectors_for_Word_Representation",
            "https://www.researchgate.net/publication/279068396_Skip-Thought_Vectors",
            "https://www.researchgate.net/publication/268079628_How_transferable_are_features_in_deep_neural_networks",
            "https://www.researchgate.net/publication/259239818_One_Billion_Word_Benchmark_for_Measuring_Progress_in_Statistical_Language_Modeling",
            "https://www.researchgate.net/publication/257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/221346269_Extracting_and_composing_robust_features_with_denoising_autoencoders"
        ]
    },
    "paper7": {
        "id": "344828174",
        "title": "An Image is Worth 16x16 Words Transformers for Image Recognition at Scale",
        "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",
        "date": "2020",
        "authers": [
            "Alexey Dosovitskiy",
            "Lucas Beyer",
            "Alexander Kolesnikov",
            "Dirk Weissenborn"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/343466387_Self-Training_With_Noisy_Student_Improves_ImageNet_Classification",
            "https://www.researchgate.net/publication/343466025_Exploring_Self-Attention_for_Image_Recognition",
            "https://www.researchgate.net/publication/343298597_Quantifying_Attention_Flow_in_Transformers",
            "https://www.researchgate.net/publication/339562815_Attention_Augmented_Convolutional_Networks",
            "https://www.researchgate.net/publication/339562468_S4L_Self-Supervised_Semi-Supervised_Learning"
        ]
    },
    "paper8": {
        "id": "305334466",
        "title": "Recurrent Neural Network Grammars",
        "abstract": "We introduce recurrent neural network grammars, probabilistic models of sentences with explicit phrase structure. We explain efficient inference procedures that allow application to both parsing and language modeling. Experiments show that they provide better parsing in English than any single previously published supervised generative model and better language modeling than state-of-the-art sequential RNNs in English and Chinese.",
        "date": "2016",
        "authers": [
            "Chris Dyer",
            "Adhiguna Kuncoro",
            "Miguel Ballesteros",
            "Noah A. Smith"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/306094026_A_Fast_Unified_Model_for_Parsing_and_Sentence_Understanding",
            "https://www.researchgate.net/publication/283865501_Feature_Optimization_for_Constituent_Parsing_via_Neural_Networks",
            "https://www.researchgate.net/publication/278965988_Transition-Based_Dependency_Parsing_with_Stack_Long_Short-Term_Memory",
            "https://www.researchgate.net/publication/319770403_A_Tutorial_on_Particle_Filtering_and_Smoothing_Fifteen_years_later",
            "https://www.researchgate.net/publication/301870716_Classes_for_Fast_Maximum_Entropy_Training",
            "https://www.researchgate.net/publication/301841091_Easy-First_Dependency_Parsing_with_Hierarchical_Tree_LSTMs",
            "https://www.researchgate.net/publication/286531327_Efficient_higher-order_CRFs_for_morphological_tagging",
            "https://www.researchgate.net/publication/284039049_Recursive_deep_models_for_semantic_compositionality_over_a_sentiment_treebank",
            "https://www.researchgate.net/publication/283806803_Generative_Incremental_Dependency_Parsing_with_Neural_Networks",
            "https://www.researchgate.net/publication/278413581_A_Bayesian_Model_for_Generative_Transition-based_Dependency_Parsing"
        ]
    },
    "paper9": {
        "id": "269416998",
        "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling",
        "abstract": "In this paper we compare different types of recurrent units in recurrent\nneural networks (RNNs). Especially, we focus on more sophisticated units that\nimplement a gating mechanism, such as a long short-term memory (LSTM) unit and\na recently proposed gated recurrent unit (GRU). We evaluate these recurrent\nunits on the tasks of polyphonic music modeling and speech signal modeling. Our\nexperiments revealed that these advanced recurrent units are indeed better than\nmore traditional recurrent units such as tanh units. Also, we found GRU to be\ncomparable to LSTM.",
        "date": "2014",
        "authers": [
            "Junyoung Chung",
            "Caglar Gulcehre",
            "KyungHyun Cho",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/265385879_On_the_Properties_of_Neural_Machine_Translation_Encoder-Decoder_Approaches",
            "https://www.researchgate.net/publication/265252627_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate",
            "https://www.researchgate.net/publication/255983764_Pylearn2_A_machine_learning_research_library",
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/279394722_Learned-Norm_Pooling_for_Deep_Feedforward_and_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/267706055_Practical_Variational_Inference_for_Neural_Networks",
            "https://www.researchgate.net/publication/265554383_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/262395872_Random_Search_for_Hyper-Parameter_Optimization",
            "https://www.researchgate.net/publication/258818168_Speech_Recognition_with_Deep_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/255173850_Generating_Sequences_With_Recurrent_Neural_Networks"
        ]
    },
    "paper10": {
        "id": "266376373",
        "title": "Fast and Accurate Shift-Reduce Constituent Parsing",
        "abstract": "Shift-reduce dependency parsers give comparable accuracies to their chart-based counterparts, yet the best shift-reduce constituent parsers still lag behind the state-of-the-art. One important reason is the existence of unary nodes in phrase structure trees, which leads to different numbers of shift-reduce actions between different outputs for the same input. This turns out to have a large empirical impact on the framework of global training and beam search. We propose a simple yet effective extension to the shift-reduce process, which eliminates size differences between action sequences in beam-search. Our parser gives comparable accuracies to the state-of-the-art chart parsers. With linear run-time complexity, our parser is over an order of magnitude faster than the fastest chart parser.",
        "date": "2013",
        "authers": [
            "Muhua Zhu",
            "Yue Zhang",
            "Wenliang Chen",
            "Min Zhang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/262402839_A_transition-based_system_for_joint_part-of-speech_tagging_and_labeled_non-projective_dependency_parsing",
            "https://www.researchgate.net/publication/262323558_Capturing_paradigmatic_and_syntagmatic_lexical_relations_towards_accurate_Chinese_part-of-speech_tagging",
            "https://www.researchgate.net/publication/228916842_Statistical_dependency_analysis_with_support_vector_machines",
            "https://www.researchgate.net/publication/228362666_A_classifier-based_parser_with_linear_run-time_complexity",
            "https://www.researchgate.net/publication/270877686_Exploiting_Lexical_Dependencies_from_Large-Scale_Data_for_Better_Shift-Reduce_Constituency_Parsing",
            "https://www.researchgate.net/publication/262361657_Utilizing_dependency_language_models_for_graph-based_dependency_parsing_models",
            "https://www.researchgate.net/publication/262349927_Discriminative_Reranking_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/243787298_On_the_parameter_space_of_generative_lexicalized_statistical_parsing_models",
            "https://www.researchgate.net/publication/233823603_Practical_Structured_Learning_Techniques_for_Natural_Language_Processing"
        ]
    },
    "paper11": {
        "id": "265252627",
        "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
        "abstract": "Neural machine translation is a recently proposed approach to machine\ntranslation. Unlike the traditional statistical machine translation, the neural\nmachine translation aims at building a single neural network that can be\njointly tuned to maximize the translation performance. The models proposed\nrecently for neural machine translation often belong to a family of\nencoder-decoders and consists of an encoder that encodes a source sentence into\na fixed-length vector from which a decoder generates a translation. In this\npaper, we conjecture that the use of a fixed-length vector is a bottleneck in\nimproving the performance of this basic encoder-decoder architecture, and\npropose to extend this by allowing a model to automatically (soft-)search for\nparts of a source sentence that are relevant to predicting a target word,\nwithout having to form these parts as a hard segment explicitly. With this new\napproach, we achieve a translation performance comparable to the existing\nstate-of-the-art phrase-based system on the task of English-to-French\ntranslation. Furthermore, qualitative analysis reveals that the\n(soft-)alignments found by the model agree well with our intuition.",
        "date": "2014",
        "authers": [
            "Dzmitry Bahdanau",
            "Kyunghyun Cho",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/270877878_Fast_and_Robust_Neural_Network_Joint_Models_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/265386055_Overcoming_the_Curse_of_Sentence_Length_for_Neural_Machine_Translation_using_Automatic_Segmentation",
            "https://www.researchgate.net/publication/265385879_On_the_Properties_of_Neural_Machine_Translation_Encoder-Decoder_Approaches",
            "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/319770418_Maxout_Networks",
            "https://www.researchgate.net/publication/307174794_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/303256841_Theano_a_CPU_and_GPU_math_expression_compiler",
            "https://www.researchgate.net/publication/289758666_Recurrent_continuous_translation_models",
            "https://www.researchgate.net/publication/270878785_Continuous_Space_Translation_Models_for_Phrase-Based_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/261309981_Hybrid_speech_recognition_with_Deep_Bidirectional_LSTM"
        ]
    },
    "paper12": {
        "id": "262877889",
        "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
        "abstract": "In this paper, we propose a novel neural network model called RNN Encoder--Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder--Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
        "date": "2014",
        "authers": [
            "Kyunghyun Cho",
            "Bart van Merrienboer",
            "Caglar Gulcehre",
            "Fethi Bougares"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality",
            "https://www.researchgate.net/publication/319770387_Deep_Sparse_Rectifier_Neural_Networks",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/312369762_Continuous_space_translation_models_with_neural_networks",
            "https://www.researchgate.net/publication/307955489_Distributed_representations_of_words_and_phrases_and_their_compositionality",
            "https://www.researchgate.net/publication/289758666_Recurrent_continuous_translation_models",
            "https://www.researchgate.net/publication/270878785_Continuous_Space_Translation_Models_for_Phrase-Based_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/233981807_ADADELTA_An_adaptive_learning_rate_method",
            "https://www.researchgate.net/publication/228379274_EuroParl_A_parallel_corpus_for_statistical_machine_translation"
        ]
    },
    "paper13": {
        "id": "262408350",
        "title": "Effective self-training for parsing",
        "abstract": "We present a simple, but surprisingly effective, method of self-training a two-phase parser-reranker system using readily available unlabeled data. We show that this type of bootstrapping is possible for parsing when the bootstrapped parses are processed by a discriminative reranker. Our improved model achieves an f-score of 92.1%, an absolute 1.1% improvement (12% error reduction) over the previous best result for Wall Street Journal parsing. Finally, we provide some analysis to better understand the phenomenon.",
        "date": "2006",
        "authers": [
            "David McClosky",
            "Eugene Charniak",
            "Mark Johnson"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221617806_PAC_Generalization_Bounds_for_Co-training",
            "https://www.researchgate.net/publication/268237865_Better_k_-best_parsing",
            "https://www.researchgate.net/publication/262349927_Discriminative_Reranking_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/230876697_North_American_News_Text_Corpus",
            "https://www.researchgate.net/publication/230876655_Applying_Cotraining_Methods_to_Statistical_Parsing",
            "https://www.researchgate.net/publication/229078318_Combining_Labeled_and_Unlabeld_Data_with_Co-Training",
            "https://www.researchgate.net/publication/223311595_MAP_adaptation_of_stochastic_grammars",
            "https://www.researchgate.net/publication/221275760_Computation_of_the_N_Best_Parse_Trees_for_Weighted_and_Stochastic_Context-Free_Grammars",
            "https://www.researchgate.net/publication/220875255_An_Empirical_Study_of_Smoothing_Techniques_for_Language_Modeling",
            "https://www.researchgate.net/publication/220875180_Coarse-to-Fine_n-Best_Parsing_and_MaxEnt_Discriminative_Reranking"
        ]
    },
    "paper14": {
        "id": "221013135",
        "title": "Self-Training PCFG Grammars with Latent Annotations Across Languages",
        "abstract": "We investigate the effectiveness of self- training PCFG grammars with latent anno- tations (PCFG-LA) for parsing languages with different amounts of labeled training data. Compared to Charniak's lexicalized parser, the PCFG-LA parser was more ef- fectively adapted to a language for which parsing has been less well developed (i.e., Chinese) and benefited more from self- training. We show for the first time that self-training is able to significantly im- prove the performance of the PCFG-LA parser, a single generative parser, on both small and large amounts of labeled train- ing data. Our approach achieves state- of-the-art parsing accuracies for a single parser on both English (91.5%) and Chi- nese (85.2%).",
        "date": "2009",
        "authers": [
            "Zhongqiang Huang",
            "Mary Harper"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/221101491_When_is_Self-Training_Effective_for_Parsing",
            "https://www.researchgate.net/publication/221012635_Mandarin_Part-of-Speech_Tagging_and_Discriminative_Reranking",
            "https://www.researchgate.net/publication/220875081_Probabilistic_CFG_with_Latent_Annotations",
            "https://www.researchgate.net/publication/220873863_Learning_Accurate_Compact_and_Interpretable_Tree_Annotation",
            "https://www.researchgate.net/publication/221012840_Sparse_Multi-Scale_Grammars_for_Discriminative_Latent_Variable_Parsing",
            "https://www.researchgate.net/publication/220875180_Coarse-to-Fine_n-Best_Parsing_and_MaxEnt_Discriminative_Reranking",
            "https://www.researchgate.net/publication/220874256_Semi-Supervised_Convex_Training_for_Dependency_Parsing",
            "https://www.researchgate.net/publication/220873964_Self-Training_for_Enhancement_and_Domain_Adaptation_of_Statistical_Parsers_Trained_on_Small_Datasets",
            "https://www.researchgate.net/publication/220873958_Forest_Reranking_Discriminative_Parsing_with_Non-Local_Features"
        ]
    },
    "paper15": {
        "id": "220873863",
        "title": "Learning Accurate Compact and Interpretable Tree Annotation",
        "abstract": "We present an automatic approach to tree annota- tion in which basic nonterminal symbols are alter- nately split and merged to maximize the likelihood of a training treebank. Starting with a simple X- bar grammar, we learn a new grammar whose non- terminals are subsymbols of the original nontermi- nals. In contrast with previous work, we are able to split various terminals to different degrees, as ap- propriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more ac- curate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F1 of 90.2% on the Penn Treebank, higher than fully lexicalized systems.",
        "date": "2006",
        "authers": [
            "Slav Petrov",
            "Leon Barrett",
            "Romain Thibaux",
            "Dan Klein"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220875081_Probabilistic_CFG_with_Latent_Annotations",
            "https://www.researchgate.net/publication/220874045_Discriminative_Training_of_a_Neural_Network_Statistical_Parser",
            "https://www.researchgate.net/publication/298836450_Automatic_word_sense_discrimination",
            "https://www.researchgate.net/publication/292453644_Computational_complexity_of_probabilistic_disambiguation_NP-completeness_results_for_parsing_problems_that_arise_in_speech_and_language_processing_applications",
            "https://www.researchgate.net/publication/288942058_A_clustering_technique_for_summarizing_multivariate_data",
            "https://www.researchgate.net/publication/242430108_Aspects_of_The_Theory_of_Syntax",
            "https://www.researchgate.net/publication/225740821_Computational_Complexity_of_Probabilistic_Disambiguation",
            "https://www.researchgate.net/publication/225517426_Inducing_probabilistic_grammars_by_Bayesian_model_merging",
            "https://www.researchgate.net/publication/221112104_Inducing_Head-Driven_PCFGs_with_Latent_Heads_Refining_a_Tree-Bank_Grammar_for_Parsing",
            "https://www.researchgate.net/publication/220875180_Coarse-to-Fine_n-Best_Parsing_and_MaxEnt_Discriminative_Reranking"
        ]
    },
    "paper16": {
        "id": "13853244",
        "title": "Long Short-term Memory",
        "abstract": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.",
        "date": "1997Neural",
        "authers": [
            "Sepp Hochreiter",
            "J\u00fcrgen Schmidhuber"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/277298117_Bridging_Long_Time_Lags_by_Weight_Guessing_and_Long_Short_Term_Memory",
            "https://www.researchgate.net/publication/277295865_Guessing_Can_Outperform_Many_Long_Time_Lag_Algorithms",
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/243698906_Finite_State_Automata_and_Simple_Recurrent_Networks",
            "https://www.researchgate.net/publication/243683010_The_utility_driven_dynamic_error_propagation_network",
            "https://www.researchgate.net/publication/313702304_Learning_sequential_structures_with_the_real-time_recurrent_learning_algorithm",
            "https://www.researchgate.net/publication/263902178_LEARNING_SEQUENTIAL_STRUCTURE_WITH_THE_REAL-TIME_RECURRENT_LEARNING_ALGORITHM",
            "https://www.researchgate.net/publication/243763246_A_recurrent_cascade-correlation_learning_architecture",
            "https://www.researchgate.net/publication/243732587_Generalization_of_Back-Propagation_to_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/243683189_Complexity_of_exact_gradient_computation_algorithms_for_recurrent_neural_networks"
        ]
    },
    "paper17": {
        "id": "322584145",
        "title": "Massive Exploration of Neural Machine Translation Architectures",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Denny Britz",
            "Anna Helen Goldie",
            "Minh-Thang Luong",
            "Quoc Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/312216100_OpenNMT_Open-Source_Toolkit_for_Neural_Machine_Translation",
            "https://www.researchgate.net/publication/311223153_Speedaccuracy_trade-offs_for_modern_convolutional_object_detectors",
            "https://www.researchgate.net/publication/309766061_A_Convolutional_Encoder_Model_for_Neural_Machine_Translation",
            "https://www.researchgate.net/publication/307747289_Show_and_tell_A_neural_image_caption_generator",
            "https://www.researchgate.net/publication/306093640_Abstractive_Text_Summarization_Using_Sequence-to-Sequence_RNNs_and_Beyond",
            "https://www.researchgate.net/publication/303657108_TensorFlow_A_system_for_large-scale_machine_learning",
            "https://www.researchgate.net/publication/273640320_LSTM_A_search_space_odyssey",
            "https://www.researchgate.net/publication/273388012_Neural_Responding_Machine_for_Short-Text_Conversation",
            "https://www.researchgate.net/publication/272194766_Show_Attend_and_Tell_Neural_Image_Caption_Generation_with_Visual_Attention"
        ]
    },
    "paper18": {
        "id": "305196650",
        "title": "Going deeper with convolutions",
        "abstract": "",
        "date": "2015",
        "authers": [
            "Christian Szegedy",
            "Wei Liu",
            "Yangqing Jia",
            "Pierre Sermanet"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770289_Deep_Neural_Networks_for_Object_Detection",
            "https://www.researchgate.net/publication/289917319_Deep_Neural_Networks_for_object_detection",
            "https://www.researchgate.net/publication/266657849_Scaling_up_matrix_computations_on_shared-memory_manycore_systems_with_1000_CPU_cores",
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770166_Provable_Bounds_for_Learning_Some_Deep_Representations",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/286271944_On_the_importance_of_initialization_and_momentum_in_deep_learning",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks"
        ]
    },
    "paper19": {
        "id": "269935397",
        "title": "FitNets Hints for Thin Deep Nets",
        "abstract": "While depth tends to improve network performances, it also makes\ngradient-based training more difficult since deeper networks tend to be more\nnon-linear. The recently proposed knowledge distillation approach is aimed at\nobtaining small and fast-to-execute models, and it has shown that a student\nnetwork could imitate the soft output of a larger teacher network or ensemble\nof networks. In this paper, we extend this idea to allow the training of a\nstudent that is deeper and thinner than the teacher, using not only the outputs\nbut also the intermediate representations learned by the teacher as hints to\nimprove the training process and final performance of the student. Because the\nstudent intermediate hidden layer will generally be smaller than the teacher's\nintermediate hidden layer, additional parameters are introduced to map the\nstudent hidden layer to the prediction of the teacher hidden layer. This allows\none to train deeper students that can generalize better or run faster, a\ntrade-off that is controlled by the chosen student capacity. For example, on\nCIFAR-10, a deep student network with almost 10.4 times less parameters\noutperforms a larger, state-of-the-art teacher network.",
        "date": "2014",
        "authers": [
            "Adriana Romero",
            "Nicolas Ballas",
            "Samira Ebrahimi Kahou",
            "Antoine Chassang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/267225654_A_Two-Stage_Pretraining_Algorithm_for_Deep_Boltzmann_Machines",
            "https://www.researchgate.net/publication/265908778_Deeply-Supervised_Nets",
            "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/289733708_Do_deep_nets_really_need_to_be_deep",
            "https://www.researchgate.net/publication/273387909_Distilling_the_Knowledge_in_a_Neural_Network",
            "https://www.researchgate.net/publication/269877085_Compressing_Deep_Convolutional_Networks_using_Vector_Quantization",
            "https://www.researchgate.net/publication/266031774_Reading_Digits_in_Natural_Images_with_Unsupervised_Feature_Learning",
            "https://www.researchgate.net/publication/265748773_Learning_Multiple_Layers_of_Features_from_Tiny_Images"
        ]
    },
    "paper20": {
        "id": "265908778",
        "title": "Deeply-Supervised Nets",
        "abstract": "Our proposed deeply-supervised nets (DSN) method simultaneously minimizes\nclassification error while making the learning process of hidden layers direct\nand transparent. We make an attempt to boost the classification performance by\nstudying a new formulation in deep networks. Three aspects in convolutional\nneural networks (CNN) style architectures are being looked at: (1) transparency\nof the intermediate layers to the overall classification; (2)\ndiscriminativeness and robustness of learned features, especially in the early\nlayers; (3) effectiveness in training due to the presence of the exploding and\nvanishing gradients. We introduce \"companion objective\" to the individual\nhidden layers, in addition to the overall objective at the output layer (a\ndifferent strategy to layer-wise pre-training). We extend techniques from\nstochastic gradient methods to analyze our algorithm. The advantage of our\nmethod is evident and our experimental result on benchmark datasets shows\nsignificant performance gain over existing methods (e.g. all state-of-the-art\nresults on MNIST, CIFAR-10, CIFAR-100, and SVHN).",
        "date": "2014",
        "authers": [
            "Chen-Yu Lee",
            "Saining Xie",
            "Patrick Gallagher",
            "Zhengyou Zhang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/291735245_Regularization_of_neural_networks_using_dropconnect",
            "https://www.researchgate.net/publication/286569315_Discriminative_transfer_learning_with_tree-based_priors",
            "https://www.researchgate.net/publication/278695382_The_Nature_of_Statistical_Learning_Theory",
            "https://www.researchgate.net/publication/278651717_The_Nature_of_Statistical_Learning_Theory",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks"
        ]
    },
    "paper21": {
        "id": "265787949",
        "title": "Going Deeper with Convolutions",
        "abstract": "We propose a deep convolutional neural network architecture codenamed\n\"Inception\", which was responsible for setting the new state of the art for\nclassification and detection in the ImageNet Large-Scale Visual Recognition\nChallenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the\nimproved utilization of the computing resources inside the network. This was\nachieved by a carefully crafted design that allows for increasing the depth and\nwidth of the network while keeping the computational budget constant. To\noptimize quality, the architectural decisions were based on the Hebbian\nprinciple and the intuition of multi-scale processing. One particular\nincarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22\nlayers deep network, the quality of which is assessed in the context of\nclassification and detection.",
        "date": "2014",
        "authers": [
            "Christian Szegedy",
            "Wei Liu",
            "Yangqing Jia",
            "Pierre Sermanet"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770289_Deep_Neural_Networks_for_Object_Detection",
            "https://www.researchgate.net/publication/289917319_Deep_Neural_Networks_for_object_detection",
            "https://www.researchgate.net/publication/266657849_Scaling_up_matrix_computations_on_shared-memory_manycore_systems_with_1000_CPU_cores",
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770166_Provable_Bounds_for_Learning_Some_Deep_Representations",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/286271944_On_the_importance_of_initialization_and_momentum_in_deep_learning",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks"
        ]
    },
    "paper22": {
        "id": "265295439",
        "title": "ImageNet Large Scale Visual Recognition Challenge",
        "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in\nobject category classification and detection on hundreds of object categories\nand millions of images. The challenge has been run annually from 2010 to\npresent, attracting participation from more than fifty institutions.\nThis paper describes the creation of this benchmark dataset and the advances\nin object recognition that have been possible as a result. We discuss the\nchallenges of collecting large-scale ground truth annotation, highlight key\nbreakthroughs in categorical object recognition, provide detailed a analysis of\nthe current state of the field of large-scale image classification and object\ndetection, and compare the state-of-the-art computer vision accuracy with human\naccuracy. We conclude with lessons learned in the five years of the challenge,\nand propose future directions and improvements.",
        "date": "2014International",
        "authers": [
            "Olga Russakovsky",
            "Jia Deng",
            "Hao Su",
            "Jonathan Krause"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/347495711_Learning_Generative_Visual_Models_from_Few_Training_Examples_An_Incremental_Bayesian_Approach_Tested_on_101_Object_Categories",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770370_Three_things_everyone_should_know_to_improve_object_retrieval",
            "https://www.researchgate.net/publication/319770363_Deep_Fisher_Networks_for_Large-Scale_Image_Classification",
            "https://www.researchgate.net/publication/319770264_Regularization_of_Neural_Networks_using_DropConnect",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/316240097_Distinctive_Image_Features_from_Scale-Invariant_Keypoints",
            "https://www.researchgate.net/publication/314450504_Object_detection_using_a_max-margin_Hough_transform"
        ]
    },
    "paper23": {
        "id": "264979485",
        "title": "Caffe Convolutional Architecture for Fast Feature Embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.\nCaffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",
        "date": "2014",
        "authers": [
            "Yangqing Jia",
            "Evan Shelhamer",
            "Jeff Donahue",
            "Sergey Karayev"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/301463801_Open-vocabulary_Object_Retrieval",
            "https://www.researchgate.net/publication/262270555_Selective_Search_for_Object_Recognition",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/258520603_Recognizing_Image_Style",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/272149731_Pylearn2_a_machine_learning_research_library",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/264890087_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/258839715_PANDA_Pose_Aligned_Networks_for_Deep_Attribute_Modeling"
        ]
    },
    "paper24": {
        "id": "260126867",
        "title": "On the Number of Linear Regions of Deep Neural Networks",
        "abstract": "We study the complexity of functions computable by deep feedforward neural networks with piecewise linear activations in terms of the symmetries and the number of linear regions that they have. Deep networks are able to sequentially map portions of each layer's input-space to the same output. In this way, deep models compute functions that react equally to complicated patterns of different inputs. The compositional structure of these functions enables them to re-use pieces of computation exponentially often in terms of the network's depth. This paper investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piecewise linear activation functions. In particular, our analysis is not specific to a single family of models, and as an example, we employ it for rectifier and maxout networks. We improve complexity bounds from pre-existing work and investigate the behavior of units in higher layers.",
        "date": "2014Advances",
        "authers": [
            "Guido Montufar",
            "Razvan Pascanu",
            "Kyunghyun Cho",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/259400019_On_the_number_of_response_regions_of_deep_feed_forward_networks_with_piece-wise_linear_activations",
            "https://www.researchgate.net/publication/258816388_Revisiting_Natural_Gradient_for_Deep_Networks",
            "https://www.researchgate.net/publication/319770418_Maxout_Networks",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/316519032_An_introduction_to_hyperplane_arrangements",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/284500238_Approximation_by_superposition_of_sigmoidale_function",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/267064227_Facing_up_to_Arrangements_Face-Count_Formulas_for_Partitions_of_Space_by_Hyperplanes",
            "https://www.researchgate.net/publication/265178583_Deep_Neural_Networks_for_Acoustic_Modeling_in_Speech_Recognition"
        ]
    },
    "paper25": {
        "id": "259441043",
        "title": "OverFeat Integrated Recognition Localization and Detection using Convolutional Networks",
        "abstract": "We present an integrated framework for using Convolutional Networks for\nclassification, localization and detection. We show how a multiscale and\nsliding window approach can be efficiently implemented within a ConvNet. We\nalso introduce a novel deep learning approach to localization by learning to\npredict object boundaries. Bounding boxes are then accumulated rather than\nsuppressed in order to increase detection confidence. We show that different\ntasks can be learnt simultaneously using a single shared network. This\nintegrated framework is the winner of the localization task of the ImageNet\nLarge Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near\nstate of the art results for the detection and classifications tasks. Finally,\nwe release a feature extractor from our best model called OverFeat.",
        "date": "2013",
        "authers": [
            "Pierre Sermanet",
            "David Eigen",
            "Xiang Zhang",
            "Michael Mathieu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262270555_Selective_Search_for_Object_Recognition",
            "https://www.researchgate.net/publication/257672343_Object_Recognition_by_Sequential_Figure-Ground_Ranking",
            "https://www.researchgate.net/publication/240308781_Learning_Hierarchical_Features_for_Scene_Labeling",
            "https://www.researchgate.net/publication/235360690_Fast_Image_Scanning_with_Deep_Max-Pooling_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/262323276_Prime_Object_Proposals_with_Randomized_Prim's_Algorithm",
            "https://www.researchgate.net/publication/233815499_Pedestrian_Detection_with_Unsupervised_Multi-Stage_Feature_Learning"
        ]
    },
    "paper26": {
        "id": "259440750",
        "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
        "abstract": "Despite the widespread practical success of deep learning methods, our\ntheoretical understanding of the dynamics of learning in deep neural networks\nremains quite sparse. We attempt to bridge the gap between the theory and\npractice of deep learning by systematically analyzing learning dynamics for the\nrestricted case of deep linear neural networks. Despite the linearity of their\ninput-output map, such networks have nonlinear gradient descent dynamics on\nweights that change with the addition of each new hidden layer. We show that\ndeep linear networks exhibit nonlinear learning phenomena similar to those seen\nin simulations of nonlinear networks, including long plateaus followed by rapid\ntransitions to lower error solutions, and faster convergence from greedy\nunsupervised pretraining initial conditions than from random initial\nconditions. We provide an analytical description of these phenomena by finding\nnew exact solutions to the nonlinear dynamics of deep learning. Our theoretical\nanalysis also reveals the surprising finding that as the depth of a network\napproaches infinity, learning speed remains finite: for a special class of\ninitial conditions on the weights, very deep networks incur only a finite delay\nin learning speed relative to shallow networks. We further show that, under\ncertain conditions on the training data, unsupervised pretraining can find this\nspecial class of initial conditions, thereby providing analytical insight into\nthe success of unsupervised pretraining in deep supervised learning tasks.",
        "date": "2013",
        "authers": [
            "Andrew M. Saxe",
            "James L Mcclelland",
            "Surya Ganguli"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/266463521_Improved_Preconditioner_for_Hessian_Free_Optimization",
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/234131129_Big_Neural_Networks_Waste_Capacity",
            "https://www.researchgate.net/publication/233730646_On_the_difficulty_of_training_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/286271944_On_the_importance_of_initialization_and_momentum_in_deep_learning",
            "https://www.researchgate.net/publication/270878508_Parsing_with_Compositional_Vector_Grammars",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks"
        ]
    },
    "paper27": {
        "id": "234119846",
        "title": "Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities",
        "abstract": "Recently, we proposed to transform the outputs of each hidden neuron in a\nmulti-layer perceptron network to have zero output and zero slope on average,\nand use separate shortcut connections to model the linear dependencies instead.\nWe continue the work by firstly introducing a third transformation to normalize\nthe scale of the outputs of each hidden neuron, and secondly by analyzing the\nconnections to second order optimization methods. We show that the\ntransformations make a simple stochastic gradient behave closer to second-order\noptimization methods and thus speed up learning. This is shown both in theory\nand with experiments. The experiments on the third transformation show that\nwhile it further increases the speed of learning, it can also hurt performance\nby converging to a worse local optimum, where both the inputs and outputs of\nmany hidden neurons are close to zero.",
        "date": "2013",
        "authers": [
            "Tommi Vatanen",
            "Tapani Raiko",
            "Harri Valpola",
            "Yann Lecun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/231556969_Deep_Learning_Made_Easier_by_Linear_Transformations_in",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/215616968_Understanding_the_difficulty_of_training_deep_feedforward_neural_networks",
            "https://www.researchgate.net/publication/289786324_Centering_Neural_Network_Gradient_Factors",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/235222671_Science_and_Spectacle_the_Work_of_Jodrell_Bank_in_Post-War_British_Culture",
            "https://www.researchgate.net/publication/225495886_Efficient_BackProp",
            "https://www.researchgate.net/publication/221619092_Topmoumoute_Online_Natural_Gradient_Algorithm",
            "https://www.researchgate.net/publication/221345102_Deep_learning_via_Hessian-free_optimization",
            "https://www.researchgate.net/publication/46392541_Deep_Big_Simple_Neural_Nets_for_Handwritten_Digit_Recognition"
        ]
    },
    "paper28": {
        "id": "328110752",
        "title": "AMC AutoML for Model Compression and Acceleration on Mobile Devices",
        "abstract": "Model compression is an effective technique to efficiently deploy neural network models on mobile devices which have limited computation resources and tight power budgets. Conventional model compression techniques rely on hand-crafted features and require domain experts to explore the large design space trading off among model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4\\(\\times \\) FLOPs reduction, we achieved 2.7% better accuracy than the hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet-V1 and achieved a speedup of 1.53\\(\\times \\) on the GPU (Titan Xp) and 1.95\\(\\times \\) on an Android phone (Google Pixel 1), with negligible loss of accuracy.",
        "date": "2018",
        "authers": [
            "Yihui He",
            "Ji Lin",
            "Zhijian Liu",
            "Hanrui Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/324435700_NetAdapt_Platform-Aware_Neural_Network_Adaptation_for_Mobile_Applications",
            "https://www.researchgate.net/publication/322059721_Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/322058668_Domain-Adaptive_Deep_Network_Compression",
            "https://www.researchgate.net/publication/320971183_More_is_Less_A_More_Complicated_Network_with_Less_Inference_Complexity",
            "https://www.researchgate.net/publication/329745708_Learning_Transferable_Architectures_for_Scalable_Image_Recognition",
            "https://www.researchgate.net/publication/328112952_NetAdapt_Platform-Aware_Neural_Network_Adaptation_for_Mobile_Applications_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_X",
            "https://www.researchgate.net/publication/322517761_Inverted_Residuals_and_Linear_Bottlenecks_Mobile_Networks_forClassification_Detection_and_Segmentation",
            "https://www.researchgate.net/publication/322058064_ThiNet_A_Filter_Level_Pruning_Method_for_Deep_Neural_Network_Compression",
            "https://www.researchgate.net/publication/320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions",
            "https://www.researchgate.net/publication/320963610_LCNN_Lookup-Based_Convolutional_Neural_Network"
        ]
    },
    "paper29": {
        "id": "319622446",
        "title": "The Expressive Power of Neural Networks A View from the Width",
        "abstract": "The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that \\emph{depth-bounded} (e.g. depth-$2$) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for \\emph{width-bounded} ReLU networks: width-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-$n$ ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an \\emph{exponential} bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a \\emph{polynomial} bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth is more effective than width for the expressiveness of ReLU networks.",
        "date": "2017",
        "authers": [
            "Zhou Lu",
            "Hongming Pu",
            "Feicheng Wang",
            "Zhiqiang Hu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308896188_Error_bounds_for_approximations_with_deep_ReLU_networks",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/319770106_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/314361329_Nearly-tight_VC-dimension_bounds_for_piecewise_linear_neural_networks",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/301857086_Benefits_of_depth_in_neural_networks",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/286512696_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/284500238_Approximation_by_superposition_of_sigmoidale_function"
        ]
    },
    "paper30": {
        "id": "314282992",
        "title": "On the Expressive Power of Overlapping Architectures of Deep Learning",
        "abstract": "Expressive efficiency refers to the relation between two architectures A and B, whereby any function realized by B could be replicated by A, but there exists functions realized by A, which cannot be replicated by B unless its size grows significantly larger. For example, it is known that deep networks are exponentially efficient with respect to shallow networks, in the sense that a shallow network must grow exponentially large in order to approximate the functions represented by a deep network of polynomial size. In this work, we extend the study of expressive efficiency to the attribute of network connectivity and in particular to the effect of \"overlaps\" in the convolutional process, i.e., when the stride of the convolution is smaller than its filter size (receptive field).\nTo theoretically analyze this aspect of network's design, we focus on a well-established surrogate for ConvNets called Convolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically that our results hold for standard ConvNets as well. Specifically, our analysis shows that having overlapping local receptive fields, and more broadly denser connectivity, results in an exponential increase in the expressive capacity of neural networks. Moreover, while denser connectivity can increase the expressive capacity, we show that the most common types of modern architectures already exhibit exponential increase in expressivity, without relying on fully-connected layers.",
        "date": "2018",
        "authers": [
            "Or Sharir",
            "Amnon Shashua"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322539221_Notes_on_the_number_of_linear_regions_of_deep_neural_networks",
            "https://www.researchgate.net/publication/309131743_Tensorial_Mixture_Models",
            "https://www.researchgate.net/publication/308026508_WaveNet_A_Generative_Model_for_Raw_Audio",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/304018355_Exponential_expressivity_in_deep_neural_networks_through_transient_chaos",
            "https://www.researchgate.net/publication/303448829_Inductive_Bias_of_Deep_Convolutional_Networks_through_Pooling_Geometry",
            "https://www.researchgate.net/publication/319770395_An_Analysis_of_Single-Layer_Networks_in_Unsupervised_Feature_Learning",
            "https://www.researchgate.net/publication/319770007_Benefits_of_depth_in_neural_networks",
            "https://www.researchgate.net/publication/312461699_Understanding_the_Effective_Receptive_Field_in_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/309572399_Depth_Separation_in_ReLU_Networks_for_Approximating_Smooth_Non-Linear_Functions"
        ]
    },
    "paper31": {
        "id": "313641935",
        "title": "Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning",
        "abstract": "In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility\ntraces, instead of experience replay, and softmax action selection can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10x10 board, using TD(\u03bb) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(\u03bb) agent with SiLU and dSiLU hidden units.",
        "date": "2018Neural",
        "authers": [
            "Stefan Elfwing",
            "Eiji Uchibe",
            "Kenji Doya"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/307627766_From_free_energy_to_expected_energy_Improving_energy-based_value_function_approximation_in_reinforcement_learning",
            "https://www.researchgate.net/publication/292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search",
            "https://www.researchgate.net/publication/282182152_Deep_Reinforcement_Learning_with_Double_Q-learning",
            "https://www.researchgate.net/publication/280898866_Approximate_Modified_Policy_Iteration_and_its_Application_to_the_Game_of_Tetris",
            "https://www.researchgate.net/publication/280104499_Massively_Parallel_Methods_for_Deep_Reinforcement_Learning",
            "https://www.researchgate.net/publication/280043948_High-Dimensional_Function_Approximation_for_Knowledge-Free_Reinforcement_Learning_a_Case_Study_in_SZ-Tetris",
            "https://www.researchgate.net/publication/319770330_Prioritized_Experience_Replay",
            "https://www.researchgate.net/publication/312990324_Td-gammon_a_self-Teaching_backgammon_program_achieves_master-level_play",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/304109482_Training_products_of_experts_by_minimizing_contrastive_divergence"
        ]
    },
    "paper32": {
        "id": "348350592",
        "title": "ResNet with one-neuron hidden layers is a Universal Approximator",
        "abstract": "We demonstrate that a very deep ResNet with stacked modules that have one neuron per hidden layer and ReLU activation functions can uniformly approximate any Lebesgue integrable function in d dimensions, i.e. \u21131(Rd). Due to the identity mapping inherent to ResNets, our network has alternating layers of dimension one and d. This stands in sharp contrast to fully connected networks, which are not universal approximators if their width is the input dimension d [21, 11]. Hence, our result implies an increase in representational power for narrow deep networks by the ResNet architecture.",
        "date": "2018",
        "authers": [
            "Hongzhou Lin",
            "Stefanie Sabrina Jegelka"
        ],
        "refrences": []
    },
    "paper33": {
        "id": "329740202",
        "title": "Squeeze-and-Excitation Networks",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Jie Hu",
            "Li Shen",
            "Gang Sun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/320965021_Lip_Reading_Sentences_in_the_Wild",
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/316450913_Residual_Attention_Network_for_Image_Classification",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/310462326_PolyNet_A_Pursuit_of_Structural_Diversity_in_Very_Deep_Networks",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/303409658_Deep_Roots_Improving_CNN_Efficiency_with_Hierarchical_Filter_Groups",
            "https://www.researchgate.net/publication/268079628_How_transferable_are_features_in_deep_neural_networks",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/263891809_Deep_Networks_with_Internal_Selective_Attention_through_Feedback_Connections"
        ]
    },
    "paper34": {
        "id": "329740172",
        "title": "ShuffleNet An Extremely Efficient Convolutional Neural Network for Mobile Devices",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Xiangyu Zhang",
            "Xinyu Zhou",
            "Mengxiao Lin",
            "Jian Sun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770160_Show_and_Tell_A_Neural_Image_Caption_Generator",
            "https://www.researchgate.net/publication/318337293_Primal-Dual_Group_Convolutions_for_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/313645102_Incremental_Network_Quantization_Towards_Lossless_CNNs_with_Low-Precision_Weights",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/303409658_Deep_Roots_Improving_CNN_Efficiency_with_Hierarchical_Filter_Groups",
            "https://www.researchgate.net/publication/301878495_SqueezeNet_AlexNet-level_accuracy_with_50x_fewer_parameters_and_05MB_model_size",
            "https://www.researchgate.net/publication/301839500_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems",
            "https://www.researchgate.net/publication/287853408_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices",
            "https://www.researchgate.net/publication/282005595_Expectation_Backpropagation_Parameter-Free_Training_of_Multilayer_Neural_Networks_with_Continuous_or_Discrete_Weights"
        ]
    },
    "paper35": {
        "id": "322950113",
        "title": "Regularized Evolution for Image Classifier Architecture Search",
        "abstract": "The effort devoted to hand-crafting image classifiers has motivated the use of architecture search to discover them automatically. Reinforcement learning and evolution have both shown promise for this purpose. This study introduces a regularized version of a popular asynchronous evolutionary algorithm. We rigorously compare it to the non-regularized form and to a highly-successful reinforcement learning baseline. Using the same hardware, compute effort and neural network training code, we conduct repeated experiments side-by-side, exploring different datasets, search spaces and scales. We show regularized evolution consistently produces models with similar or higher accuracy, across a variety of contexts without need for re-tuning parameters. In addition, regularized evolution exhibits considerably better performance than reinforcement learning at early search stages, suggesting it may be the better choice when fewer compute resources are available. This constitutes the first controlled comparison of the two search algorithms in this context. Finally, we present new architectures discovered with regularized evolution that we nickname AmoebaNets. These models set a new state of the art for CIFAR-10 (mean test error = 2.13%) and mobile-size ImageNet (top-5 accuracy = 92.1% with 5.06M parameters), and reach the current state of the art for ImageNet (top-5 accuracy = 96.2%).",
        "date": "2018Proceedings",
        "authers": [
            "Esteban Real",
            "Alok Aggarwal",
            "Yanping Huang",
            "Quoc V Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/325673550_Efficient_Architecture_Search_by_Network_Transformation",
            "https://www.researchgate.net/publication/321902574_Deep_Neuroevolution_Genetic_Algorithms_Are_a_Competitive_Alternative_for_Training_Deep_Neural_Networks_for_Reinforcement_Learning",
            "https://www.researchgate.net/publication/318255371_Dual_Path_Networks",
            "https://www.researchgate.net/publication/316598820_DeepArchitect_Automatically_Designing_and_Training_Deep_Architectures",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/313096253_PathNet_Evolution_Channels_Gradient_Descent_in_Super_Neural_Networks",
            "https://www.researchgate.net/publication/309738510_Designing_Neural_Network_Architectures_using_Reinforcement_Learning",
            "https://www.researchgate.net/publication/308981007_Deep_Pyramidal_Residual_Networks",
            "https://www.researchgate.net/publication/306885833_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/304857984_AdaNet_Adaptive_Structural_Learning_of_Artificial_Neural_Networks"
        ]
    },
    "paper36": {
        "id": "320968382",
        "title": "Xception Deep Learning with Depthwise Separable Convolutions",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Francois Chollet"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319769813_Fast_and_Accurate_Deep_Network_Learning_by_Exponential_Linear_Units_ELUs",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/284579051_Fast_and_Accurate_Deep_Network_Learning_by_Exponential_Linear_Units_ELUs",
            "https://www.researchgate.net/publication/269722508_Flattened_Convolutional_Neural_Networks_for_Feedforward_Acceleration",
            "https://www.researchgate.net/publication/260642043_Rigid-Motion_Scattering_for_Texture_Classification",
            "https://www.researchgate.net/publication/236736831_Acceleration_of_Stochastic_Approximation_by_Averaging",
            "https://www.researchgate.net/publication/230867026_Simplifying_ConvNets_for_Fast_Learning",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks"
        ]
    },
    "paper37": {
        "id": "338503872",
        "title": "Fast Neural Architecture Search of Compact Semantic Segmentation Models via Auxiliary Cells",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Vladimir Nekrasov",
            "Hao Chen",
            "Chunhua Shen",
            "Ian Reid"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/324584089_Simple_Baselines_for_Human_Pose_Estimation_and_Tracking",
            "https://www.researchgate.net/publication/335144529_Real-Time_Joint_Semantic_Segmentation_and_Depth_Estimation_Using_Asymmetric_Annotations",
            "https://www.researchgate.net/publication/330595799_CReaM_Condensed_Real-time_Models_for_Depth_Prediction_using_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/329748830_Taskonomy_Disentangling_Task_Transfer_Learning",
            "https://www.researchgate.net/publication/329745708_Learning_Transferable_Architectures_for_Scalable_Image_Recognition",
            "https://www.researchgate.net/publication/323570681_On_the_Power_of_Over-parametrization_in_Neural_Networks_with_Quadratic_Activation",
            "https://www.researchgate.net/publication/323302973_Neural_Architecture_Search_with_Bayesian_Optimisation_and_Optimal_Transport",
            "https://www.researchgate.net/publication/323118469_Efficient_Neural_Architecture_Search_via_Parameters_Sharing",
            "https://www.researchgate.net/publication/323027025_Encoder-Decoder_with_Atrous_Separable_Convolution_for_Semantic_Image_Segmentation",
            "https://www.researchgate.net/publication/322517761_Inverted_Residuals_and_Linear_Bottlenecks_Mobile_Networks_forClassification_Detection_and_Segmentation"
        ]
    },
    "paper38": {
        "id": "335463644",
        "title": "Boundary-Aware Feature Propagation for Scene Segmentation",
        "abstract": "In this work, we address the challenging issue of scene segmentation. To increase the feature similarity of the same object while keeping the feature discrimination of different objects, we explore to propagate information throughout the image under the control of objects' boundaries. To this end, we first propose to learn the boundary as an additional semantic class to enable the network to be aware of the boundary layout. Then, we propose unidirectional acyclic graphs (UAGs) to model the function of undirected cyclic graphs (UCGs), which structurize the image via building graphic pixel-by-pixel connections, in an efficient and effective way. Furthermore, we propose a boundary-aware feature propagation (BFP) module to harvest and propagate the local features within their regions isolated by the learned boundaries in the UAG-structured image. The proposed BFP is capable of splitting the feature propagation into a set of semantic groups via building strong connections among the same segment region but weak connections between different segment regions. Without bells and whistles, our approach achieves new state-of-the-art segmentation performance on three challenging semantic segmentation datasets, i.e., PASCAL-Context, CamVid, and Cityscapes.",
        "date": "2019",
        "authers": [
            "Henghui Ding",
            "Xudong Jiang",
            "Ai Qun Liu",
            "Nadia Magnenat Thalmann"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/339558864_Dynamic_Multi-Scale_Filters_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/339558490_Unpaired_Image_Captioning_via_Scene_Graph_Alignments",
            "https://www.researchgate.net/publication/339556516_Joint_Learning_of_Saliency_Detection_and_Weakly_Supervised_Semantic_Segmentation",
            "https://www.researchgate.net/publication/339555830_Deep_Learning_for_Light_Field_Saliency_Detection",
            "https://www.researchgate.net/publication/339555410_Adaptive_Context_Network_for_Scene_Parsing",
            "https://www.researchgate.net/publication/339554650_Fast_Video_Object_Segmentation_via_Dynamic_Targeting_Network",
            "https://www.researchgate.net/publication/338512016_Dual_Attention_Network_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/338509793_Scene_Graph_Generation_With_External_Knowledge_and_Image_Reconstruction",
            "https://www.researchgate.net/publication/338506535_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation"
        ]
    },
    "paper39": {
        "id": "329442528",
        "title": "DenseASPP for Semantic Segmentation in Street Scenes",
        "abstract": "Semantic image segmentation is a basic street scene un-\nderstanding task in autonomous driving, where each pixel in\na high resolution image is categorized into a set of seman-\ntic labels. Unlike other scenarios, objects in autonomous\ndriving scene exhibit very large scale changes, which poses\ngreat challenges for high-level feature representation in a\nsense that multi-scale information must be correctly en-\ncoded. To remedy this problem, atrous convolution[14] was\nintroduced to generate features with larger receptive fields\nwithout sacrificing spatial resolution. Built upon atrous\nconvolution, Atrous Spatial Pyramid Pooling (ASPP)[2]\nwas proposed to concatenate multiple atrous-convolved fea-\ntures using different dilation rates into a final feature rep-\nresentation. Although ASPP is able to generate multi-scale\nfeatures, we argue the feature resolution in the scale-axis\nis not dense enough for the autonomous driving scenario.\nTo this end, we propose Densely connected Atrous Spa-\ntial Pyramid Pooling (DenseASPP), which connects a set\nof atrous convolutional layers in a dense way, such that it\ngenerates multi-scale features that not only cover a larger\nscale range, but also cover that scale range densely, with-\nout significantly increasing the model size. We evaluate\nDenseASPP on the street scene benchmark Cityscapes[4]\nand achieve state-of-the-art performance.",
        "date": "2018",
        "authers": [
            "Maoke Yang",
            "Yu Kun",
            "Chi Zhang",
            "Zhiwei Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322749812_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/324996175_Understanding_Convolution_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/322058210_Video_Scene_Parsing_with_Predictive_Feature_Learning",
            "https://www.researchgate.net/publication/320971443_Full-Resolution_Residual_Networks_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/320968233_RefineNet_Multi-path_Refinement_Networks_for_High-Resolution_Semantic_Segmentation",
            "https://www.researchgate.net/publication/320968206_Pyramid_Scene_Parsing_Network",
            "https://www.researchgate.net/publication/320964900_Large_Kernel_Matters_-_Improve_Semantic_Segmentation_by_Global_Convolutional_Network",
            "https://www.researchgate.net/publication/319770420_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_and_Fully_Connected_CRFs",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/317679203_Rethinking_Atrous_Convolution_for_Semantic_Image_Segmentation"
        ]
    },
    "paper40": {
        "id": "302305068",
        "title": "Multi-Scale Context Aggregation by Dilated Convolutions",
        "abstract": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction problems such as semantic segmentation are structurally different from image classification. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.",
        "date": "2016",
        "authers": [
            "Fisher Yu",
            "Vladlen Koltun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319769910_Efficient_piecewise_training_of_deep_structure_models_for_semantic_segmentation",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/282179651_Vision-Based_Offline-Online_Perception_Paradigm_for_Autonomous_Driving",
            "https://www.researchgate.net/publication/277334270_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Robust_Semantic_Pixel-Wise_Labelling",
            "https://www.researchgate.net/publication/275588416_FlowNet_Learning_Optical_Flow_with_Convolutional_Networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/308830795_Multiclass_semantic_video_segmentation_with_object-level_active_inference",
            "https://www.researchgate.net/publication/302305924_Feature_Space_Optimization_for_Semantic_Video_Segmentation",
            "https://www.researchgate.net/publication/283761983_Attention_to_Scale_Scale-aware_Semantic_Image_Segmentation",
            "https://www.researchgate.net/publication/276923091_Learning_Deconvolution_Network_for_Semantic_Segmentation"
        ]
    },
    "paper41": {
        "id": "301880609",
        "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding",
        "abstract": "Visual understanding of complex urban street scenes is an enabling factor for a wide range of applications. Object detection has benefited enormously from large-scale datasets, especially in the context of deep learning. For semantic urban scene understanding, however, no current dataset adequately captures the complexity of real-world urban scenes. To address this, we introduce Cityscapes, a benchmark suite and large-scale dataset to train and test approaches for pixel-level and instance-level semantic labeling. Cityscapes is comprised of a large, diverse set of stereo video sequences recorded in streets from 50 different cities. 5000 of these images have high quality pixel-level annotations; 20000 additional images have coarse annotations to enable methods that leverage large volumes of weakly-labeled data. Crucially, our effort exceeds previous attempts in terms of dataset size, annotation richness, scene variability, and complexity. Our accompanying empirical study provides an in-depth analysis of the dataset characteristics, as well as a performance evaluation of several state-of-the-art approaches based on our benchmark.",
        "date": "2016",
        "authers": [
            "Marius Cordts",
            "Mohamed Omran",
            "Sebastian Ramos",
            "Timo Rehfeld"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770205_Monocular_pedestrian_detection_survey_and_experiments",
            "https://www.researchgate.net/publication/319769910_Efficient_piecewise_training_of_deep_structure_models_for_semantic_segmentation",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770420_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_and_Fully_Connected_CRFs",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311610893_Efficient_Piecewise_Training_of_Deep_Structured_Models_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311610196_Semantic_Instance_Annotation_of_Street_Scenes_by_3D_to_2D_Label_Transfer",
            "https://www.researchgate.net/publication/308862494_Learning_to_segment_under_various_forms_of_weak_supervision"
        ]
    },
    "paper42": {
        "id": "347030093",
        "title": "Improving Semantic Segmentation via Decoupled Body and Edge Supervision",
        "abstract": "Existing semantic segmentation approaches either aim to improve the object\u2019s inner consistency by modeling the global context, or refine objects detail along their boundaries by multi-scale feature fusion. In this paper, a new paradigm for semantic segmentation is proposed. Our insight is that appealing performance of semantic segmentation requires explicitly modeling the object body and edge, which correspond to the high and low frequency of the image. To do so, we first warp the image feature by learning a flow field to make the object part more consistent. The resulting body feature and the residual edge feature are further optimized under decoupled supervision by explicitly sampling different parts (body or edge) pixels. We show that the proposed framework with various baselines or backbone networks leads to better object inner consistency and object boundaries. Extensive experiments on four major road scene semantic segmentation benchmarks including Cityscapes, CamVid, KIITI and BDD show that our proposed approach establishes new state of the art while retaining high efficiency in inference. In particular, we achieve 83.7 mIoU % on Cityscape with only fine-annotated data. Code and models are made available to foster any further research (https://github.com/lxtGH/DecoupleSegNets).",
        "date": "2020",
        "authers": [
            "Xiangtai Li",
            "Xia Li",
            "Li Zhang",
            "Guangliang Cheng"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/342537621_Gated_Fully_Fusion_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/329743810_High-Resolution_Image_Synthesis_and_Semantic_Manipulation_with_Conditional_GANs",
            "https://www.researchgate.net/publication/329442528_DenseASPP_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/325718841_PAD-Net_Multi-Tasks_Guided_Prediction-and-Distillation_Network_for_Simultaneous_Depth_Estimation_and_Scene_Parsing",
            "https://www.researchgate.net/publication/321417929_High-Resolution_Image_Synthesis_and_Semantic_Manipulation_with_Conditional_GANs",
            "https://www.researchgate.net/publication/320195152_Learning_Affinity_via_Spatial_Propagation_Networks",
            "https://www.researchgate.net/publication/343465903_Strip_Pooling_Rethinking_Spatial_Pooling_for_Scene_Parsing",
            "https://www.researchgate.net/publication/343461519_Dynamic_Graph_Message_Passing_Networks",
            "https://www.researchgate.net/publication/343454917_Spatial_Pyramid_Based_Graph_Reasoning_for_Semantic_Segmentation"
        ]
    },
    "paper43": {
        "id": "346022004",
        "title": "End-to-End Object Detection with Transformers",
        "abstract": "We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster R-CNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr.",
        "date": "2020",
        "authers": [
            "Nicolas Carion",
            "Francisco Massa",
            "Gabriel Synnaeve",
            "Nicolas Usunier"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/339561869_FCOS_Fully_Convolutional_One-Stage_Object_Detection",
            "https://www.researchgate.net/publication/322057895_DeepSetNet_Predicting_Sets_with_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/321347654_Parallel_WaveNet_Fast_High-Fidelity_Speech_Synthesis",
            "https://www.researchgate.net/publication/310769756_Fully_Convolutional_Instance-aware_Semantic_Segmentation",
            "https://www.researchgate.net/publication/308278279_SSD_Single_Shot_MultiBox_Detector",
            "https://www.researchgate.net/publication/265252627_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate",
            "https://www.researchgate.net/publication/259212328_Scalable_Object_Detection_Using_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/215616968_Understanding_the_difficulty_of_training_deep_feedforward_neural_networks",
            "https://www.researchgate.net/publication/343466724_Bridging_the_Gap_Between_Anchor-Based_and_Anchor-Free_Detection_via_Adaptive_Training_Sample_Selection",
            "https://www.researchgate.net/publication/339562815_Attention_Augmented_Convolutional_Networks"
        ]
    },
    "paper44": {
        "id": "345324756",
        "title": "SegFix Model-Agnostic Boundary Refinement for Segmentation",
        "abstract": "We present a model-agnostic post-processing scheme to improve the boundary quality for the segmentation result that is generated by any existing segmentation model. Motivated by the empirical observation that the label predictions of interior pixels are more reliable, we propose to replace the originally unreliable predictions of boundary pixels by the predictions of interior pixels. Our approach processes only the input image through two steps: (i) localize the boundary pixels and (ii) identify the corresponding interior pixel for each boundary pixel. We build the correspondence by learning a direction away from the boundary pixel to an interior pixel. Our method requires no prior information of the segmentation models and achieves nearly real-time speed. We empirically verify that our SegFix consistently reduces the boundary errors for segmentation results generated from various state-of-the-art models on Cityscapes, ADE20K and GTA5. Code is available at: https://github.com/openseg-group/openseg.pytorch.",
        "date": "2020",
        "authers": [
            "Yuhui Yuan",
            "Jingyi Xie",
            "Xilin Chen",
            "Jingdong Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/338509297_Co-Occurrent_Features_in_Semantic_Segmentation",
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/329743873_Context_Encoding_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/320971612_Richer_Convolutional_Features_for_Edge_Detection",
            "https://www.researchgate.net/publication/320195152_Learning_Affinity_via_Spatial_Propagation_Networks",
            "https://www.researchgate.net/publication/317230093_CASENet_Deep_Category-Aware_Semantic_Edge_Detection",
            "https://www.researchgate.net/publication/314182547_Label_Refinement_Network_for_Coarse-to-Fine_Semantic_Segmentation",
            "https://www.researchgate.net/publication/346770482_Object-Contextual_Representations_for_Semantic_Segmentation"
        ]
    },
    "paper45": {
        "id": "343466461",
        "title": "Learning Dynamic Routing for Semantic Segmentation",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Yanwei Li",
            "Lin Song",
            "Yukang Chen",
            "Zeming Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/338503872_Fast_Neural_Architecture_Search_of_Compact_Semantic_Segmentation_Models_via_Auxiliary_Cells",
            "https://www.researchgate.net/publication/321242021_BlockDrop_Dynamic_Inference_Paths_in_Residual_Networks",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/283471087_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/276923248_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/220659463_The_Pascal_Visual_Object_Classes_VOC_challenge",
            "https://www.researchgate.net/publication/346160386_Single_Path_One-Shot_Neural_Architecture_Search_with_Uniform_Sampling",
            "https://www.researchgate.net/publication/339559337_CCNet_Criss-Cross_Attention_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/339554584_Progressive_Differentiable_Architecture_Search_Bridging_the_Depth_Gap_Between_Search_and_Evaluation"
        ]
    },
    "paper46": {
        "id": "343456450",
        "title": "Joint Semantic Segmentation and Boundary Detection Using Iterative Pyramid Contexts",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Mingmin Zhen",
            "Jinglu Wang",
            "Lei Zhou",
            "Shiwei Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/329743873_Context_Encoding_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329442528_DenseASPP_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/320974965_Gated_Feedback_Refinement_Network_for_Dense_Image_Labeling",
            "https://www.researchgate.net/publication/317230093_CASENet_Deep_Category-Aware_Semantic_Edge_Detection",
            "https://www.researchgate.net/publication/315178093_Holistically-Nested_Edge_Detection",
            "https://www.researchgate.net/publication/311842448_MultiNet_Real-time_Joint_Semantic_Reasoning_for_Autonomous_Driving",
            "https://www.researchgate.net/publication/310610877_RefineNet_Multi-Path_Refinement_Networks_with_Identity_Mappings_for_High-Resolution_Semantic_Segmentation",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better",
            "https://www.researchgate.net/publication/276923248_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation"
        ]
    },
    "paper47": {
        "id": "352224617",
        "title": "Excavating AI the politics of images in machine learning training sets",
        "abstract": "By looking at the politics of classification within machine learning systems, this article demonstrates why the automated interpretation of images is an inherently social and political project. We begin by asking what work images do in computer vision systems, and what is meant by the claim that computers can \u201crecognize\u201d an image? Next, we look at the method for introducing images into computer systems and look at how taxonomies order the foundational concepts that will determine how a system interprets the world. Then we turn to the question of labeling: how humans tell computers which words will relate to a given image. What is at stake in the way AI systems use these labels to classify humans, including by race, gender, emotions, ability, sexuality, and personality? Finally, we turn to the purposes that computer vision is meant to serve in our society\u2014the judgments, choices, and consequences of providing computers with these capacities. Methodologically, we call this an archeology of datasets: studying the material layers of training images and labels, cataloguing the principles and values by which taxonomies are constructed, and analyzing how these taxonomies create the parameters of intelligibility for an AI system. By doing this, we can critically engage with the underlying politics and values of a system, and analyze which normative patterns of life are assumed, supported, and reproduced.",
        "date": "2021AI",
        "authers": [
            "Kate Crawford",
            "Trevor Paglen"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/334512882_Emotional_Expressions_Reconsidered_Challenges_to_Inferring_Emotion_From_Human_Facial_Movements",
            "https://www.researchgate.net/publication/330879115_Unsupervised_by_any_other_name_Hidden_layers_of_knowledge_production_in_artificial_intelligence_on_social_media",
            "https://www.researchgate.net/publication/322877702_Emotion_Fingerprints_or_Emotion_Populations_A_Meta-Analytic_Investigation_of_Autonomic_Features_of_Emotion_Categories",
            "https://www.researchgate.net/publication/329927208_Artificial_Unintelligence_How_Computers_Misunderstand_the_World",
            "https://www.researchgate.net/publication/329748610_Eye_in_the_Sky_Real-Time_Drone_Surveillance_System_DSS_for_Violent_Individuals_Identification_Using_ScatterNet_Hybrid_Deep_Learning_Network",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319394978_Artificial_Intelligence_---_A_Modern_Approach",
            "https://www.researchgate.net/publication/249983357_How_Did_Fear_Become_a_Scientific_Object_and_What_Kind_of_Object_Is_It",
            "https://www.researchgate.net/publication/248819167_The_Body_and_the_Archive",
            "https://www.researchgate.net/publication/247122070_Pattern_Recognition_as_Rule-Guided_Inference"
        ]
    },
    "paper48": {
        "id": "343463185",
        "title": "PULSE Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Sachit Menon",
            "Alexandru Damian",
            "Shijia Hu",
            "Nikhil Ravi"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/345324463_Analyzing_Demographic_Bias_in_Artificially_Generated_Facial_Pictures",
            "https://www.researchgate.net/publication/329748624_FSRNet_End-to-End_Learning_Face_Super-Resolution_with_Facial_Priors",
            "https://www.researchgate.net/publication/329745710_New_Techniques_for_Preserving_Global_Structure_and_Denoising_with_Low_Information_Loss_in_Single-Image_Super-Resolution",
            "https://www.researchgate.net/publication/326723251_To_Learn_Image_Super-Resolution_Use_a_GAN_to_Learn_How_to_Do_Image_Degradation_First",
            "https://www.researchgate.net/publication/321374755_FSRNet_End-to-End_Learning_Face_Super-Resolution_with_Facial_Priors",
            "https://www.researchgate.net/publication/339555522_Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space",
            "https://www.researchgate.net/publication/339483013_FairGAN_Achieving_Fair_Data_Generation_and_Classification_through_Generative_Adversarial_Nets",
            "https://www.researchgate.net/publication/338962150_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks",
            "https://www.researchgate.net/publication/338514531_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks",
            "https://www.researchgate.net/publication/320968363_Photo-Realistic_Single_Image_Super-Resolution_Using_a_Generative_Adversarial_Network"
        ]
    },
    "paper49": {
        "id": "356869040",
        "title": "ObjectNet A large-scale bias-controlled dataset for pushing the limits of object recognition models",
        "abstract": "2019 Neural information processing systems foundation. All rights reserved. We collect a large real-world test set, ObjectNet, for object recognition with controls where object backgrounds, rotations, and imaging viewpoints are random. Most scientific experiments have controls, confounds which are removed from the data, to ensure that subjects cannot perform a task by exploiting trivial correlations in the data. Historically, large machine learning and computer vision datasets have lacked such controls. This has resulted in models that must be fine-tuned for new datasets and perform better on datasets than in real-world applications. When tested on ObjectNet, object detectors show a 40-45% drop in performance, with respect to their performance on other benchmarks, due to the controls for biases. Controls make ObjectNet robust to fine-tuning showing only small performance increases. We develop a highly automated platform that enables gathering datasets with controls by crowdsourcing image capturing and annotation. ObjectNet is the same size as the ImageNet test set (50,000 images), and by design does not come paired with a training set in order to encourage generalization. The dataset is both easier than ImageNet - objects are largely centered and unoccluded - and harder, due to the controls. Although we focus on object recognition here, data with controls can be gathered at scale using automated tools throughout machine learning to generate datasets that exercise models in new ways thus providing valuable feedback to researchers. This work opens up new avenues for research in generalizable, robust, and more human-like computer vision and in creating datasets where results are predictive of real-world performance.",
        "date": "2019",
        "authers": [
            "A Barbu",
            "D Mayo",
            "J Alverio",
            "W Luo"
        ],
        "refrences": []
    },
    "paper50": {
        "id": "355882923",
        "title": "Exploring Simple Siamese Representation Learning",
        "abstract": "",
        "date": "2021",
        "authers": [
            "Xinlei Chen",
            "Kaiming He"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/309640954_Fully-Convolutional_Siamese_Networks_for_Object_Tracking",
            "https://www.researchgate.net/publication/306187421_SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts",
            "https://www.researchgate.net/publication/221620245_Signature_Verification_Using_a_Siamese_Time_Delay_Neural_Network",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/4246277_Dimensionality_Reduction_by_Learning_an_Invariant_Mapping",
            "https://www.researchgate.net/publication/343456678_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning",
            "https://www.researchgate.net/publication/339559093_Unsupervised_Pre-Training_of_Image_Features_on_Non-Curated_Data",
            "https://www.researchgate.net/publication/338503604_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature",
            "https://www.researchgate.net/publication/329743791_Unsupervised_Feature_Learning_via_Non-parametric_Instance_Discrimination",
            "https://www.researchgate.net/publication/315454672_Mask_R-CNN"
        ]
    },
    "paper51": {
        "id": "355882623",
        "title": "Propagate Yourself Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning",
        "abstract": "",
        "date": "2021",
        "authers": [
            "Zhenda Xie",
            "Yutong Lin",
            "Zheng Zhang",
            "Yue Cao"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/339561869_FCOS_Fully_Convolutional_One-Stage_Object_Detection",
            "https://www.researchgate.net/publication/323931846_Unsupervised_Representation_Learning_by_Predicting_Image_Rotations",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/301837491_Unsupervised_Learning_of_Visual_Representations_by_Solving_Jigsaw_Puzzles",
            "https://www.researchgate.net/publication/277023095_Unsupervised_Visual_Representation_Learning_by_Context_Prediction",
            "https://www.researchgate.net/publication/263471626_Discriminative_Unsupervised_Feature_Learning_with_Exemplar_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/339555805_Local_Aggregation_for_Unsupervised_Learning_of_Visual_Embeddings",
            "https://www.researchgate.net/publication/338503604_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature",
            "https://www.researchgate.net/publication/329743791_Unsupervised_Feature_Learning_via_Non-parametric_Instance_Discrimination"
        ]
    },
    "paper52": {
        "id": "352398842",
        "title": "Large image datasets A pyrrhic win for computer vision",
        "abstract": "",
        "date": "2021",
        "authers": [
            "Abeba Birhane",
            "Vinay Uday Prabhu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/343463185_PULSE_Self-Supervised_Photo_Upsampling_via_Latent_Space_Exploration_of_Generative_Models",
            "https://www.researchgate.net/publication/334634583_Estimating_the_success_of_re-identifications_in_incomplete_datasets_using_generative_models",
            "https://www.researchgate.net/publication/333332997_Translating_Principles_into_Practices_of_Digital_Ethics_Five_Risks_of_Being_Unethical",
            "https://www.researchgate.net/publication/322674945_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition",
            "https://www.researchgate.net/publication/318337409_Revisiting_Unreasonable_Effectiveness_of_Data_in_Deep_Learning_Era",
            "https://www.researchgate.net/publication/314285557_Beyond_'Revenge_Porn'_The_Continuum_of_Image-Based_Sexual_Abuse",
            "https://www.researchgate.net/publication/306023833_Deep_Expectation_of_Real_and_Apparent_Age_from_a_Single_Image_Without_Facial_Landmarks",
            "https://www.researchgate.net/publication/302515980_How_Masculine_Is_a_Flute_A_Replication_Study_on_Gender_Stereotypes_and_Preferences_for_Musical_Instruments_among_Young_Children",
            "https://www.researchgate.net/publication/284576917_Glove_Global_Vectors_for_Word_Representation",
            "https://www.researchgate.net/publication/271196763_Unequal_Representation_and_Gender_Stereotypes_in_Image_Search_Results_for_Occupations"
        ]
    },
    "paper53": {
        "id": "347459139",
        "title": "Towards fairer datasets filtering and balancing the distribution of the people subtree in the ImageNet hierarchy",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Kaiyu Yang",
            "Klint Qinami",
            "Li Fei-Fei",
            "Jia Deng"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322587393_Men_Also_Like_Shopping_Reducing_Gender_Bias_Amplification_using_Corpus-level_Constraints",
            "https://www.researchgate.net/publication/315818258_Valence_arousal_familiarity_concreteness_and_imageability_ratings_for_292_two-character_Chinese_nouns_in_Cantonese_speakers_in_Hong_Kong",
            "https://www.researchgate.net/publication/307747289_Show_and_tell_A_neural_image_caption_generator",
            "https://www.researchgate.net/publication/307473328_What_makes_ImageNet_good_for_transfer_learning",
            "https://www.researchgate.net/publication/303545933_When_corporations_come_to_define_the_visual_politics_of_gender_The_case_of_Getty_Images",
            "https://www.researchgate.net/publication/301844872_Visual_Genome_Connecting_Language_and_Vision_Using_Crowdsourced_Dense_Image_Annotations",
            "https://www.researchgate.net/publication/295853816_Thirty_shades_of_offensiveness_L1_and_LX_English_users'_understanding_perception_and_self-reported_use_of_negative_emotion-laden_words",
            "https://www.researchgate.net/publication/284219429_Censoring_Representations_with_an_Adversary",
            "https://www.researchgate.net/publication/280530043_Pushing_the_Frontiers_of_Unconstrained_Face_Detection_and_Recognition_IARPA_Janus_Benchmark_A",
            "https://www.researchgate.net/publication/271196763_Unequal_Representation_and_Gender_Stereotypes_in_Image_Search_Results_for_Occupations"
        ]
    },
    "paper54": {
        "id": "344753035",
        "title": "Between Subjectivity and Imposition Power Dynamics in Data Annotation for Computer Vision",
        "abstract": "The interpretation of data is fundamental to machine learning. This paper investigates practices of image data annotation as performed in industrial contexts. We define data annotation as a sense-making practice, where annotators assign meaning to data through the use of labels. Previous human-centered investigations have largely focused on annotators? subjectivity as a major cause of biased labels. We propose a wider view on this issue: guided by constructivist grounded theory, we conducted several weeks of fieldwork at two annotation companies. We analyzed which structures, power relations, and naturalized impositions shape the interpretation of data. Our results show that the work of annotators is profoundly informed by the interests, values, and priorities of other actors above their station. Arbitrary classifications are vertically imposed on annotators, and through them, on data. This imposition is largely naturalized. Assigning meaning to data is often presented as a technical matter. This paper shows it is, in fact, an exercise of power with multiple implications for individuals and society.",
        "date": "2020Proceedings",
        "authers": [
            "Milagros Miceli",
            "Martin Schuessler",
            "Tianling Yang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/341693469_Co-Designing_Checklists_to_Understand_Organizational_Challenges_and_Opportunities_around_Fairness_in_AI",
            "https://www.researchgate.net/publication/338403092_Biased_Priorities_Biased_Outcomes_Three_Recommendations_for_Ethics-oriented_Data_Annotation_Practices",
            "https://www.researchgate.net/publication/332748249_How_Data_Science_Workers_Work_with_Data_Discovery_Capture_Curation_Design_Creation",
            "https://www.researchgate.net/publication/329990585_Understanding_and_Mitigating_Worker_Biases_in_the_Crowdsourced_Collection_of_Subjective_Judgments",
            "https://www.researchgate.net/publication/325594485_Baselines_and_a_datasheet_for_the_Cerema_AWP_dataset",
            "https://www.researchgate.net/publication/324670607_Gender_Recognition_or_Gender_Reductionism_The_Social_Implications_of_Embedded_Gender_Recognition_Systems",
            "https://www.researchgate.net/publication/317888465_Networked_Employment_Discrimination",
            "https://www.researchgate.net/publication/297664844_Thinking_critically_about_and_researching_algorithms",
            "https://www.researchgate.net/publication/288669223_The_Politics_of_Measurement_and_Action",
            "https://www.researchgate.net/publication/271647061_Leveraging_In-Batch_Annotation_Bias_for_Crowdsourced_Active_Learning"
        ]
    },
    "paper55": {
        "id": "343465745",
        "title": "Self-Supervised Learning of Pretext-Invariant Representations",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Ishan Misra",
            "Laurens van der Maaten"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/339768441_Video_Representation_Learning_by_Dense_Predictive_Coding",
            "https://www.researchgate.net/publication/329750748_Improvements_to_Context_Based_Self-Supervised_Learning",
            "https://www.researchgate.net/publication/323931846_Unsupervised_Representation_Learning_by_Predicting_Image_Rotations",
            "https://www.researchgate.net/publication/318337409_Revisiting_Unreasonable_Effectiveness_of_Data_in_Deep_Learning_Era",
            "https://www.researchgate.net/publication/316098571_Virtual_Adversarial_Training_A_Regularization_Method_for_Supervised_and_Semi-Supervised_Learning",
            "https://www.researchgate.net/publication/315747848_Self-Supervised_Video_Representation_Learning_With_Odd-One-Out_Networks",
            "https://www.researchgate.net/publication/312492399_Adversarial_Variational_Bayes_Unifying_Variational_Autoencoders_and_Generative_Adversarial_Networks",
            "https://www.researchgate.net/publication/308295512_Ambient_Sound_Provides_Supervision_for_Visual_Learning",
            "https://www.researchgate.net/publication/306187421_SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts",
            "https://www.researchgate.net/publication/343456678_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning"
        ]
    },
    "paper56": {
        "id": "343461321",
        "title": "Learning Representations by Predicting Bags of Visual Words",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Spyros Gidaris",
            "Andrei Bursuc",
            "Nikos Komodakis",
            "Patrick Perez"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/339555791_How_Do_Neural_Networks_See_Depth_in_Single_Images",
            "https://www.researchgate.net/publication/323931846_Unsupervised_Representation_Learning_by_Predicting_Image_Rotations",
            "https://www.researchgate.net/publication/308295512_Ambient_Sound_Provides_Supervision_for_Visual_Learning",
            "https://www.researchgate.net/publication/305881526_Matching_Networks_for_One_Shot_Learning",
            "https://www.researchgate.net/publication/301837491_Unsupervised_Learning_of_Visual_Representations_by_Solving_Jigsaw_Puzzles",
            "https://www.researchgate.net/publication/279839496_Learning_Deep_Features_for_Scene_Recognition_using_Places_Database",
            "https://www.researchgate.net/publication/279068396_Skip-Thought_Vectors",
            "https://www.researchgate.net/publication/277023095_Unsupervised_Visual_Representation_Learning_by_Context_Prediction",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/263471626_Discriminative_Unsupervised_Feature_Learning_with_Exemplar_Convolutional_Neural_Networks"
        ]
    },
    "paper57": {
        "id": "334116365",
        "title": "Universal Language Model Fine-tuning for Text Classification",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Jeremy Howard",
            "Sebastian Ruder"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/320920333_GradNorm_Gradient_Normalization_for_Adaptive_Loss_Balancing_in_Deep_Multitask_Networks",
            "https://www.researchgate.net/publication/328159324_Exploring_the_Limits_of_Weakly_Supervised_Pretraining_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_II",
            "https://www.researchgate.net/publication/325448855_Colorless_Green_Recurrent_Networks_Dream_Hierarchically",
            "https://www.researchgate.net/publication/322590138_Supervised_Learning_of_Universal_Sentence_Representations_from_Natural_Language_Inference_Data",
            "https://www.researchgate.net/publication/322582488_Using_millions_of_emoji_occurrences_to_learn_any-domain_representations_for_detecting_sentiment_emotion_and_sarcasm",
            "https://www.researchgate.net/publication/319770381_How_transferable_are_features_in_deep_neural_networks",
            "https://www.researchgate.net/publication/319770369_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/319770231_Pointer_Sentinel_Mixture_Models",
            "https://www.researchgate.net/publication/318849650_Learned_in_Translation_Contextualized_Word_Vectors"
        ]
    },
    "paper58": {
        "id": "304506026",
        "title": "Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units",
        "abstract": "We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic process which randomly applies the identity or zero map, combining the intuitions of dropout and zoneout while respecting neuron values. This connection suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks.",
        "date": "2016",
        "authers": [
            "Dan Hendrycks",
            "Kevin Gimpel"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/332717934_A_Simple_Approximation_to_the_Area_Under_Standard_Normal_Curve",
            "https://www.researchgate.net/publication/319770320_Zoneout_Regularizing_RNNs_by_Randomly_Preserving_Hidden_Activations",
            "https://www.researchgate.net/publication/319769813_Fast_and_Accurate_Deep_Network_Learning_by_Exponential_Linear_Units_ELUs",
            "https://www.researchgate.net/publication/305119419_Generalizing_and_Improving_Weight_Initialization",
            "https://www.researchgate.net/publication/303821573_Zoneout_Regularizing_RNNs_by_Randomly_Preserving_Hidden_Activations",
            "https://www.researchgate.net/publication/303409435_Residual_Networks_Behave_Like_Ensembles_of_Relatively_Shallow_Networks",
            "https://www.researchgate.net/publication/301879329_Deep_Networks_with_Stochastic_Depth",
            "https://www.researchgate.net/publication/284579051_Fast_and_Accurate_Deep_Network_Learning_by_Exponential_Linear_Units_ELUs",
            "https://www.researchgate.net/publication/319770257_Exact_solutions_to_the_nonlinear_dynamics_of_learning_in_deep_linear_neural_networks",
            "https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting"
        ]
    },
    "paper59": {
        "id": "304018244",
        "title": "SQuAD 100000 Questions for Machine Comprehension of Text",
        "abstract": "We present a new reading comprehension dataset, SQuAD, consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset in both manual and automatic ways to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We built a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research.",
        "date": "2016",
        "authers": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/301404923_Machine_Comprehension_with_Syntax_Frames_and_Semantics",
            "https://www.researchgate.net/publication/319770348_Teaching_Machines_to_Read_and_Comprehend",
            "https://www.researchgate.net/publication/318497709_My_Computer_Is_an_Honor_Student_-_but_How_Intelligent_Is_It_Standardized_Tests_as_a_Measure_of_AI",
            "https://www.researchgate.net/publication/312607081_Building_a_large_annotated_corpus_of_english_The_penn_treebank",
            "https://www.researchgate.net/publication/309438804_N-gram_IDF_A_Global_Term_Weighting_Scheme_Based_on_Information_Distance",
            "https://www.researchgate.net/publication/306094228_A_Thorough_Examination_of_the_CNNDaily_Mail_Reading_Comprehension_Task",
            "https://www.researchgate.net/publication/301445887_WikiQA_A_Challenge_Dataset_for_Open-Domain_Question_Answering",
            "https://www.researchgate.net/publication/301405087_Learning_to_Solve_Arithmetic_Word_Problems_with_Verb_Categorization",
            "https://www.researchgate.net/publication/301404907_Modeling_Biological_Processes_for_Reading_Comprehension",
            "https://www.researchgate.net/publication/301404729_Learning_Answer-Entailing_Structures_for_Machine_Comprehension"
        ]
    },
    "paper60": {
        "id": "284576917",
        "title": "Glove Global Vectors for Word Representation",
        "abstract": "",
        "date": "2014",
        "authers": [
            "Jeffrey Pennington",
            "Richard Socher",
            "Christopher D. Manning"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/314818211_Quantitative_evaluation_of_passage_retrieval_algorithms_for_question_answering",
            "https://www.researchgate.net/publication/301408902_Linguistic_Regularities_in_Sparse_and_Explicit_Word_Representations",
            "https://www.researchgate.net/publication/289176734_Word_Embeddings_through_Hellinger_PCA",
            "https://www.researchgate.net/publication/285896121_Learning_word_embeddings_efficiently_with_noise-contrastive_estimation",
            "https://www.researchgate.net/publication/285895924_Linguistic_regularities_in_continuous_space_word_representations",
            "https://www.researchgate.net/publication/270878536_Better_Word_Representations_with_Recursive_Neural_Networks_for_Morphology",
            "https://www.researchgate.net/publication/270878508_Parsing_with_Compositional_Vector_Grammars",
            "https://www.researchgate.net/publication/270877599_Don't_count_predict_A_systematic_comparison_of_context-counting_vs_context-predicting_semantic_vectors",
            "https://www.researchgate.net/publication/267709055_Deep_Neural_Networks_Segment_Neuronal_Membranes_in_Electron_Microscopy_Images"
        ]
    },
    "paper61": {
        "id": "279068396",
        "title": "Skip-Thought Vectors",
        "abstract": "We describe an approach for unsupervised learning of a generic, distributed\nsentence encoder. Using the continuity of text from books, we train an\nencoder-decoder model that tries to reconstruct the surrounding sentences of an\nencoded passage. Sentences that share semantic and syntactic properties are\nthus mapped to similar vector representations. We next introduce a simple\nvocabulary expansion method to encode words that were not seen as part of\ntraining, allowing us to expand our vocabulary to a million words. After\ntraining our model, we extract and evaluate our vectors with linear models on 8\ntasks: semantic relatedness, paraphrase detection, image-sentence ranking,\nquestion-type classification and 4 benchmark sentiment and subjectivity\ndatasets. The end result is an off-the-shelf encoder that can produce highly\ngeneric sentence representations that are robust and perform well in practice.\nWe will make our encoder publicly available.",
        "date": "2015Advances",
        "authers": [
            "Ryan Kiros",
            "Yukun Zhu",
            "Ruslan R. Salakhutdinov",
            "Richard Zemel"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/329975395_Grounded_Compositional_Semantics_for_Finding_and_Describing_Images_with_Sentences",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/319770257_Exact_solutions_to_the_nonlinear_dynamics_of_learning_in_deep_linear_neural_networks",
            "https://www.researchgate.net/publication/319770249_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions",
            "https://www.researchgate.net/publication/308837339_Associating_neural_word_embeddings_with_deep_image_representations_using_Fisher_Vectors",
            "https://www.researchgate.net/publication/301409028_ECNU_One_Stone_Two_Birds_Ensemble_of_Heterogenous_Measures_for_Semantic_Relatedness_and_Textual_Entailment",
            "https://www.researchgate.net/publication/301408986_Illinois-LH_A_Denotational_and_Distributional_Approach_to_Semantics",
            "https://www.researchgate.net/publication/289758666_Recurrent_continuous_translation_models",
            "https://www.researchgate.net/publication/284039049_Recursive_deep_models_for_semantic_compositionality_over_a_sentiment_treebank"
        ]
    },
    "paper62": {
        "id": "268079628",
        "title": "How transferable are features in deep neural networks",
        "abstract": "Many deep neural networks trained on natural images exhibit a curious\nphenomenon in common: on the first layer they learn features similar to Gabor\nfilters and color blobs. Such first-layer features appear not to be specific to\na particular dataset or task, but general in that they are applicable to many\ndatasets and tasks. Features must eventually transition from general to\nspecific by the last layer of the network, but this transition has not been\nstudied extensively. In this paper we experimentally quantify the generality\nversus specificity of neurons in each layer of a deep convolutional neural\nnetwork and report a few surprising results. Transferability is negatively\naffected by two distinct issues: (1) the specialization of higher layer neurons\nto their original task at the expense of performance on the target task, which\nwas expected, and (2) optimization difficulties related to splitting networks\nbetween co-adapted neurons, which was not expected. In an example network\ntrained on ImageNet, we demonstrate that either of these two issues may\ndominate, depending on whether features are transferred from the bottom,\nmiddle, or top of the network. We also document that the transferability of\nfeatures decreases as the distance between the base task and target task\nincreases, but that transferring features even from distant tasks can be better\nthan using random features. A final surprising result is that initializing a\nnetwork with transferred features from almost any number of layers can produce\na boost to generalization that lingers even after fine-tuning to the target\ndataset.",
        "date": "2014Advances",
        "authers": [
            "Jason Yosinski",
            "Jeff Clune",
            "Y. Bengio",
            "Hod Lipson"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/283601334_Deep_learning_of_representations_for_unsupervised_and_transfer_learning",
            "https://www.researchgate.net/publication/268265707_ICA_with_Reconstruction_Cost_for_Efficient_Overcomplete_Feature_Learning",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/258374356_Rich_Feature_Hierarchies_for_Accurate_Object_Detection_and_Semantic_Segmentation"
        ]
    },
    "paper63": {
        "id": "259239818",
        "title": "One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling",
        "abstract": "We propose a new benchmark corpus to be used for measuring progress in\nstatistical language modeling. With almost one billion words of training data,\nwe hope this benchmark will be useful to quickly evaluate novel language\nmodeling techniques, and to compare their contribution when combined with other\nadvanced techniques. We show performance of several well-known types of\nlanguage models, with the best results achieved with a recurrent neural network\nbased language model. The baseline unpruned Kneser-Ney 5-gram model achieves\nperplexity 74.4. A combination of techniques leads to 37% reduction in\nperplexity, or 11% reduction in cross-entropy (bits), over that baseline.\nThe benchmark is available as a code.google.com project; besides the scripts\nneeded to rebuild the training/held-out data, it also makes available\nlog-probability values for each word in each of ten held-out data sets, for\neach of the baseline n-gram models.",
        "date": "2013",
        "authers": [
            "Ciprian Chelba",
            "Tomas Mikolov",
            "Mike Schuster",
            "Qi Ge"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/241637478_Strategies_for_training_large_scale_neural_network_language_models",
            "https://www.researchgate.net/publication/228348202_Hierarchical_probabilistic_neural_network_language_model",
            "https://www.researchgate.net/publication/224246503_Extensions_of_recurrent_neural_network_language_model",
            "https://www.researchgate.net/publication/307174896_An_Empirical_Study_of_Smoothing_Techniques_for_Language_Modeling",
            "https://www.researchgate.net/publication/288345724_Class-based_n-gram_models_of_natural_language",
            "https://www.researchgate.net/publication/270878020_Factored_Language_Model_based_on_Recurrent_Neural_Network",
            "https://www.researchgate.net/publication/266458936_Statistical_Language_Models_Based_on_Neural_Networks",
            "https://www.researchgate.net/publication/261167314_Speed_regularization_and_optimality_in_word_classing",
            "https://www.researchgate.net/publication/242821088_A_Maximum_Entropy_approach_to_adaptive_statistical_language_modeling",
            "https://www.researchgate.net/publication/222800591_Structured_language_modeling"
        ]
    },
    "paper64": {
        "id": "257882504",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "abstract": "The recently introduced continuous Skip-gram model is an efficient method for\nlearning high-quality distributed vector representations that capture a large\nnumber of precise syntactic and semantic word relationships. In this paper we\npresent several extensions that improve both the quality of the vectors and the\ntraining speed. By subsampling of the frequent words we obtain significant\nspeedup and also learn more regular word representations. We also describe a\nsimple alternative to the hierarchical softmax called negative sampling. An\ninherent limitation of word representations is their indifference to word order\nand their inability to represent idiomatic phrases. For example, the meanings\nof \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\".\nMotivated by this example, we present a simple method for finding phrases in\ntext, and show that learning good vector representations for millions of\nphrases is possible.",
        "date": "2013Advances",
        "authers": [
            "Tomas Mikolov",
            "Ilya Sutskever",
            "Kai Chen",
            "G.s. Corrado"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/258082321_Distributional_Semantics_Beyond_Words_Supervised_Learning_of_Analogy_and_Paraphrase",
            "https://www.researchgate.net/publication/241637478_Strategies_for_training_large_scale_neural_network_language_models",
            "https://www.researchgate.net/publication/234131319_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/228348202_Hierarchical_probabilistic_neural_network_language_model",
            "https://www.researchgate.net/publication/285895924_Linguistic_regularities_in_continuous_space_word_representations",
            "https://www.researchgate.net/publication/266458936_Statistical_Language_Models_Based_on_Neural_Networks",
            "https://www.researchgate.net/publication/262367926_Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces",
            "https://www.researchgate.net/publication/229091480_Learning_Representations_by_Back_Propagating_Errors",
            "https://www.researchgate.net/publication/228095628_A_Fast_and_Simple_Algorithm_for_Training_Neural_Probabilistic_LanguageModels",
            "https://www.researchgate.net/publication/225818196_Neural_Probabilistic_Language_Models"
        ]
    },
    "paper65": {
        "id": "221361415",
        "title": "ImageNet a Large-Scale Hierarchical Image Database",
        "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ldquoImageNetrdquo, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.",
        "date": "2009Proceedings",
        "authers": [
            "Jia Deng",
            "Wei Dong",
            "Richard Socher",
            "Li-Jia Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/277292831_The_2005_pascal_visual_object_classes_challenge",
            "https://www.researchgate.net/publication/238347229_The_Pascal_Visual_Object_Classes_Challenge_2006_VOC2006_Results",
            "https://www.researchgate.net/publication/313527089_Distinctive_image_features_from_scale-invariant_key_points",
            "https://www.researchgate.net/publication/312457795_Semantic_hierarchies_for_visual_object_recognition",
            "https://www.researchgate.net/publication/269953350_WordNet_An_Electronic_Lexical_Database",
            "https://www.researchgate.net/publication/242442798_Principles_of_Categorization",
            "https://www.researchgate.net/publication/239443282_Robust_Scalable_Recognition_with_a_Vocabulary_Tree",
            "https://www.researchgate.net/publication/233710354_The_FERET_database_and_evaluation_procedure_for_face-recognition_algorithms",
            "https://www.researchgate.net/publication/232630154_Learning_Object_Categories_from_Googles_Image_Search",
            "https://www.researchgate.net/publication/230854795_WordNet_-_An_Electronical_Lexical_Database"
        ]
    },
    "paper66": {
        "id": "221346269",
        "title": "Extracting and composing robust features with denoising autoencoders",
        "abstract": "Previous work has shown that the dicul- ties in learning deep generative or discrim- inative models can be overcome by an ini- tial unsupervised learning step that maps in- puts to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a rep- resentation based on the idea of making the learned representations robust to partial cor- ruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to ini- tialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising ad- vantage of corrupting the input of autoen- coders on a pattern classification benchmark suite.",
        "date": "2008",
        "authers": [
            "Pascal Vincent",
            "Hugo Larochelle",
            "Y. Bengio",
            "Pierre-Antoine Manzagol"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/221620372_A_Theoretical_Analysis_of_Robust_Coding_over_Noisy_Overcomplete_Channels",
            "https://www.researchgate.net/publication/221617957_A_Theory_of_Retinal_Population_Coding",
            "https://www.researchgate.net/publication/221364240_Fields_of_Experts_A_Framework_for_Learning_Image_Priors",
            "https://www.researchgate.net/publication/312451443_Efficient_learning_of_sparse_representations_with_an_energy-based_model",
            "https://www.researchgate.net/publication/292215395_Neural_networks_and_physical_systems_with_emergent_collective_computational_abilities",
            "https://www.researchgate.net/publication/239566324_Non-linear_latent_factor_models_for_revealing_structure_in_high-dimensional_data",
            "https://www.researchgate.net/publication/237044580_Parallel_Distributed_Processing_Explorations_in_the_Microstructure_of_Cognition",
            "https://www.researchgate.net/publication/230876626_Parallel_Distributed_Processing_Explorations_in_the_Microstructures_of_Cognition",
            "https://www.researchgate.net/publication/222438607_Connectionist_Learning_Procedures"
        ]
    },
    "paper67": {
        "id": "343466387",
        "title": "Self-Training With Noisy Student Improves ImageNet Classification",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Qizhe Xie",
            "Minh-Thang Luong",
            "Eduard Hovy",
            "Quoc V. Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/334843952_Interpolation_Consistency_Training_for_Semi-supervised_Learning",
            "https://www.researchgate.net/publication/332069196_Born_Again_Neural_Networks",
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/318392350_Adversarial_Dropout_for_Supervised_and_Semi-supervised_Learning",
            "https://www.researchgate.net/publication/316098571_Virtual_Adversarial_Training_A_Regularization_Method_for_Supervised_and_Semi-Supervised_Learning",
            "https://www.researchgate.net/publication/313481233_Semi-Supervised_QA_with_Generative_Domain-Adaptive_Nets",
            "https://www.researchgate.net/publication/310462326_PolyNet_A_Pursuit_of_Structural_Diversity_in_Very_Deep_Networks",
            "https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth",
            "https://www.researchgate.net/publication/305881127_Improved_Techniques_for_Training_GANs",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions"
        ]
    },
    "paper68": {
        "id": "343466025",
        "title": "Exploring Self-Attention for Image Recognition",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Hengshuang Zhao",
            "Jiaya Jia",
            "Vladlen Koltun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/316450913_Residual_Attention_Network_for_Image_Classification",
            "https://www.researchgate.net/publication/308278279_SSD_Single_Shot_MultiBox_Detector",
            "https://www.researchgate.net/publication/306187421_SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/303698513_Dynamic_Filter_Networks",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/283659096_Stacked_Attention_Networks_for_Image_Question_Answering",
            "https://www.researchgate.net/publication/272194766_Show_Attend_and_Tell_Neural_Image_Caption_Generation_with_Visual_Attention",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge"
        ]
    },
    "paper69": {
        "id": "343298597",
        "title": "Quantifying Attention Flow in Transformers",
        "abstract": "",
        "date": "2020",
        "authers": [
            "Samira Abnar",
            "Willem Zuidema"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/311990858_Attention-based_LSTM_for_Aspect-level_Sentiment_Classification",
            "https://www.researchgate.net/publication/343299346_Learning_to_Deceive_with_Attention-Based_Explanations",
            "https://www.researchgate.net/publication/336999161_Attention_is_not_not_Explanation",
            "https://www.researchgate.net/publication/335780510_Is_Attention_Interpretable",
            "https://www.researchgate.net/publication/335778955_What_Does_BERT_Look_at_An_Analysis_of_BERT's_Attention",
            "https://www.researchgate.net/publication/334116956_GLUE_A_Multi-Task_Benchmark_and_Analysis_Platform_for_Natural_Language_Understanding",
            "https://www.researchgate.net/publication/322583071_Interactive_Visualization_and_Manipulation_of_Attention-based_Neural_Machine_Translation",
            "https://www.researchgate.net/publication/317558625_Attention_Is_All_You_Need",
            "https://www.researchgate.net/publication/309729965_Assessing_the_Ability_of_LSTMs_to_Learn_Syntax-Sensitive_Dependencies"
        ]
    },
    "paper70": {
        "id": "339562815",
        "title": "Attention Augmented Convolutional Networks",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Irwan Bello",
            "Barret Zoph",
            "Quoc Le",
            "Ashish Vaswani"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/311223153_Speedaccuracy_trade-offs_for_modern_convolutional_object_detectors",
            "https://www.researchgate.net/publication/306187421_SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/265252627_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/221110516_Objects_in_Context",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition",
            "https://www.researchgate.net/publication/338511824_AutoAugment_Learning_Augmentation_Strategies_From_Data",
            "https://www.researchgate.net/publication/338510249_MnasNet_Platform-Aware_Neural_Architecture_Search_for_Mobile"
        ]
    },
    "paper71": {
        "id": "339562468",
        "title": "S4L Self-Supervised Semi-Supervised Learning",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Lucas Beyer",
            "Xiaohua Zhai",
            "Avital Oliver",
            "Alexander Kolesnikov"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/334843952_Interpolation_Consistency_Training_for_Semi-supervised_Learning",
            "https://www.researchgate.net/publication/323931846_Unsupervised_Representation_Learning_by_Predicting_Image_Rotations",
            "https://www.researchgate.net/publication/323411512_A_DIRT-T_Approach_to_Unsupervised_Domain_Adaptation",
            "https://www.researchgate.net/publication/316098571_Virtual_Adversarial_Training_A_Regularization_Method_for_Supervised_and_Semi-Supervised_Learning",
            "https://www.researchgate.net/publication/308716468_Variational_Autoencoder_for_Deep_Learning_of_Images_Labels_and_Captions",
            "https://www.researchgate.net/publication/305881127_Improved_Techniques_for_Training_GANs",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/301837491_Unsupervised_Learning_of_Visual_Representations_by_Solving_Jigsaw_Puzzles",
            "https://www.researchgate.net/publication/280581078_Pseudo-Label_The_Simple_and_Efficient_Semi-Supervised_Learning_Method_for_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/279968088_Semi-Supervised_Learning_with_Ladder_Network"
        ]
    },
    "paper72": {
        "id": "306094026",
        "title": "A Fast Unified Model for Parsing and Sentence Understanding",
        "abstract": "Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suffer from two key technical problems that make them slow and unwieldy for large-scale NLP tasks: they can only operate on parsed sentences and they do not directly support batched computation. We address these issues by introducing the Stack-augmented Parser-Interpreter Neural Network (SPINN), which combines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shift-reduce parser. Our model supports batched computation for a speedup of up to 25x over other tree-structured models, and its integrated parser allows it to operate on unparsed data with little loss of accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models.",
        "date": "2016",
        "authers": [
            "Samuel R. Bowman",
            "Jon Gauthier",
            "Abhinav Rastogi",
            "Raghav Gupta"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305334466_Recurrent_Neural_Network_Grammars",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770245_Order-Embeddings_of_Images_and_Language",
            "https://www.researchgate.net/publication/312416396_Long_Short-Term_Memory-Networks_for_Machine_Reading",
            "https://www.researchgate.net/publication/305334471_Top-down_Tree_Long_Short-Term_Memory_Networks",
            "https://www.researchgate.net/publication/305334400_Learning_Natural_Language_Inference_with_LSTM",
            "https://www.researchgate.net/publication/301880883_Long_Short-Term_Memory-Networks_for_Machine_Reading",
            "https://www.researchgate.net/publication/301841091_Easy-First_Dependency_Parsing_with_Hierarchical_Tree_LSTMs",
            "https://www.researchgate.net/publication/299487682_A_Fast_and_Accurate_Dependency_Parser_using_Neural_Networks"
        ]
    },
    "paper73": {
        "id": "283865501",
        "title": "Feature Optimization for Constituent Parsing via Neural Networks",
        "abstract": "The performance of discriminative constituent parsing relies crucially on feature engineering, and effective features usually have to be carefully selected through a painful manual process. In this paper, we propose to automatically learn a set of effective features via neural networks. Specifically, we build a feedforward neural network model, which takes as input a few primitive units (words, POS tags and certain contextual tokens) from the local context, induces the feature representation in the hidden layer and makes parsing predictions in the output layer. The network simultaneously learns the feature representation and the prediction model parameters using a back propagation algorithm. By pre-Training the model on a large amount of automatically parsed data, and then fine-Tuning on the manually annotated Treebank data, our parser achieves the highest F1 score at 86.6% on Chinese Treebank 5.1, and a competitive F1 score at 90.7% on English Treebank. More importantly, our parser generalizes well on cross-domain test sets, where we significantly outperform Berkeley arser by 3.4 points on average for Chinese and 2.5 points for English.",
        "date": "2015",
        "authers": [
            "Zhiguo Wang",
            "Haitao Mi",
            "Nianwen Xue"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/270878092_Joint_POS_Tagging_and_Transition-based_Constituent_Parsing_in_Chinese_with_Non-local_Features",
            "https://www.researchgate.net/publication/270818464_Automatic_Feature_Selection_for_Agenda-Based_Dependency_Parsing",
            "https://www.researchgate.net/publication/266376373_Fast_and_Accurate_Shift-Reduce_Constituent_Parsing",
            "https://www.researchgate.net/publication/312607081_Building_a_large_annotated_corpus_of_english_The_penn_treebank",
            "https://www.researchgate.net/publication/304533937_Learning_representations_by_back_propagating_errors_Cogn",
            "https://www.researchgate.net/publication/299487682_A_Fast_and_Accurate_Dependency_Parser_using_Neural_Networks",
            "https://www.researchgate.net/publication/271231477_Phrase_Parses_Reranking_Based_on_Higher-Order_Lexical_Dependencies",
            "https://www.researchgate.net/publication/270878508_Parsing_with_Compositional_Vector_Grammars",
            "https://www.researchgate.net/publication/270877743_Low-Rank_Tensors_for_Scoring_Dependency_Structures",
            "https://www.researchgate.net/publication/269997813_Grammar_as_a_Foreign_Language"
        ]
    },
    "paper74": {
        "id": "278965988",
        "title": "Transition-Based Dependency Parsing with Stack Long Short-Term Memory",
        "abstract": "",
        "date": "2015",
        "authers": [
            "Chris Dyer",
            "Miguel Ballesteros",
            "Wang Ling",
            "Austin Matthews"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/289176638_The_Inside-Outside_Recursive_Neural_Network_model_for_Dependency_Parsing",
            "https://www.researchgate.net/publication/281812760_TwoToo_Simple_Adaptations_of_Word2Vec_for_Syntax_Problems",
            "https://www.researchgate.net/publication/279068962_Structured_Training_for_Neural_Network_Transition-Based_Parsing",
            "https://www.researchgate.net/publication/329975395_Grounded_Compositional_Semantics_for_Finding_and_Describing_Images_with_Sentences",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770387_Deep_Sparse_Rectifier_Neural_Networks",
            "https://www.researchgate.net/publication/307955489_Distributed_representations_of_words_and_phrases_and_their_compositionality",
            "https://www.researchgate.net/publication/299487682_A_Fast_and_Accurate_Dependency_Parser_using_Neural_Networks",
            "https://www.researchgate.net/publication/284039049_Recursive_deep_models_for_semantic_compositionality_over_a_sentiment_treebank",
            "https://www.researchgate.net/publication/283619991_Greed_Is_Good_If_Randomized_New_Inference_for_Dependency_Parsing"
        ]
    },
    "paper75": {
        "id": "319770403",
        "title": "A Tutorial on Particle Filtering and Smoothing Fifteen years later",
        "abstract": "Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented.",
        "date": "2008",
        "authers": [
            "Arnaud Doucet",
            "Adam Michael Johansen"
        ],
        "refrences": []
    },
    "paper76": {
        "id": "301870716",
        "title": "Classes for Fast Maximum Entropy Training",
        "abstract": "Maximum entropy models are considered by many to be one of the most promising avenues of language modeling research. Unfortunately, long training times make maximum entropy research difficult. We present a novel speedup technique: we change the form of the model to use classes. Our speedup works by creating two maximum entropy models, the first of which predicts the class of each word, and the second of which predicts the word itself. This factoring of the model leads to fewer non-zero indicator functions, and faster normalization, achieving speedups of up to a factor of 35 over one of the best previous techniques. It also results in typically slightly lower perplexities. The same trick can be used to speed training of other machine learning techniques, e.g. neural networks, applied to any problem with a large number of outputs, such as language modeling.",
        "date": "2001",
        "authers": [
            "Joshua Goodman"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220355244_Class-Based_n-gram_Models_of_Natural_Language",
            "https://www.researchgate.net/publication/3192689_Inducing_Features_of_Random_Fields",
            "https://www.researchgate.net/publication/2596889_Adaptive_Statistical_Language_Modeling_A_Maximum_Entropy_Approach",
            "https://www.researchgate.net/publication/2418338_Cluster_Expansions_And_Iterative_Scaling_For_Maximum_Entropy_Language_Models",
            "https://www.researchgate.net/publication/230876357_On_Structuring_Probabilistic_Dependencies_in_Stochastic_Language_Modelling",
            "https://www.researchgate.net/publication/38363908_Generalized_Iterative_Scaling_for_Log-Linear_Models",
            "https://www.researchgate.net/publication/2626194_Putting_It_All_Together_Language_Model_Combination",
            "https://www.researchgate.net/publication/2362847_Language_Model_Size_Reduction_By_Pruning_And_Clustering",
            "https://www.researchgate.net/publication/2328946_Efficient_Training_Methods_For_Maximum_Entropy_Language_Modeling"
        ]
    },
    "paper77": {
        "id": "301841091",
        "title": "Easy-First Dependency Parsing with Hierarchical Tree LSTMs",
        "abstract": "We suggest a compositional vector representation of parse trees that relies on a recursive combination of recurrent-neural network encoders. To demonstrate its effectiveness, we use the representation as the backbone of a greedy, bottom-up dependency parser, achieving state-of-the-art accuracies for English and Chinese, without relying on external word embeddings. The parser's implementation is available for download at the first author's webpage.",
        "date": "2016Transactions",
        "authers": [
            "Eliyahu Kiperwasser",
            "Yoav Goldberg"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/289176638_The_Inside-Outside_Recursive_Neural_Network_model_for_Dependency_Parsing",
            "https://www.researchgate.net/publication/283556656_An_Effective_Neural_Network_Model_for_Graph-based_Dependency_Parsing",
            "https://www.researchgate.net/publication/281812760_TwoToo_Simple_Adaptations_of_Word2Vec_for_Syntax_Problems",
            "https://www.researchgate.net/publication/279068962_Structured_Training_for_Neural_Network_Transition-Based_Parsing",
            "https://www.researchgate.net/publication/278965988_Transition-Based_Dependency_Parsing_with_Stack_Long_Short-Term_Memory",
            "https://www.researchgate.net/publication/277022875_A_Re-ranking_Model_for_Dependency_Parser_with_Recursive_Convolutional_Neural_Network",
            "https://www.researchgate.net/publication/273067823_Improved_Semantic_Representations_From_Tree-Structured_Long_Short-Term_Memory_Networks",
            "https://www.researchgate.net/publication/264003485_SemEval-2014_Task_1_Evaluation_of_Compositional_Distributional_Semantic_Models_on_Full_Sentences_through_Semantic_Relatedness_and_Textual_Entailment",
            "https://www.researchgate.net/publication/234814829_A_tale_of_two_parsers_investigating_and_combining_graph-based_and_transition-based_dependency_parsing_using_beam-search",
            "https://www.researchgate.net/publication/228569700_Learning_Continuous_Phrase_Representations_and_Syntactic_Parsing_with_Recursive_Neural_Networks"
        ]
    },
    "paper78": {
        "id": "286531327",
        "title": "Efficient higher-order CRFs for morphological tagging",
        "abstract": "Training higher-order conditional random fields is prohibitive for huge tag sets. We present an approximated conditional random field using coarse-to-fine decoding and early updating. We show that our implementation yields fast and accurate morphological taggers across six languages with different morphological properties and that across languages higher-order models give significant improvements over 1st-order models.",
        "date": "2013",
        "authers": [
            "T. M\u00fcller",
            "H. Schmid",
            "H. Sch\u00fctze"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262274512_Knowledge_Sources_for_Constituent_Parsing_of_German_a_Morphologically_Rich_and_Less-Configurational_Language",
            "https://www.researchgate.net/publication/255682142_Morphological_Tagging_Data_vs_Dictionaries",
            "https://www.researchgate.net/publication/221102585_Estimation_of_Conditional_Probabilities_With_Decision_Trees_and_an_Application_to_Fine-Grained_POS_Tagging",
            "https://www.researchgate.net/publication/220875017_Practical_very_large_scale_CRFs",
            "https://www.researchgate.net/publication/220874670_Guided_Learning_for_Bidirectional_Sequence_Classification"
        ]
    },
    "paper79": {
        "id": "284039049",
        "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
        "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment composition-ality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
        "date": "2013",
        "authers": [
            "Richard Socher",
            "A. Perelygin",
            "J.Y. Wu",
            "J. Chuang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/254675183_Minimizers_Maximizers_and_the_Rhetoric_of_Scalar_Reasoning",
            "https://www.researchgate.net/publication/303475895_Sentiment_composition",
            "https://www.researchgate.net/publication/284025120_Information_relevance_and_social_decision-making",
            "https://www.researchgate.net/publication/225955045_Denial_and_contrast_A_relevance_theoretic_analysis_ofbut"
        ]
    },
    "paper80": {
        "id": "283806803",
        "title": "Generative Incremental Dependency Parsing with Neural Networks",
        "abstract": "We propose a neural network model for scalable generative transition-based dependency parsing. A probability distribution over both sentences and transition sequences is parameterised by a feedforward neural network. The model surpasses the accuracy and speed of previous generative dependency parsers, reaching 91.1% UAS. Perplexity results show a strong improvement over n-gram language models, opening the way to the efficient integration of syntax into neural models for language generation.",
        "date": "2015",
        "authers": [
            "Jan Buys",
            "Phil Blunsom"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/286902441_OxLM_A_Neural_Language_Modelling_Framework_for_Machine_Translation",
            "https://www.researchgate.net/publication/279068962_Structured_Training_for_Neural_Network_Transition-Based_Parsing",
            "https://www.researchgate.net/publication/277560449_Transition-Based_Dependency_Parsing_with_Stack_Long_Short-Term_Memory",
            "https://www.researchgate.net/publication/270878122_Tailoring_Continuous_Word_Representations_for_Dependency_Parsing",
            "https://www.researchgate.net/publication/270877878_Fast_and_Robust_Neural_Network_Joint_Models_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/262402839_A_transition-based_system_for_joint_part-of-speech_tagging_and_labeled_non-projective_dependency_parsing",
            "https://www.researchgate.net/publication/259239818_One_Billion_Word_Benchmark_for_Measuring_Progress_in_Statistical_Language_Modeling",
            "https://www.researchgate.net/publication/257870129_Transition-based_Dependency_Parsing_with_Selectional_Branching",
            "https://www.researchgate.net/publication/251574306_The_Stanford_typed_dependencies_representation",
            "https://www.researchgate.net/publication/228707544_Deterministic_dependency_parsing_of_English_text"
        ]
    },
    "paper81": {
        "id": "278413581",
        "title": "A Bayesian Model for Generative Transition-based Dependency Parsing",
        "abstract": "We propose a simple, scalable, fully generative model for transition-based\ndependency parsing with high accuracy. The model, parameterized by Hierarchical\nPitman-Yor Processes, overcomes the limitations of previous generative models\nby allowing fast and accurate inference. We propose an efficient decoding\nalgorithm based on particle filtering that can adapt the beam size to the\nuncertainty in the model while jointly predicting POS tags and parse trees. The\nUAS of the parser is on par with that of a greedy discriminative baseline. As a\nlanguage model, it obtains better perplexity than a n-gram model by performing\nsemi-supervised learning over a large unlabelled corpus. We show that the model\nis able to generate locally and syntactically coherent sentences, opening the\ndoor to further applications in language generation.",
        "date": "2015",
        "authers": [
            "Jan Buys",
            "Phil Blunsom"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262402839_A_transition-based_system_for_joint_part-of-speech_tagging_and_labeled_non-projective_dependency_parsing",
            "https://www.researchgate.net/publication/257870129_Transition-based_Dependency_Parsing_with_Selectional_Branching",
            "https://www.researchgate.net/publication/228707544_Deterministic_dependency_parsing_of_English_text",
            "https://www.researchgate.net/publication/221618802_Modeling_the_effects_of_memory_on_human_online_sentence_processing_with_particle_filters",
            "https://www.researchgate.net/publication/221013207_Unsupervised_Induction_of_Tree_Substitution_Grammars_for_Dependency_Parsing",
            "https://www.researchgate.net/publication/221013182_Exact_Inference_for_Generative_Probabilistic_Non-Projective_Dependency_Parsing",
            "https://www.researchgate.net/publication/221013171_Fast_and_Robust_Multilingual_Dependency_Parsing_with_a_Generative_Latent_Variable_Model",
            "https://www.researchgate.net/publication/221012805_Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers",
            "https://www.researchgate.net/publication/220874833_Transition-based_Dependency_Parsing_with_Rich_Non-local_Features",
            "https://www.researchgate.net/publication/220874243_Corpus-Based_Induction_of_Syntactic_Structure_Models_of_Dependency_and_Constituency"
        ]
    },
    "paper82": {
        "id": "265385879",
        "title": "On the Properties of Neural Machine Translation Encoder-Decoder Approaches",
        "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence\nautomatically.",
        "date": "2014",
        "authers": [
            "Kyunghyun Cho",
            "Bart van Merrienboer",
            "Dzmitry Bahdanau",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266797103_BLEU_deconstructed_Designing_a_Better_MT_Evaluation_Metric",
            "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/221012675_Domain_Adaptation_via_Pseudo_In-Domain_Data_Selection",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/289758666_Recurrent_continuous_translation_models",
            "https://www.researchgate.net/publication/265554383_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/255173850_Generating_Sequences_With_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/233981807_ADADELTA_An_adaptive_learning_rate_method",
            "https://www.researchgate.net/publication/233409624_Sequence_Transduction_with_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/221013286_Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation"
        ]
    },
    "paper83": {
        "id": "255983764",
        "title": "Pylearn2 A machine learning research library",
        "abstract": "Pylearn2 is a machine learning research library. This does not just mean that\nit is a collection of machine learning algorithms that share a common API; it\nmeans that it has been designed for flexibility and extensibility in order to\nfacilitate research projects that involve new or unusual use cases. In this\npaper we give a brief history of the library, an overview of its basic\nphilosophy, a summary of the library's architecture, and a description of how\nthe Pylearn2 community functions socially.",
        "date": "2013",
        "authers": [
            "Ian Goodfellow",
            "David Warde-Farley",
            "Pascal Lamblin",
            "Vincent Dumoulin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770395_An_Analysis_of_Single-Layer_Networks_in_Unsupervised_Feature_Learning",
            "https://www.researchgate.net/publication/312538118_Support-vector_networks",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/304109482_Training_products_of_experts_by_minimizing_contrastive_divergence",
            "https://www.researchgate.net/publication/303256841_Theano_a_CPU_and_GPU_math_expression_compiler",
            "https://www.researchgate.net/publication/271513141_Support_Vector_Networks",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/266031774_Reading_Digits_in_Natural_Images_with_Unsupervised_Feature_Learning"
        ]
    },
    "paper84": {
        "id": "243781690",
        "title": "Untersuchungen zu dynamischen neuronalen Netzen",
        "abstract": "",
        "date": "1991",
        "authers": [
            "Sepp Hochreiter"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/311100814_Comparing_Biases_for_Minimal_Network_Construction_with_Back-Propagation",
            "https://www.researchgate.net/publication/341530631_An_Introduction_to_Neural_Networks",
            "https://www.researchgate.net/publication/313601183_Optimal_brain_damage_in",
            "https://www.researchgate.net/publication/312986214_Some_studies_in_machine_learning_using_the_game_of_checkers",
            "https://www.researchgate.net/publication/291743705_Connectionist_music_composition_based_on_melodic_stylistic_and_psychophysical_constraints",
            "https://www.researchgate.net/publication/286375944_Supervised_learning_systems_with_excess_degrees_of_freedom",
            "https://www.researchgate.net/publication/285483611_Learning_to_generate_artificial_fovea_trajectories_for_target_detection",
            "https://www.researchgate.net/publication/273130022_Incremental_Learning_or_The_Importance_of_Starting_Small",
            "https://www.researchgate.net/publication/266850402_Cognitive_Map_Construction_and_Use_A_Parallel_Distributed_Processing_Approach",
            "https://www.researchgate.net/publication/265461524_Neural_networks_An_introduction"
        ]
    },
    "paper85": {
        "id": "279394722",
        "title": "Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks",
        "abstract": "In this paper we propose and investigate a novel nonlinear unit, called L p unit, for deep neural networks. The proposed L p unit receives signals from several projections of a subset of units in the layer below and computes a normalized L p norm. We notice two interesting interpretations of the L p unit. First, the proposed unit can be understood as a generalization of a number of conventional pooling operators such as average, root-mean-square and max pooling widely used in, for instance, convolutional neural networks (CNN), HMAX models and neocognitrons. Furthermore, the L p unit is, to a certain degree, similar to the recently proposed maxout unit [13] which achieved the state-of-the-art object recognition results on a number of benchmark datasets. Secondly, we provide a geometrical interpretation of the activation function based on which we argue that the L p unit is more efficient at representing complex, nonlinear separating boundaries. Each L p unit defines a superelliptic boundary, with its exact shape defined by the order p. We claim that this makes it possible to model arbitrarily shaped, curved boundaries more efficiently by combining a few L p units of different orders. This insight justifies the need for learning different orders for each unit in the model. We empirically evaluate the proposed L p units on a number of datasets and show that multilayer perceptrons (MLP) consisting of the L p units achieve the state-of-the-art results on a number of benchmark datasets. Furthermore, we evaluate the proposed L p unit on the recently proposed deep recurrent neural networks (RNN).",
        "date": "2014",
        "authers": [
            "Caglar Gulcehre",
            "Kyunghyun Cho",
            "Razvan Pascanu",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/258816388_Revisiting_Natural_Gradient_for_Deep_Networks",
            "https://www.researchgate.net/publication/258247515_On_Fast_Dropout_and_its_Applicability_to_Recurrent_Networks",
            "https://www.researchgate.net/publication/255983764_Pylearn2_A_machine_learning_research_library",
            "https://www.researchgate.net/publication/234140324_Knowledge_Matters_Importance_of_Prior_Information_for_Optimization",
            "https://www.researchgate.net/publication/233866039_High-dimensional_sequence_transduction",
            "https://www.researchgate.net/publication/233753224_Theano_new_features_and_speed_improvements",
            "https://www.researchgate.net/publication/233730646_On_the_difficulty_of_training_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/228467601_The_Manifold_Tangent_Classifier",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/228095594_Modeling_Temporal_Dependencies_in_High-Dimensional_SequencesApplication_to_Polyphonic_Music_Generation_and_Transcription"
        ]
    },
    "paper86": {
        "id": "267706055",
        "title": "Practical Variational Inference for Neural Networks",
        "abstract": "Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural net-works. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically re-duce the number of network weights and lead to improved generalisation. Exper-imental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus.",
        "date": "",
        "authers": [
            "Alex Graves"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/239571798_Information_processing_in_dynamical_systems_Foundations_of_harmony_theory",
            "https://www.researchgate.net/publication/221620610_Offline_Arabic_Handwriting_Recognition_with_Multidimensional_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/221620570_Phone_Recognition_with_the_Mean-Covariance_Restricted_Boltzmann_Machine",
            "https://www.researchgate.net/publication/221346365_Connectionist_temporal_classification_Labelling_unsegmented_sequence_data_with_recurrent_neural_'networks",
            "https://www.researchgate.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.researchgate.net/publication/3303419_Variational_Learning_and_Bits-Back_Coding_An_Information-Theoretic_View_to_Bayesian_Learning",
            "https://www.researchgate.net/publication/3302208_An_analysis_of_noise_in_recurrent_neural_networks_Convergence_and_generalization",
            "https://www.researchgate.net/publication/313601183_Optimal_brain_damage_in",
            "https://www.researchgate.net/publication/277509458_Arithmetic_Coding_for_Data_Compression"
        ]
    },
    "paper87": {
        "id": "265554383",
        "title": "Sequence to Sequence Learning with Neural Networks",
        "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent\nperformance on difficult learning tasks. Although DNNs work well whenever large\nlabeled training sets are available, they cannot be used to map sequences to\nsequences. In this paper, we present a general end-to-end approach to sequence\nlearning that makes minimal assumptions on the sequence structure. Our method\nuses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to\na vector of a fixed dimensionality, and then another deep LSTM to decode the\ntarget sequence from the vector. Our main result is that on an English to\nFrench translation task from the WMT-14 dataset, the translations produced by\nthe LSTM achieve a BLEU score of 34.7 on the entire test set, where the LSTM's\nBLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did\nnot have difficulty on long sentences. For comparison, a strong phrase-based\nSMT system achieves a BLEU score of 33.3 on the same dataset. When we used the\nLSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system,\nits BLEU score increases to 36.5, which beats the previous state of the art.\nThe LSTM also learned sensible phrase and sentence representations that are\nsensitive to word order and are relatively invariant to the active and the\npassive voice. Finally, we found that reversing the order of the words in all\nsource sentences (but not target sentences) improved the LSTM's performance\nmarkedly, because doing so introduced many short term dependencies between the\nsource and the target sentence which made the optimization problem easier.",
        "date": "2014Advances",
        "authers": [
            "Ilya Sutskever",
            "Oriol Vinyals",
            "Quoc V. Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/270877878_Fast_and_Robust_Neural_Network_Joint_Models_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/265386055_Overcoming_the_Curse_of_Sentence_Length_for_Neural_Machine_Translation_using_Automatic_Segmentation",
            "https://www.researchgate.net/publication/263086337_Edinburgh's_Phrase-based_Machine_Translation_Systems_for_WMT-14",
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/221620298_LSTM_can_solve_hard_long_time_lag_problems",
            "https://www.researchgate.net/publication/221618573_A_Neural_Probabilistic_Language_Model",
            "https://www.researchgate.net/publication/221346365_Connectionist_temporal_classification_Labelling_unsegmented_sequence_data_with_recurrent_neural_'networks",
            "https://www.researchgate.net/publication/51968606_Building_high-level_features_using_large_scale_unsupervised_learning",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.researchgate.net/publication/5583935_Learning_long-term_dependencies_with_gradient_descent_is_difficult"
        ]
    },
    "paper88": {
        "id": "262395872",
        "title": "Random Search for Hyper-Parameter Optimization",
        "abstract": "Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent \"High Throughput\" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.",
        "date": "2012Journal",
        "authers": [
            "James Bergstra",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/227447179_Simulation-Based_Optimization_with_Stochastic_Approximation_Using_Common_Random_Numbers",
            "https://www.researchgate.net/publication/221346269_Extracting_and_composing_robust_features_with_denoising_autoencoders",
            "https://www.researchgate.net/publication/221345414_An_empirical_evaluation_of_deep_architectures_on_problems_with_many_factors_of_variation",
            "https://www.researchgate.net/publication/220319875_Why_Does_Unsupervised_Pre-training_Help_Deep_Learning",
            "https://www.researchgate.net/publication/215991023_Learning_Deep_Architectures_for_AI",
            "https://www.researchgate.net/publication/45130828_Response_Surface_Methodology_for_Optimizing_Hyper_Parameters",
            "https://www.researchgate.net/publication/10710734_Reducing_the_Time_Complexity_of_the_Derandomized_Evolution_Strategy_with_Covariance_Matrix_Adaptation_CMA-ES",
            "https://www.researchgate.net/publication/6026283_Optimization_by_Simulated_Annealing",
            "https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition",
            "https://www.researchgate.net/publication/321133827_A_Comparison_of_Three_Methods_for_Selecting_Values_of_Input_Variables_in_the_Analysis_of_Output_from_a_Computer_Code"
        ]
    },
    "paper89": {
        "id": "258818168",
        "title": "Speech Recognition with Deep Recurrent Neural Networks",
        "abstract": "Recurrent neural networks (RNNs) are a powerful model for sequential\ndata. End-to-end training methods such as Connectionist Temporal\nClassification make it possible to train RNNs for sequence labelling\nproblems where the input-output alignment is unknown. The combination of\nthese methods with the Long Short-term Memory RNN architecture has\nproved particularly fruitful, delivering state-of-the-art results in\ncursive handwriting recognition. However RNN performance in speech\nrecognition has so far been disappointing, with better results returned\nby deep feedforward networks. This paper investigates \\emph{deep\nrecurrent neural networks}, which combine the multiple levels of\nrepresentation that have proved so effective in deep networks with the\nflexible use of long range context that empowers RNNs. When trained\nend-to-end with suitable regularisation, we find that deep Long\nShort-term Memory RNNs achieve a test set error of 17.7% on the TIMIT\nphoneme recognition benchmark, which to our knowledge is the best\nrecorded score.",
        "date": "2013Acoustics,",
        "authers": [
            "Alex Graves",
            "Abdel-rahman Mohamed",
            "Geoffrey Hinton"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/261119155_Applying_Convolutional_Neural_Networks_concepts_to_hybrid_NN-HMM_model_for_speech_recognition",
            "https://www.researchgate.net/publication/255564594_Revisiting_Recurrent_Neural_Networks_for_Robust_ASR",
            "https://www.researchgate.net/publication/230875873_Connectionist_Speech_Recognition_A_Hybrid_Approach",
            "https://www.researchgate.net/publication/224216007_Acoustic_Modeling_Using_Deep_Belief_Networks",
            "https://www.researchgate.net/publication/224149891_Discriminatively_estimated_joint_acoustic_duration_and_language_model_for_speech_recognition",
            "https://www.researchgate.net/publication/221620610_Offline_Arabic_Handwriting_Recognition_with_Multidimensional_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/221619960_Unconstrained_On-line_Handwriting_Recognition_with_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/221617663_Forward-backward_retraining_of_recurrent_neural_networks",
            "https://www.researchgate.net/publication/221484545_Investigation_of_full-sequence_training_of_deep_belief_networks_for_speech_recognition",
            "https://www.researchgate.net/publication/221346365_Connectionist_temporal_classification_Labelling_unsegmented_sequence_data_with_recurrent_neural_'networks"
        ]
    },
    "paper90": {
        "id": "255173850",
        "title": "Generating Sequences With Recurrent Neural Networks",
        "abstract": "This paper shows how Long Short-term Memory recurrent neural networks can be\nused to generate complex sequences with long-range structure, simply by\npredicting one data point at a time. The approach is demonstrated for text\n(where the data are discrete) and online handwriting (where the data are\nreal-valued). It is then extended to handwriting synthesis by allowing the\nnetwork to condition its predictions on a text sequence. The resulting system\nis able to generate highly realistic cursive handwriting in a wide variety of\nstyles.",
        "date": "2013",
        "authers": [
            "Alex Graves"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266485700_SUBWORD_LANGUAGE_MODELING_WITH_NEURAL_NETWORKS",
            "https://www.researchgate.net/publication/228095594_Modeling_Temporal_Dependencies_in_High-Dimensional_SequencesApplication_to_Polyphonic_Music_Generation_and_Transcription",
            "https://www.researchgate.net/publication/227458453_The_Minimum_Description_Length_Principle",
            "https://www.researchgate.net/publication/224626482_IAM-OnDB_-_An_on-line_English_sentence_database_acquired_from_handwritten_text_on_a_whiteboard",
            "https://www.researchgate.net/publication/221620610_Offline_Arabic_Handwriting_Recognition_with_Multidimensional_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/220320057_Learning_Precise_Timing_with_LSTM_Recurrent_Networks",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.researchgate.net/publication/5583935_Learning_long-term_dependencies_with_gradient_descent_is_difficult",
            "https://www.researchgate.net/publication/3302208_An_analysis_of_noise_in_recurrent_neural_networks_Convergence_and_generalization"
        ]
    },
    "paper91": {
        "id": "262402839",
        "title": "A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing",
        "abstract": "Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins. We present a transition-based system for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-the-art results for all languages.",
        "date": "2012",
        "authers": [
            "Bernd Bohnet",
            "Joakim Nivre"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266887545_Comparing_Advanced_Graph-based_and_Transition-based_Dependency_Parsers",
            "https://www.researchgate.net/publication/234809510_Experiments_with_a_multilanguage_non-projective_dependency_parser",
            "https://www.researchgate.net/publication/234796040_Very_high_accuracy_and_fast_dependency_parsing_is_not_a_contradiction",
            "https://www.researchgate.net/publication/230876740_The_CoNLL-2009_Shared_Task_Syntactic_and_Semantic_Dependencies_in_Multiple_Languages",
            "https://www.researchgate.net/publication/230876736_A_Latent_Variable_Model_of_Synchronous_Syntactic-Semantic_Parsing_for_Multiple_Languages",
            "https://www.researchgate.net/publication/268720443_Inductive_Dependency_Parsing",
            "https://www.researchgate.net/publication/266034441_Incremental_Joint_POS_Tagging_and_Dependency_Parsing_in_Chinese",
            "https://www.researchgate.net/publication/262355038_Incremental_joint_approach_to_word_segmentation_POS_tagging_and_dependency_parsing_in_Chinese",
            "https://www.researchgate.net/publication/234828464_Investigating_multilingual_dependency_parsing",
            "https://www.researchgate.net/publication/228981212_Semisupervised_condensed_nearest_neighbor_for_part-of-speech_tagging"
        ]
    },
    "paper92": {
        "id": "262323558",
        "title": "Capturing paradigmatic and syntagmatic lexical relations towards accurate Chinese part-of-speech tagging",
        "abstract": "From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a state-of-the-art baseline.",
        "date": "2012",
        "authers": [
            "Weiwei Sun",
            "Hans Uszkoreit"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/228734693_Morphological_features_help_POS_tagging_of_unknown_words_across_language_varieties",
            "https://www.researchgate.net/publication/221481293_Improved_clustering_techniques_for_class-based_statistical_language_modelling",
            "https://www.researchgate.net/publication/221013125_Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing",
            "https://www.researchgate.net/publication/288905957_SVMTool_A_general_POS_tagger_generator_based_on_support_vector_machines",
            "https://www.researchgate.net/publication/285905347_A_conditional_random_field_word_segmenter",
            "https://www.researchgate.net/publication/269031283_A_tale_of_two_parsers",
            "https://www.researchgate.net/publication/234812408_An_efficient_method_for_determining_bilingual_word_classes",
            "https://www.researchgate.net/publication/226270700_Bagging_Predictors",
            "https://www.researchgate.net/publication/221101487_Word-based_and_Character-based_Word_Segmentation_Models_Comparison_and_Combination",
            "https://www.researchgate.net/publication/221013109_A_Tale_of_Two_Parsers_Investigating_and_Combining_Graph-based_and_Transition-based_Dependency_Parsing"
        ]
    },
    "paper93": {
        "id": "228916842",
        "title": "Statistical dependency analysis with support vector machines",
        "abstract": "In this paper, we propose a method for analyzing word-word dependencies using deterministic bottom-up manner using Support Vector machines. We experimented with dependency trees converted from Penn treebank data, and achieved over 90% accuracy of word-word dependency. Though the result is little worse than the most up-to-date phrase structure based parsers, it looks satisfactorily accurate considering that our parser uses no information from phrase structures.",
        "date": "2003",
        "authers": [
            "Hiroyasu Yamada",
            "Yuji Matsumoto"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220874244_Revision_Learning_and_its_Application_to_Part-of-Speech_Tagging",
            "https://www.researchgate.net/publication/220482445_Parsing_English_with_a_Link_Grammar",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/301864384_Three_New_Probabilistic_Models_for_Dependency_Parsing_An_Exploration",
            "https://www.researchgate.net/publication/260730920_An_Empirical_Comparison_of_Probability_Models_for_Dependency_Grammar",
            "https://www.researchgate.net/publication/221101482_Three_New_Probabilistic_Models_for_Dependency_Parsing_An_Exploration",
            "https://www.researchgate.net/publication/220874091_A_New_Statistical_Parser_Based_on_Bigram_Lexical_Dependencies",
            "https://www.researchgate.net/publication/220343911_Learning_to_Parse_Natural_Language_with_Maximum_Entropy_Models",
            "https://www.researchgate.net/publication/200033835_The_Nature_of_Statistical_Learning_Theory",
            "https://www.researchgate.net/publication/2538570_A_Maximum-Entropy-Inspired_Parser"
        ]
    },
    "paper94": {
        "id": "228362666",
        "title": "A classifier-based parser with linear run-time complexity",
        "abstract": "We present a classifier-based parser that produces constituent trees in linear time. The parser uses a basic bottom-up shift-reduce algorithm, but employs a classifier to determine parser actions instead of a grammar. This can be seen as an exten-sion of the deterministic dependency parser of Nivre and Scholz (2004) to full constituent parsing. We show that, with an appropriate feature set used in classifi-cation, a very simple one-path greedy parser can perform at the same level of accuracy as more complex parsers. We evaluate our parser on section 23 of the WSJ section of the Penn Treebank, and obtain precision and recall of 87.54% and 87.61%, respectively.",
        "date": "2005",
        "authers": [
            "Kenji Sagae",
            "Alon Lavie"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/228916842_Statistical_dependency_analysis_with_support_vector_machines",
            "https://www.researchgate.net/publication/228707544_Deterministic_dependency_parsing_of_English_text",
            "https://www.researchgate.net/publication/221013189_A_Boosting_Algorithm_for_Classification_of_Semi-Structured_Text",
            "https://www.researchgate.net/publication/220817026_Chunking_with_Support_Vector_Machines",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/221013334_Induction_of_Greedy_Controllers_for_Deterministic_Treebank_Parsers",
            "https://www.researchgate.net/publication/220873245_The_Necessity_of_Parsing_for_Predicate_Argument_Recognition",
            "https://www.researchgate.net/publication/2867292_Learning_A_Lightweight_Robust_Deterministic_Parser",
            "https://www.researchgate.net/publication/2547815_A_Linear_Observed_Time_Statistical_Parser_Based_on_Maximum_Entropy_Models",
            "https://www.researchgate.net/publication/2540346_The_Necessity_of_Parsing_for_Predicate_Argument_Recognition"
        ]
    },
    "paper95": {
        "id": "270877686",
        "title": "Exploiting Lexical Dependencies from Large-Scale Data for Better Shift-Reduce Constituency Parsing",
        "abstract": "This paper proposes a method to improve shift-reduce constituency parsing by using lexical dependencies. The lexical dependency information is obtained from a large amount of auto-parsed data that is generated by a baseline shift-reduce parser on unlabeled data. We then incorporate a set of novel features defined on this information into the shift-reduce parsing model. The features can help to disambiguate action conflicts during decoding. Experimental results show that the new features achieve absolute improvements over a strong baseline by 0.9% and 1.1% on English and Chinese respectively. Moreover, the improved parser outperforms all previously reported shift-reduce constituency parsers.",
        "date": "2012",
        "authers": [
            "Muhua Zhu",
            "Jingbo Zhu",
            "Huizhen Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221013081_Improving_Dependency_Parsing_with_Subtrees_from_Auto-Parsed_Data",
            "https://www.researchgate.net/publication/221012688_Self-Training_with_Products_of_Latent_Variable_Grammars",
            "https://www.researchgate.net/publication/220873576_Web-Scale_Features_for_Full-Scale_Parsing"
        ]
    },
    "paper96": {
        "id": "262361657",
        "title": "Utilizing dependency language models for graph-based dependency parsing models",
        "abstract": "Most previous graph-based parsing models increase decoding complexity when they use high-order features due to exact-inference decoding. In this paper, we present an approach to enriching high-order feature representations for graph-based dependency parsing models using a dependency languagemodel and beam search. The dependency language model is built on a large-amount of additional auto-parsed data that is processed by a baseline parser. Based on the dependency language model, we represent a set of features for the parsing model. Finally, the features are efficiently integrated into the parsing model during decoding using beam search. Our approach has two advantages. Firstly we utilize rich high-order features defined over a view of large scope and additional large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data.",
        "date": "2012",
        "authers": [
            "Wenliang Chen",
            "Min Zhang",
            "Haizhou Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/237533325_CoNLL-X_Shared_Task_on_Multilingual_Dependency_Parsing",
            "https://www.researchgate.net/publication/228916842_Statistical_dependency_analysis_with_support_vector_machines",
            "https://www.researchgate.net/publication/221013081_Improving_Dependency_Parsing_with_Subtrees_from_Auto-Parsed_Data",
            "https://www.researchgate.net/publication/221013054_Dependency_Parsing_and_Domain_Adaptation_with_LR_Models_and_Parser_Ensembles",
            "https://www.researchgate.net/publication/221012782_Characterizing_the_Errors_of_Data-Driven_Dependency_Parsing_Models",
            "https://www.researchgate.net/publication/220874856_An_Error-Driven_Word-Character_Hybrid_Model_for_Joint_Chinese_Word_Segmentation_and_POS_Tagging",
            "https://www.researchgate.net/publication/220874801_Reranking_and_Self-Training_for_Parser_Adaptation",
            "https://www.researchgate.net/publication/220873136_Cross_Language_Dependency_Parsing_using_a_Bilingual_Lexicon",
            "https://www.researchgate.net/publication/220873101_Online_Large-Margin_Training_of_Dependency_Parsers",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank"
        ]
    },
    "paper97": {
        "id": "262349927",
        "title": "Discriminative Reranking for Natural Language Parsing",
        "abstract": "",
        "date": "2000",
        "authers": [
            "Michael Collins"
        ],
        "refrences": []
    },
    "paper98": {
        "id": "243787298",
        "title": "On the parameter space of generative lexicalized statistical parsing models",
        "abstract": "In this thesis, we apply as well as develop techniques and methodologies for the examination of the complex systems that are lexicalized statistical parsing models. The primary idea is that of treating the \u201cmodel as data\u201d, which is not a particular method, but a paradigm and a research methodology. Our argument is that lexicalized statistical parsing models have become increasingly complex, and therefore require thorough scrutiny, both to achieve the scientific aim of understanding what has been built thus far, and to achieve both the scientific and engineering goal of using that understanding for progress. In this thesis, we take a particular, dominant type of parsing model and perform a macro analysis, to reveal its core (and design a software engine that modularizes the periphery), and we also crucially perform a detailed analysis, which provides for the first time a window onto the efficacy of specific parameters. These analyses have not only yielded insight into the core model, but they have also enabled the identification of \u201cinefficiencies\u201d in our baseline model, such that those inefficiencies can be reduced to form a more compact model, or exploited for finding a better-estimated model with higher accuracy, or both.",
        "date": "2004",
        "authers": [
            "Dan Bikel"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221101811_A_Computational_Model_Of_Language_Performance_Data_Oriented_Parsing",
            "https://www.researchgate.net/publication/220875062_Towards_History-Based_Grammars_Using_Richer_Models_for_Probabilistic_Parsing",
            "https://www.researchgate.net/publication/220874982_D-Tree_Grammars",
            "https://www.researchgate.net/publication/220873033_Statistical_Decision-Tree_Models_for_Parsing",
            "https://www.researchgate.net/publication/220816862_Parsing_the_Voyager_Domain_Using_Pearl",
            "https://www.researchgate.net/publication/220708270_Automatic_Learning_for_Semantic_Collocation",
            "https://www.researchgate.net/publication/220685657_The_zero-frequency_problem_Estimating_the_probabilities_of_novel_events_in_adaptive_text_compression",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/220017613_Fast_Exact_Inference_with_a_Factored_Model_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/216300475_Empirical_Methods_for_Artificial_Intelligence"
        ]
    },
    "paper99": {
        "id": "233823603",
        "title": "Practical Structured Learning Techniques for Natural Language Processing",
        "abstract": "",
        "date": "2006",
        "authers": [
            "Daume H C III"
        ],
        "refrences": []
    },
    "paper100": {
        "id": "270877878",
        "title": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation",
        "abstract": "Recent work has shown success in using neural network language models (NNLMs) as features in MT systems. Here, we present a novel formulation for a neural network joint model (NNJM), which augments the NNLM with a source context window. Our model is purely lexicalized and can be integrated into any MT decoder. We also present several variations of the NNJM which provide significant additive improvements. Although the model is quite simple, it yields strong empirical results. On the NIST OpenMT12 Arabic-English condition, the NNJM features produce a gain of +3.0 BLEU on top of a powerful, featurerich baseline which already includes a target-only NNLM. The NNJM features also produce a gain of +6.3 BLEU on top of a simpler baseline equivalent to Chiang's (2007) original Hiero implementation. Additionally, we describe two novel techniques for overcoming the historically high cost of using NNLM-style models in MT decoding. These techniques speed up NNJM computation by a factor of 10,000x, making the model as fast as a standard back-off LM.",
        "date": "2014",
        "authers": [
            "Jacob Devlin",
            "Rabih Zbib",
            "Zhongqiang Huang",
            "Thomas Lamar"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/290650943_Bilingual_word_embeddings_for_phrase-based_machine_translation",
            "https://www.researchgate.net/publication/319770436_Efficient_backprop",
            "https://www.researchgate.net/publication/312369762_Continuous_space_translation_models_with_neural_networks",
            "https://www.researchgate.net/publication/289690359_Factored_soft_source_syntactic_constraints_for_hierarchical_machine_translation",
            "https://www.researchgate.net/publication/287008400_An_efficient_language_model_using_double-array_structures",
            "https://www.researchgate.net/publication/285895924_Linguistic_regularities_in_continuous_space_word_representations",
            "https://www.researchgate.net/publication/285432248_Decoding_with_large-scale_neural_language_models_improves_translation",
            "https://www.researchgate.net/publication/283112108_Joint_language_and_translation_modeling_with_recurrent_neural_networks",
            "https://www.researchgate.net/publication/277186684_Lexical_Features_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/270878785_Continuous_Space_Translation_Models_for_Phrase-Based_Statistical_Machine_Translation"
        ]
    },
    "paper101": {
        "id": "265386055",
        "title": "Overcoming the Curse of Sentence Length for Neural Machine Translation using Automatic Segmentation",
        "abstract": "The authors of (Cho et al., 2014a) have shown that the recently introduced\nneural network translation systems suffer from a significant drop in\ntranslation quality when translating long sentences, unlike existing\nphrase-based translation systems. In this paper, we propose a way to address\nthis issue by automatically segmenting an input sentence into phrases that can\nbe easily translated by the neural network translation model. Once each segment\nhas been independently translated by the neural machine translation model, the\ntranslated clauses are concatenated to form a final translation. Empirical\nresults show a significant improvement in translation quality for long\nsentences.",
        "date": "2014",
        "authers": [
            "Jean Pouget-Abadie",
            "Dzmitry Bahdanau",
            "Bart van Merrienboer",
            "Kyunghyun Cho"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220816913_Statistical_Phrase-Based_Translation",
            "https://www.researchgate.net/publication/258818168_Speech_Recognition_with_Deep_Recurrent_Neural_Networks"
        ]
    },
    "paper102": {
        "id": "319770418",
        "title": "Maxout Networks",
        "abstract": "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.",
        "date": "2013",
        "authers": [
            "Ian Goodfellow",
            "David Warde-Farley",
            "Mehdi Mirza",
            "Aaron Courville"
        ],
        "refrences": []
    },
    "paper103": {
        "id": "307174794",
        "title": "Statistical Machine Translation",
        "abstract": "This introductory text to statistical machine translation (SMT) provides all of the theories and methods needed to build a statistical machine translator, such as Google Language Tools and Babelfish. In general, statistical techniques allow automatic translation systems to be built quickly for any language-pair using only translated texts and generic software. With increasing globalization, statistical machine translation will be central to communication and commerce. Based on courses and tutorials, and classroom-tested globally, it is ideal for instruction or self-study, for advanced undergraduates and graduate students in computer science and/or computational linguistics, and researchers in natural language processing. The companion website provides open-source corpora and tool-kits.",
        "date": "2009",
        "authers": [
            "Philipp Koehn"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/265657436_Automatic_Sentence_Segmentation_and_Punctuation_Prediction_for_Spoken_Language_Translation",
            "https://www.researchgate.net/publication/237327924_Continuous_space_language_models_for_the_IWSLT_2006_task",
            "https://www.researchgate.net/publication/237247141_The_TALP_Ngram-based_SMT_system_for_IWSLT_2007",
            "https://www.researchgate.net/publication/237247130_The_TALP-UPC_Ngram-based_statistical_machine_translation_system_for_ACL-WMT_2008",
            "https://www.researchgate.net/publication/234815897_A_statistical_approach_to_language_translation",
            "https://www.researchgate.net/publication/234815723_Two_tools_for_creating_and_visualizing_sub-sentential_alignments_of_parallel_text",
            "https://www.researchgate.net/publication/234811483_The_LDV-COMBO_system_for_SMT",
            "https://www.researchgate.net/publication/234802687_Methods_and_practical_issues_in_evaluating_alignment_techniques",
            "https://www.researchgate.net/publication/230668373_Using_shallow_syntax_information_to_improve_word_alignment_and_reordering_for_SMT",
            "https://www.researchgate.net/publication/228945619_Word_error_rates_Decomposition_over_POS_classes_and_applications_for_error_analysis"
        ]
    },
    "paper104": {
        "id": "303256841",
        "title": "Theano a CPU and GPU math expression compiler",
        "abstract": "",
        "date": "2010",
        "authers": [
            "James Bergstra",
            "O. Breuleux",
            "Frederic Bastien",
            "Pascal Lamblin"
        ],
        "refrences": []
    },
    "paper105": {
        "id": "289758666",
        "title": "Recurrent continuous translation models",
        "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of state-of-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
        "date": "2013",
        "authers": [
            "Nal Kalchbrenner",
            "P. Blunsom"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/302879092_A_simple_fast_and_effective_reparameterization_of_IBM_model_2",
            "https://www.researchgate.net/publication/270878336_The_Role_of_Syntax_in_Vector_Space_Models_of_Compositional_Semantics",
            "https://www.researchgate.net/publication/255563511_Context_Dependent_Recurrent_Neural_Network_Language_Model"
        ]
    },
    "paper106": {
        "id": "270878785",
        "title": "Continuous Space Translation Models for Phrase-Based Statistical Machine Translation",
        "abstract": "",
        "date": "2012",
        "authers": [
            "Holger Schwenk"
        ],
        "refrences": []
    },
    "paper107": {
        "id": "261309981",
        "title": "Hybrid speech recognition with Deep Bidirectional LSTM",
        "abstract": "Deep Bidirectional LSTM (DBLSTM) recurrent neural networks have recently been shown to give state-of-the-art performance on the TIMIT speech database. However, the results in that work relied on recurrent-neural-network-specific objective functions, which are difficult to integrate with existing large vocabulary speech recognition systems. This paper investigates the use of DBLSTM as an acoustic model in a standard neural network-HMM hybrid system. We find that a DBLSTM-HMM hybrid gives equally good results on TIMIT as the previous work. It also outperforms both GMM and deep network benchmarks on a subset of the Wall Street Journal corpus. However the improvement in word error rate over the deep network is modest, despite a great increase in framelevel accuracy. We conclude that the hybrid approach with DBLSTM appears to be well suited for tasks where acoustic modelling predominates. Further investigation needs to be conducted to understand how to better leverage the improvements in frame-level accuracy towards better word error rates.",
        "date": "2013",
        "authers": [
            "Alex Graves",
            "Navdeep Jaitly",
            "Abdel-rahman Mohamed"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/255564594_Revisiting_Recurrent_Neural_Networks_for_Robust_ASR",
            "https://www.researchgate.net/publication/230875873_Connectionist_Speech_Recognition_A_Hybrid_Approach",
            "https://www.researchgate.net/publication/228828379_The_Kaldi_speech_recognition_toolkit",
            "https://www.researchgate.net/publication/224216007_Acoustic_Modeling_Using_Deep_Belief_Networks",
            "https://www.researchgate.net/publication/221346365_Connectionist_temporal_classification_Labelling_unsegmented_sequence_data_with_recurrent_neural_'networks",
            "https://www.researchgate.net/publication/220320057_Learning_Precise_Timing_with_LSTM_Recurrent_Networks",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.researchgate.net/publication/3316656_Bidirectional_recurrent_neural_networks",
            "https://www.researchgate.net/publication/3302208_An_analysis_of_noise_in_recurrent_neural_networks_Convergence_and_generalization",
            "https://www.researchgate.net/publication/267706055_Practical_Variational_Inference_for_Neural_Networks"
        ]
    },
    "paper108": {
        "id": "319770387",
        "title": "Deep Sparse Rectifier Neural Networks",
        "abstract": "While logistic sigmoid neurons are more biologically plausable that hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros, which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabelled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labelled data sets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised nueral networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training",
        "date": "2011Journal",
        "authers": [
            "Xavier Glorot",
            "Antoine Bordes",
            "Y. Bengio"
        ],
        "refrences": []
    },
    "paper109": {
        "id": "319770183",
        "title": "Imagenet classification with deep convolutional neural networks",
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif- ferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implemen- tation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called dropout that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry",
        "date": "2012",
        "authers": [
            "Alex Krizhevsky",
            "I Sutskever",
            "G Hinton"
        ],
        "refrences": []
    },
    "paper110": {
        "id": "312369762",
        "title": "Continuous space translation models with neural networks",
        "abstract": "",
        "date": "2012",
        "authers": [
            "Le Hai Son",
            "A. Allauzen",
            "F. Yvon"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/302963741_N-gram-based_machine_translation_enhanced_with_neural_networks_for_the_French-English_BTEC-IWSLT'10_task"
        ]
    },
    "paper111": {
        "id": "307955489",
        "title": "Distributed representations of words and phrases and their compositionality",
        "abstract": "",
        "date": "2013",
        "authers": [
            "T. Mikolov"
        ],
        "refrences": []
    },
    "paper112": {
        "id": "267960550",
        "title": "ImageNet Classification with Deep Convolutional Neural Networks",
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif-ferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make train-ing faster, we used non-saturating neurons and a very efficient GPU implemen-tation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
        "date": "2012Advances",
        "authers": [
            "Alex Krizhevsky",
            "Ilya Sutskever",
            "Geoffrey E. Hinton"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/258627767_Metric_Learning_for_Large_Scale_Image_Classification_Generalizing_to_New_Classes_at_Near-Zero_Cost",
            "https://www.researchgate.net/publication/244947191_1974_Beyond_regression_New_tools_for_predicting_and_analysis_in_the_behavioral_sciences",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/221376179_Convolutional_Networks_and_Applications_in_Vision",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/221344904_Convolutional_deep_belief_networks_for_scalable_unsupervised_learning_of_hierarchical_representations",
            "https://www.researchgate.net/publication/220860992_Best_Practices_for_Convolutional_Neural_Networks_Applied_to_Visual_Document_Analysis",
            "https://www.researchgate.net/publication/220016377_High-dimensional_signature_compression_for_large-scale_image_classification",
            "https://www.researchgate.net/publication/48199502_High-Performance_Neural_Networks_for_Visual_Object_Classification",
            "https://www.researchgate.net/publication/40443832_A_High-Throughput_Screening_Approach_to_Discovering_Good_Forms_of_Biologically_Inspired_Visual_Representation"
        ]
    },
    "paper113": {
        "id": "233981807",
        "title": "ADADELTA An adaptive learning rate method",
        "abstract": "We present a novel per-dimension learning rate method for gradient descent\ncalled ADADELTA. The method dynamically adapts over time using only first order\ninformation and has minimal computational overhead beyond vanilla stochastic\ngradient descent. The method requires no manual tuning of a learning rate and\nappears robust to noisy gradient information, different model architecture\nchoices, various data modalities and selection of hyperparameters. We show\npromising results compared to other methods on the MNIST digit classification\ntask using a single machine and on a large scale voice dataset in a distributed\ncluster environment.",
        "date": "2012",
        "authers": [
            "Matthew D. Zeiler"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/236735729_No_More_Pesky_Learning_Rates",
            "https://www.researchgate.net/publication/225273758_No_More_Pesky_Learning_Rates",
            "https://www.researchgate.net/publication/216792889_Improving_the_Convergence_of_Back-Propagation_Learning_with_Second-Order_Methods",
            "https://www.researchgate.net/publication/265350973_Application_of_Pretrained_Deep_Neural_Networks_to_Large_Vocabulary_Conversational_Speech_Recognition",
            "https://www.researchgate.net/publication/236736791_A_Stochastic_Approximation_Method",
            "https://www.researchgate.net/publication/229091480_Learning_Representations_by_Back_Propagating_Errors",
            "https://www.researchgate.net/publication/221497515_Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization"
        ]
    },
    "paper114": {
        "id": "228379274",
        "title": "EuroParl A parallel corpus for statistical machine translation",
        "abstract": "We collected a corpus of parallel text in 11 lan-guages from the proceedings of the European Par-liament, which are published on the web 1 . This cor-pus has found widespread use in the NLP commu-nity. Here, we focus on its acquisition and its appli-cation as training data for statistical machine trans-lation (SMT). We trained SMT systems for 110 lan-guage pairs, which reveal interesting clues into the challenges ahead.",
        "date": "2004",
        "authers": [
            "Philipp Koehn"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/234795504_Shared_task_statistical_machine_translation_between_European_languages",
            "https://www.researchgate.net/publication/230875890_The_Mathematics_of_Statistical_Machine_Translation_Parameter_Estimation",
            "https://www.researchgate.net/publication/220873989_A_Program_for_Aligning_Sentences_in_Bilingual_Corpora",
            "https://www.researchgate.net/publication/220355307_A_Program_for_Aligning_Sentences_in_Bilingual_Corpora",
            "https://www.researchgate.net/publication/220873246_Mining_the_Web_for_Bilingual_Text",
            "https://www.researchgate.net/publication/220839665_Pharaoh_A_Beam_Search_Decoder_for_Phrase-Based_Statistical_Machine_Translation_Models",
            "https://www.researchgate.net/publication/2662390_Adaptive_Multilingual_Sentence_Boundary_Disambiguation"
        ]
    },
    "paper115": {
        "id": "221617806",
        "title": "PAC Generalization Bounds for Co-training",
        "abstract": "The rule-based bootstrapping introduced by Yarowsky, and its co- training variant by Blum and Mitchell, have met with considerable em- pirical success. Earlier work on the theory of co-training has been only loosely related to empirically useful co-training algorithms. Here we give a new PAC-style bound on generalization error which justifies both the use of confidences \u2014 partial rules and partial labeling of the unlabeled data \u2014 and the use of an agreement-based objective function as sug- gested by Collins and Singer. Our bounds apply to the multiclass case, i.e., where instances are to be assigned one of labels for . One well-known form of bootstrapping is the EM algorithm (Dempster, Laird and Rubin, 1977). This algorithm iteratively updates model parameters by using the current model to infer (a probability distribution on) labels for the unlabeled data and then adjusting the model parameters to fit the (distribution on) filled-in labels. When the model defines a joint probability distribution over observable data and unobservable labels, each iteration of the EM algorithm can be shown to increase the probability of the observable data given the model parameters. However, EM is often subject to local minima \u2014 situations in which the filled-in data and the model parameters fit each other well but the model parameters are far from their maximum-likelihood values. Furthermore, even if EM does find the globally optimal maximum likelihood parameters, a model with a large number of parameters will over-fit the data. No PAC-style guarantee has yet been given for the generalization accuracy of the maximum likelihood model.",
        "date": "2001Advances",
        "authers": [
            "Sanjoy Dasgupta",
            "Michael L. Littman",
            "David Allen Mcallester"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221995817_Maximum_Likelihood_from_Incomplete_Data_Via_EM_Algorithm",
            "https://www.researchgate.net/publication/2457211_Combining_Labeled_and_Unlabeled_Data_with_Co-Training",
            "https://www.researchgate.net/publication/2298037_Unsupervised_Word_Sense_Disambiguation_Rivaling_Supervised_Methods"
        ]
    },
    "paper116": {
        "id": "268237865",
        "title": "Better k -best parsing",
        "abstract": "We discuss the relevance of k-best parsing to recent applications in natural language processing, and develop efficient algorithms for k-best trees in the framework of hypergraph parsing. To demonstrate the efficiency, scalability and accuracy of these algorithms, we present experiments on Bikel's implementation of Collins' lexicalized PCFG model, and on Chiang's CFG-based decoder for hierarchical phrase-based translation. We show in particular how the improved output of our algorithms has the potential to improve results from parse reranking systems and other applications.",
        "date": "2005",
        "authers": [
            "Liang Huang",
            "David Chiang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/225179572_An_Overview_of_Probabilistic_Tree_Transducers_for_Natural_Language_Processing",
            "https://www.researchgate.net/publication/220873101_Online_Large-Margin_Training_of_Dependency_Parsers",
            "https://www.researchgate.net/publication/220355462_The_Alignment_Template_Approach_to_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/2850230_Parsing_And_Hypergraphs",
            "https://www.researchgate.net/publication/2356246_Parsing_with_the_Shortest_Derivation",
            "https://www.researchgate.net/publication/312607081_Building_a_large_annotated_corpus_of_english_The_penn_treebank",
            "https://www.researchgate.net/publication/303147113_Compositional_Semantics_With_Lexicalized_Tree-Adjoining_Grammar_LTAG_How_Much_Underspecification_is_Necessary",
            "https://www.researchgate.net/publication/262349927_Discriminative_Reranking_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/247442902_Introduction_To_Algorithms"
        ]
    },
    "paper117": {
        "id": "230876697",
        "title": "North American News Text Corpus",
        "abstract": "",
        "date": "1995",
        "authers": [
            "David Graff"
        ],
        "refrences": []
    },
    "paper118": {
        "id": "230876655",
        "title": "Applying Cotraining Methods to Statistical Parsing",
        "abstract": "",
        "date": "2001",
        "authers": [
            "S Anoop"
        ],
        "refrences": []
    },
    "paper119": {
        "id": "229078318",
        "title": "Combining Labeled and Unlabeld Data with Co-Training",
        "abstract": "",
        "date": "1998",
        "authers": [
            "Avrim Blum",
            "Tom Mitchell"
        ],
        "refrences": []
    },
    "paper120": {
        "id": "223311595",
        "title": "MAP adaptation of stochastic grammars",
        "abstract": "This paper investigates supervised and unsupervised adaptation of stochastic grammars, including n-gram language models and probabilistic context-free grammars (PCFGs), to a new domain. It is shown that the commonly used approaches of count merging and model interpolation are special cases of a more general maximum a posteriori (MAP) framework, which additionally allows for alternate adaptation approaches. This paper investigates the effectiveness of different adaptation strategies, and, in particular, focuses on the need for supervision in the adaptation process. We show that n-gram models as well as PCFGs benefit from either supervised or unsupervised MAP adaptation in various tasks. For n-gram models, we compare the benefit from supervised adaptation with that of unsupervised adaptation on a speech recognition task with an adaptation sample of limited size (about 17 h), and show that unsupervised adaptation can obtain 51% of the 7.7% adaptation gain obtained by supervised adaptation. We also investigate the benefit of using multiple word hypotheses (in the form of a word lattice) for unsupervised adaptation on a speech recognition task for which there was a much larger adaptation sample available. The use of word lattices for adaptation required the derivation of a generalization of the well-known Good-Turing estimate.",
        "date": "2006Computer",
        "authers": [
            "Michiel Bacchiani",
            "Michael Riley",
            "Brian Roark",
            "Richard Sproat"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/263890871_Unsupervised_language_model_adaptation",
            "https://www.researchgate.net/publication/220685657_The_zero-frequency_problem_Estimating_the_probabilities_of_novel_events_in_adaptive_text_compression",
            "https://www.researchgate.net/publication/220475988_Automated_Natural_Spoken_Dialog",
            "https://www.researchgate.net/publication/220355374_Estimation_of_Probabilistic_Context-Free_Grammars",
            "https://www.researchgate.net/publication/4084664_Good-Turing_estimation_from_word_lattices_for_unsupervised_language_model_adaptation",
            "https://www.researchgate.net/publication/3333325_Lee_C_Maximum_a_posteriori_estimation_for_multivariate_Gaussian_mixture_observations_of_Markov_chains_IEEE_Trans_Speech_Audio_Process_2_291-298",
            "https://www.researchgate.net/publication/2955633_Automated_natural_spoken_dialog",
            "https://www.researchgate.net/publication/2927500_Example_Selection_for_Bootstrapping_Statistical_Parsers",
            "https://www.researchgate.net/publication/2910947_Automatic_Transcription_Of_Voicemail_At_Att",
            "https://www.researchgate.net/publication/2876571_Supervised_and_unsupervised_PCFG_adaptation_to_novel_domains"
        ]
    },
    "paper121": {
        "id": "221275760",
        "title": "Computation of the N Best Parse Trees for Weighted and Stochastic Context-Free Grammars",
        "abstract": "Context-Free Grammars are the object of increasing interest in the pattern recognition research community in an attempt to\novercome the limited modeling capabilities of the simpler regular grammars, and have application in a variety of fields such\nas language modeling, speech recognition, optical character recognition, computational biology, etc. This paper proposes an\nefficient algorithm to solve one of the problems associated to the use of weighted and stochastic Context-Free Grammars: the\nproblem of computing the N best parse trees of a given string. After the best parse tree has been computed using the CYK algorithm, a large number of\nalternative parse trees are obtained, in order by weight (or probability), in a small fraction of the time required by the\nCYK algorithm to find the best parse tree. This is confirmed by experimental results using grammars from two different domains:\na chromosome grammar, and a grammar modeling natural language sentences from the Wall Street Journal corpus.",
        "date": "2000Lecture",
        "authers": [
            "V\u00edctor M. Jim\u00e9nez",
            "Andr\u00e9s Marzal"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/242394905_Basic_Methods_of_Probabilistic_Context_Free_Grammars",
            "https://www.researchgate.net/publication/221482600_Estimation_of_the_probability_distributions_of_stochastic_context-free_grammars_from_the_k-best_derivations",
            "https://www.researchgate.net/publication/221478582_Learning_of_stochastic_context-free_grammars_by_means_of_estimation_algorithms",
            "https://www.researchgate.net/publication/31447209_Stochastic_Context-Free_Grammars_for_tRNA_Modeling",
            "https://www.researchgate.net/publication/312607081_Building_a_large_annotated_corpus_of_english_The_penn_treebank",
            "https://www.researchgate.net/publication/267149006_Syntactic_Pattern_Recognition_and_Applications",
            "https://www.researchgate.net/publication/262493823_The_Art_of_Computer_Programming",
            "https://www.researchgate.net/publication/242361757_Introduction_to_Formal_Language_Theory",
            "https://www.researchgate.net/publication/236411695_Syntactic_Pattern_Recognition_An_Introduction",
            "https://www.researchgate.net/publication/222994624_Applications_of_stochastic_context-free_grammars_using_the_Inside-Outside_algorithm"
        ]
    },
    "paper122": {
        "id": "220875255",
        "title": "An Empirical Study of Smoothing Techniques for Language Modeling",
        "abstract": "We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including those described by Jelinek and Mercer (1980); Katz (1987); Bell, Cleary and Witten (1990); Ney, Essen and Kneser (1994), and Kneser and Ney (1995). We investigate how factors such as training data size, training corpus (e.g. Brown vs. Wall Street Journal), count cutoffs, and n -gram order (bigram vs. trigram) affect the relative performance of these methods, which is measured through the cross-entropy of test data. We find that these factors can significantly affect the relative performance of models, with the most significant factor being training data size. Since no previous comparisons have examined these factors systematically, this is the first thorough characterization of the relative performance of various algorithms. In addition, we introduce methodologies for analyzing smoothing algorithm efficacy in detail, and using these techniques we motivate a novel variation of Kneser\u2013Ney smoothing that consistently outperforms all other algorithms evaluated. Finally, results showing that improved language model smoothing leads to improved speech recognition performance are presented.",
        "date": "1996Computer",
        "authers": [
            "Stanley F. Chen",
            "Joshua Goodman"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/301144179_Estimation_Procedures_for_Language_Context_Poor_Estimates_are_Worse_than_None",
            "https://www.researchgate.net/publication/248593046_Combining_Syntactic_Knowledge_and_Visual_Text_Recognition_A_Hidden_Markov_Model_for_Part_of_Speech_Tagging_In_A_Word_Recognition_Algorithm",
            "https://www.researchgate.net/publication/230875889_An_Estimate_of_an_Upper_Bound_for_the_Entropy_of_English",
            "https://www.researchgate.net/publication/224377724_A_Maximum_Likelihood_Approach_to_Continuous_Speech_Recognition",
            "https://www.researchgate.net/publication/221102042_A_Spelling_Correction_Program_Based_on_a_Noisy_Channel_Model",
            "https://www.researchgate.net/publication/220685657_The_zero-frequency_problem_Estimating_the_probabilities_of_novel_events_in_adaptive_text_compression",
            "https://www.researchgate.net/publication/220355244_Class-Based_n-gram_Models_of_Natural_Language",
            "https://www.researchgate.net/publication/1782255_Natural_Language_Parsing_as_Statistical_Pattern_Recognition",
            "https://www.researchgate.net/publication/313201001_The_population_frequencies_of_species_and_the_estimation_of_population_parameters",
            "https://www.researchgate.net/publication/303517837_Numerical_recipes_in_C"
        ]
    },
    "paper123": {
        "id": "220875180",
        "title": "Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking",
        "abstract": "Discriminative reranking is one method for constructing high-performance statis- tical parsers (Collins, 2000). A discrim- inative reranker requires a source of can- didate parses for each sentence. This pa- per describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000). This method gener- ates 50-best lists that are of substantially higher quality than previously obtainable. We used these parses as the input to a MaxEnt reranker (Johnson et al., 1999; Riezler et al., 2002) that selects the best parse from the set of parses for each sen- tence, obtaining an f-score of 91.0% on sentences of length 100 or less.",
        "date": "2005",
        "authers": [
            "Eugene Charniak",
            "Mark Johnson"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220874539_Estimators_for_Stochastic_Unification-Based_Grammars",
            "https://www.researchgate.net/publication/51991698_A_Comparison_of_Algorithms_for_Maximum_Entropy_Parameter_Estimation",
            "https://www.researchgate.net/publication/3491928_The_N-best_Algorithm_An_Efficient_and_Exact_Procedure_for_Finding_the_N_Most_Likely_Sentence_Hypotheses",
            "https://www.researchgate.net/publication/2921800_In_Accurate_Unlexicalized_Parsing",
            "https://www.researchgate.net/publication/2839498_Parsing_the_Wall_Street_Journal_using_a_Lexical-Functional_Grammar_and_Discriminative_Estimation_Techniques",
            "https://www.researchgate.net/publication/2561857_An_Efficient_Implementation_of_a_New_DOP_Model",
            "https://www.researchgate.net/publication/268237865_Better_k_-best_parsing",
            "https://www.researchgate.net/publication/262349927_Discriminative_Reranking_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/259810695_A_Transformational_Approach_to_English_Syntax_Root_Structure-Preserving_and_Local_Transformations",
            "https://www.researchgate.net/publication/228609663_Projection_Heads_and_Optimality"
        ]
    },
    "paper124": {
        "id": "221101491",
        "title": "When is Self-Training Effective for Parsing",
        "abstract": "Self-training has been shown capable of improving on state-of-the-art parser per- formance (McClosky et al., 2006) despite the conventional wisdom on the matter and several studies to the contrary (Charniak, 1997; Steedman et al., 2003). However, it has remained unclear when and why self- training is helpful. In this paper, we test four hypotheses (namely, presence of a phase transition, impact of search errors, value of non-generative reranker features, and effects of unknown words). From these experiments, we gain a better un- derstanding of why self-training works for parsing. Since improvements from self- training are correlated with unknown bi- grams and biheads but not unknown words, the benefit of self-training appears most in- fluenced by seeing known words in new combinations.",
        "date": "2008",
        "authers": [
            "David McClosky",
            "Eugene Charniak",
            "Mark Johnson"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/239807299_CLSP_WS02_Final_Report_Semi-Supervised_Training_for_Statistical_Parsing",
            "https://www.researchgate.net/publication/220874688_Constituent_Parsing_with_Incremental_Sigmoid_Belief_Networks",
            "https://www.researchgate.net/publication/220873863_Learning_Accurate_Compact_and_Interpretable_Tree_Annotation",
            "https://www.researchgate.net/publication/220817154_Towards_Robust_Semantic_Role_Labeling",
            "https://www.researchgate.net/publication/312607081_Building_a_large_annotated_corpus_of_english_The_penn_treebank",
            "https://www.researchgate.net/publication/238198632_Building_a_large_natural_language_corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/230876697_North_American_News_Text_Corpus",
            "https://www.researchgate.net/publication/220875180_Coarse-to-Fine_n-Best_Parsing_and_MaxEnt_Discriminative_Reranking",
            "https://www.researchgate.net/publication/220873964_Self-Training_for_Enhancement_and_Domain_Adaptation_of_Statistical_Parsers_Trained_on_Small_Datasets"
        ]
    },
    "paper125": {
        "id": "221012635",
        "title": "Mandarin Part-of-Speech Tagging and Discriminative Reranking",
        "abstract": "",
        "date": "2007",
        "authers": [
            "Zhongqiang Huang",
            "Mary Harper",
            "Wen Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/228734693_Morphological_features_help_POS_tagging_of_unknown_words_across_language_varieties",
            "https://www.researchgate.net/publication/224640972_Reranking_for_Sentence_Boundary_Detection_in_Conversational_Speech",
            "https://www.researchgate.net/publication/247932100_The_morphology_of_Chinese",
            "https://www.researchgate.net/publication/228649189_Re-ranking_algorithms_for_name_tagging",
            "https://www.researchgate.net/publication/228057950_Conditional_Random_Fields_Probabilistic_Models_for_Segmenting_and_Labeling_Sequence_Data",
            "https://www.researchgate.net/publication/225070191_A_Decision-Theoretic_Generalization_of_On-Line_Learning_and_an_Application_to_Boosting",
            "https://www.researchgate.net/publication/221346436_An_Efficient_Boosting_Algorithm_for_Combining_Preferences",
            "https://www.researchgate.net/publication/221102892_Building_a_Large-Scale_Annotated_Chinese_Corpus",
            "https://www.researchgate.net/publication/220875180_Coarse-to-Fine_n-Best_Parsing_and_MaxEnt_Discriminative_Reranking",
            "https://www.researchgate.net/publication/220355542_Discriminative_Reranking_for_Natural_Language_Parsing"
        ]
    },
    "paper126": {
        "id": "220875081",
        "title": "Probabilistic CFG with Latent Annotations",
        "abstract": "This paper defines a generative probabilis- tic model of parse trees, which we call PCFG-LA. This model is an extension of PCFG in which non-terminal symbols are augmented with latent variables. Fine- grained CFG rules are automatically in- duced from a parsed corpus by training a PCFG-LA model using an EM-algorithm. Because exact parsing with a PCFG-LA is NP-hard, several approximations are de- scribed and empirically compared. In ex- periments using the Penn WSJ corpus, our automatically trained model gave a per- formance of 86.6% (F , sentences 40 words), which is comparable to that of an unlexicalized PCFG parser created using extensive manual feature selection.",
        "date": "2005",
        "authers": [
            "Takuya Matsuzaki",
            "Yusuke Miyao",
            "Jun'ichi Tsujii"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220816667_Inducing_History_Representations_for_Broad_Coverage_Statistical_Parsing",
            "https://www.researchgate.net/publication/292453644_Computational_complexity_of_probabilistic_disambiguation_NP-completeness_results_for_parsing_problems_that_arise_in_speech_and_language_processing_applications",
            "https://www.researchgate.net/publication/246297098_Generalizationspecialization_of_context_free_grammars_based-on_entropy_of_non-terminals",
            "https://www.researchgate.net/publication/228523594_On_maximizing_metrics_for_syntactic_disambiguation",
            "https://www.researchgate.net/publication/225740821_Computational_Complexity_of_Probabilistic_Disambiguation",
            "https://www.researchgate.net/publication/220873944_Parsing_the_WSJ_using_CCG_and_log-linear_models",
            "https://www.researchgate.net/publication/220488267_Efficient_Algorithms_for_Parsing_the_DOP_Model",
            "https://www.researchgate.net/publication/220355517_Head-Driven_Statistical_Models_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/2929293_Recovering_Latent_Information_in_Treebanks",
            "https://www.researchgate.net/publication/2922698_Nondeterministic_LTAG_Derivation_Tree_Extraction"
        ]
    },
    "paper127": {
        "id": "221012840",
        "title": "Sparse Multi-Scale Grammars for Discriminative Latent Variable Parsing",
        "abstract": "We present a discriminative, latent variable approach to syntactic parsing in which rules exist at multiple scales of refinement. The model is formally a latent variable CRF gram- mar over trees, learned by iteratively splitting grammar productions (not categories). Dif- ferent regions of the grammar are refined to different degrees, yielding grammars which are three orders of magnitude smaller than the single-scale baseline and 20 times smaller than the split-and-merge grammars of Petrov et al. (2006). In addition, our discriminative approach integrally admits features beyond lo- cal tree configurations. We present a multi- scale training method along with an efficient CKY-style dynamic program. On a variety of domains and languages, this method produces the best published parsing accuracies with the smallest reported grammars.",
        "date": "2008",
        "authers": [
            "Slav Petrov",
            "Dan Klein"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221013249_The_infinite_PCFG_using_hierarchical_Dirichlet_processes",
            "https://www.researchgate.net/publication/221012623_Max-Margin_Parsing",
            "https://www.researchgate.net/publication/220875081_Probabilistic_CFG_with_Latent_Annotations",
            "https://www.researchgate.net/publication/220874765_Lexicalization_in_Crosslinguistic_Probabilistic_Parsing_The_Case_of_French",
            "https://www.researchgate.net/publication/220874045_Discriminative_Training_of_a_Neural_Network_Statistical_Parser",
            "https://www.researchgate.net/publication/220873863_Learning_Accurate_Compact_and_Interpretable_Tree_Annotation",
            "https://www.researchgate.net/publication/220873596_Efficient_Feature-based_Conditional_Random_Field_Parsing",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/2921800_In_Accurate_Unlexicalized_Parsing",
            "https://www.researchgate.net/publication/2476043_An_Annotation_Scheme_for_Free_Word_Order_Languages"
        ]
    },
    "paper128": {
        "id": "220874256",
        "title": "Semi-Supervised Convex Training for Dependency Parsing",
        "abstract": "",
        "date": "2008",
        "authers": [
            "Qin Iris Wang",
            "Dale Schuurmans",
            "Dekang Lin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/228916842_Statistical_dependency_analysis_with_support_vector_machines",
            "https://www.researchgate.net/publication/228058014_Pattern_Classification",
            "https://www.researchgate.net/publication/221101491_When_is_Self-Training_Effective_for_Parsing",
            "https://www.researchgate.net/publication/220874801_Reranking_and_Self-Training_for_Parser_Adaptation",
            "https://www.researchgate.net/publication/220874243_Corpus-Based_Induction_of_Syntactic_Structure_Models_of_Dependency_and_Constituency",
            "https://www.researchgate.net/publication/220874121_A_Generative_Constituent-Context_Model_for_Improved_Grammar_Induction",
            "https://www.researchgate.net/publication/220873101_Online_Large-Margin_Training_of_Dependency_Parsers",
            "https://www.researchgate.net/publication/220320285_The_Entire_Regularization_Path_for_the_Support_Vector_Machine",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank"
        ]
    },
    "paper129": {
        "id": "220873964",
        "title": "Self-Training for Enhancement and Domain Adaptation of Statistical Parsers Trained on Small Datasets",
        "abstract": "Creating large amounts of annotated data to train statistical PCFG parsers is expensive, and the performance of such parsers declines when training and test data are taken from different domains. In this paper we use self- training in order to improve the quality of a parser and to adapt it to a different do- main, using only small amounts of manually annotated seed data. We report significant improvement both when the seed and test data are in the same domain and in the out- of-domain adaptation scenario. In particu- lar, we achieve 50% reduction in annotation cost for the in-domain case, yielding an im- provement of 66% over previous work, and a 20-33% reduction for the domain adaptation case. This is the first time that self-training with small labeled datasets is applied suc- cessfully to these tasks. We were also able to formulate a characterization of when self- training is valuable.",
        "date": "2007",
        "authers": [
            "Roi Reichart",
            "Ari Rappoport"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/221101491_When_is_Self-Training_Effective_for_Parsing",
            "https://www.researchgate.net/publication/220874801_Reranking_and_Self-Training_for_Parser_Adaptation",
            "https://www.researchgate.net/publication/220814356_A_Two-Stage_Method_for_Active_Learning_of_Statistical_Grammars",
            "https://www.researchgate.net/publication/2927500_Example_Selection_for_Bootstrapping_Statistical_Parsers",
            "https://www.researchgate.net/publication/2477043_Bootstrapping_Statistical_Parsers_from_Small_Datasets",
            "https://www.researchgate.net/publication/230876696_Rerankinng_and_Self-Training_for_Parser_Adaptation",
            "https://www.researchgate.net/publication/228796527_Corrected_co-training_for_statistical_parsers",
            "https://www.researchgate.net/publication/223311595_MAP_adaptation_of_stochastic_grammars",
            "https://www.researchgate.net/publication/220875180_Coarse-to-Fine_n-Best_Parsing_and_MaxEnt_Discriminative_Reranking"
        ]
    },
    "paper130": {
        "id": "220873958",
        "title": "Forest Reranking Discriminative Parsing with Non-Local Features",
        "abstract": "Conventional n-best reranking techniques of- ten suffer from the limited scope of the n- best list, which rules out many potentially good alternatives. We instead propose forest reranking, a method that reranks a packed for- est of exponentially many parses. Since ex- act inference is intractable with non-local fea- tures, we present an approximate algorithm in- spired by forest rescoring that makes discrim- inative training practical over the whole Tree- bank. Our final result, an F-score of 91.7, out- performs both 50-best and 100-best reranking baselines, and is better than any previously re- ported systems trained on the Treebank.",
        "date": "2008",
        "authers": [
            "Liang Huang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262408350_Effective_self-training_for_parsing",
            "https://www.researchgate.net/publication/221012623_Max-Margin_Parsing",
            "https://www.researchgate.net/publication/220874045_Discriminative_Training_of_a_Neural_Network_Statistical_Parser",
            "https://www.researchgate.net/publication/220873101_Online_Large-Margin_Training_of_Dependency_Parsers",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/2850230_Parsing_And_Hypergraphs",
            "https://www.researchgate.net/publication/2561857_An_Efficient_Implementation_of_a_New_DOP_Model",
            "https://www.researchgate.net/publication/2481913_The_Structure_of_Shared_Forests_in_Ambiguous_Parsing",
            "https://www.researchgate.net/publication/268237865_Better_k_-best_parsing",
            "https://www.researchgate.net/publication/262349927_Discriminative_Reranking_for_Natural_Language_Parsing"
        ]
    },
    "paper131": {
        "id": "220874045",
        "title": "Discriminative Training of a Neural Network Statistical Parser",
        "abstract": "Discriminative methods have shown signican t improvements over traditional generative meth- ods in many machine learning applications, but there has been dicult y in extending them to natural language parsing. One problem is that much of the work on discriminative methods conates changes to the learning method with changes to the parameterization of the problem. We show how a parser can be trained with a dis- criminative learning method while still param- eterizing the problem according to a generative probability model. We present three methods for training a neural network to estimate the probabilities for a statistical parser, one gen- erative, one discriminative, and one where the probability model is generative but the training criteria is discriminative. The latter model out- performs the previous two, achieving state-of- the-art levels of performance (90.1% F-measure on constituents).",
        "date": "2004",
        "authers": [
            "James Henderson"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220816667_Inducing_History_Representations_for_Broad_Coverage_Statistical_Parsing",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/262349927_Discriminative_Reranking_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/246304479_Generative_versus_discriminative_models_for_statistical_left-corner_parsing",
            "https://www.researchgate.net/publication/220875022_New_Ranking_Algorithms_for_Parsing_and_Tagging_Kernels_over_Discrete_Structures_and_the_Voted_Perceptron",
            "https://www.researchgate.net/publication/220355517_Head-Driven_Statistical_Models_for_Natural_Language_Parsing",
            "https://www.researchgate.net/publication/220343911_Learning_to_Parse_Natural_Language_with_Maximum_Entropy_Models",
            "https://www.researchgate.net/publication/215721451_Neural_Networks_For_Pattern_Recognition",
            "https://www.researchgate.net/publication/200033835_The_Nature_of_Statistical_Learning_Theory",
            "https://www.researchgate.net/publication/4355809_Deterministic_left_corner_parsing"
        ]
    },
    "paper132": {
        "id": "298836450",
        "title": "Automatic word sense discrimination",
        "abstract": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering, Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous worn are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from re corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.",
        "date": "1998Computational",
        "authers": [
            "H Schutze"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221299854_Using_WordNet_to_Disambiguate_Word_Senses_for_Text_Retrieval",
            "https://www.researchgate.net/publication/2633937_ScatterGather_A_Cluster-based_Approach_to_Browsing_Large_Document_Collections",
            "https://www.researchgate.net/publication/238984455_A_Practical_Approach_for_Representing_Context_and_for_Performing_Word_Sense_Disambiguation_Using_Neural_Networks",
            "https://www.researchgate.net/publication/232878134_Contextual_Correlates_of_Semantic_Similarity",
            "https://www.researchgate.net/publication/230854746_Automatic_sense_disambiguation_using_machine_readable_dictionaries_How_to_tell_a_pine_cone_from_an_ice_cream_cone",
            "https://www.researchgate.net/publication/229593960_Word-Word_Associations_in_Document_Retrieval_Systems",
            "https://www.researchgate.net/publication/228057706_Indexing_By_Latent_Semantic_Analysis",
            "https://www.researchgate.net/publication/223483101_Recent_Trends_in_Hierarchic_Document_Clustering_A_Critical_Review",
            "https://www.researchgate.net/publication/222393384_Experiment_on_linguistically_based_term_associations",
            "https://www.researchgate.net/publication/222281706_A_cooccurrence-based_thesaurus_and_two_applications_to_Information_Retrieval"
        ]
    },
    "paper133": {
        "id": "292453644",
        "title": "Computational complexity of probabilistic disambiguation NP-completeness results for parsing problems that arise in speech and language processing applications",
        "abstract": "Recent models of natural language processing employ statistical reasoning for dealing with the ambiguity of formal grammars. In this approach, statistics, concerning the various linguistic phenomena of interest, are gathered from actual linguistic data and used to estimate the probabilities of the various entities that are generated by a given grammar, e.g., derivations, parse-trees and sentences. The extension of grammars with probabilities makes it possible to state ambiguity resolution as a constrained optimization formula, which aims at maximizing the probability of some entity that the grammar generates given the input (e.g., maximum probability parse-tree given some input sentence). The implementation of these optimization formulae in efficient algorithms, however, does not always proceed smoothly. In this paper, we address the computational complexity of ambiguity resolution under various kinds of probabilistic models. We provide proofs that some, frequently occurring problems of ambiguity resolution are NP-complete. These problems are encountered in various applications, e.g., language understanding for text- and speech-based applications. Assuming the common model of computation, this result implies that, for many existing probabilistic models it is not possible to devise tractable algorithms for solving these optimization problems.",
        "date": "2002",
        "authers": [
            "K. Sima'an"
        ],
        "refrences": []
    },
    "paper134": {
        "id": "288942058",
        "title": "A clustering technique for summarizing multivariate data",
        "abstract": "",
        "date": "1976",
        "authers": [
            "G. Ball",
            "D. Hall"
        ],
        "refrences": []
    },
    "paper135": {
        "id": "242430108",
        "title": "Aspects of The Theory of Syntax",
        "abstract": "",
        "date": "1970College",
        "authers": [
            "Noam Chomsky"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/235039252_Measures_of_Syntactic_Complexity",
            "https://www.researchgate.net/publication/9517409_Movement-Produced_Stimulation_in_the_Development_of_Visually_Guided_Behavior",
            "https://www.researchgate.net/publication/324640748_Applikativnaja_porozdajuscaja_model'_i_iscislenie_transformacij_v_russkom_jazyke",
            "https://www.researchgate.net/publication/324304653_The_Principles_of_Semantics",
            "https://www.researchgate.net/publication/320181926_Word_and_Object",
            "https://www.researchgate.net/publication/313154879_The_misbehavior_of_organisms",
            "https://www.researchgate.net/publication/303837236_Negation_in_English",
            "https://www.researchgate.net/publication/290803936_Beitrag_zur_allgemeinen_Kasuslehre",
            "https://www.researchgate.net/publication/285058764_Receptive_fields_binocular_interaction_and_functional_architecture_in_the_cat's_visual_cortex",
            "https://www.researchgate.net/publication/284399676_The_Position_of_Embedding_Transformations_in_a_Grammar"
        ]
    },
    "paper136": {
        "id": "225740821",
        "title": "Computational Complexity of Probabilistic Disambiguation",
        "abstract": "Recent models of natural language processing employ statistical reasoning for dealing with the ambiguity of formal grammars. In this approach, statistics, concerning the various linguistic phenomena of interest, are gathered from actual linguistic data and used to estimate the probabilities of the various entities that are generated by a given grammar, e.g., derivations, parse-trees and sentences. The extension of grammars with probabilities makes it possible to state ambiguity resolution as a constrained optimization formula, which aims at maximizing the probability of some entity that the grammar generates given the input (e.g., maximum probability parse-tree given some input sentence). The implementation of these optimization formulae in efficient algorithms, however, does not always proceed smoothly. In this paper, we address the computational complexity of ambiguity resolution under various kinds of probabilistic models. We provide proofs that some, frequently occurring problems of ambiguity resolution are NP-complete. These problems are encountered in various applications, e.g., language understanding for text- and speech-based applications. Assuming the common model of computation, this result implies that, for many existing probabilistic models it is not possible to devise tractable algorithms for solving these optimization problems.",
        "date": "2002Grammars",
        "authers": [
            "Khalil Sima'an"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319393405_An_Introduction_to_Kolmogorov_Complexity_and_Its_Applications",
            "https://www.researchgate.net/publication/242394905_Basic_Methods_of_Probabilistic_Context_Free_Grammars",
            "https://www.researchgate.net/publication/221101811_A_Computational_Model_Of_Language_Performance_Data_Oriented_Parsing",
            "https://www.researchgate.net/publication/220874758_The_Intersection_of_Finite_State_Automata_and_Definite_Clause_Grammars",
            "https://www.researchgate.net/publication/220873033_Statistical_Decision-Tree_Models_for_Parsing",
            "https://www.researchgate.net/publication/220816736_Decision_Tree_Parsing_using_a_Hidden_Derivation_Model",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/38358970_A_Universal_Prior_for_Integers_and_Estimation_by_Minimum_Description_Length",
            "https://www.researchgate.net/publication/2607825_A_Corpus-based_Probabilistic_Grammar_with_Only_Two_Non-terminals",
            "https://www.researchgate.net/publication/2475419_A_Probabilistic_Corpus-Driven_Model_for_Lexical-Functional_Analysis"
        ]
    },
    "paper137": {
        "id": "225517426",
        "title": "Inducing probabilistic grammars by Bayesian model merging",
        "abstract": "We describe a framework for inducing probabilistic grammars from corpora of positive samples. First, samples are incorporated by adding ad-hoc rules to a working grammar; subsequently, elements of the model (such as states or nonterminals) are merged to achieve generalization and a more compact representation. The choice of what to merge and when to stop is governed by the Bayesian posterior probability of the grammar given the data, which formalizes a trade-off between a close fit to the data and a default preference for simpler models (Occam's Razor). The general scheme is illustrated using three types of probabilistic grammars: Hidden Markov models, class-based n-grams, and stochastic context-free grammars.",
        "date": "1970",
        "authers": [
            "Andreas Stolcke",
            "Stephen Omohundro"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/274364636_Maximum-Entropy_and_Bayesian_Methods_in_Science_and_Engineering",
            "https://www.researchgate.net/publication/220312496_Grammatical_inference_by_Hill_Climbing",
            "https://www.researchgate.net/publication/220049445_An_Introduction_to_Hidden_Markov_Models",
            "https://www.researchgate.net/publication/38364607_A_Maximization_Technique_Occurring_in_Statistical_Analysis_of_Probabilistic_Functions_of_Markov_Chains",
            "https://www.researchgate.net/publication/35846898_A_study_of_grammatical_inference"
        ]
    },
    "paper138": {
        "id": "221112104",
        "title": "Inducing Head-Driven PCFGs with Latent Heads Refining a Tree-Bank Grammar for Parsing",
        "abstract": "Although state-of-the-art parsers for natural language are lexicalized, it was recently shown that an accurate unlexicalized parser for the Penn tree-bank can be simply read off a manually refined tree-bank. While lexicalized parsers often suffer from sparse data, manual mark-up is costly and largely based on individual linguistic intuition. Thus, across domains, languages, and tree-bank annotations, a fundamental question arises: Is it possible to automatically induce an accurate parser from a tree-bank without resorting to full lexicalization? In this paper, we show how to induce a probabilistic parser with latent head infor- mation from simple linguistic principles. Our parser has a performance of 85.1% (LP/LR F1), which is as good as that of early lexicalized ones. This is remarkable since the induction of probabilistic grammars is in general a hard task.",
        "date": "2005",
        "authers": [
            "Detlef Prescher"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/236157548_Factorial_Hidden_Markov_Models",
            "https://www.researchgate.net/publication/230876175_Lexical-Functional_Grammar_A_Formal_System_for_Grammatical_Representation",
            "https://www.researchgate.net/publication/220873033_Statistical_Decision-Tree_Models_for_Parsing",
            "https://www.researchgate.net/publication/220817598_A_Procedure_for_Quantitatively_Comparing_the_Syntactic_Coverage_of_English_Grammars",
            "https://www.researchgate.net/publication/220017637_Building_a_Large_Annotated_Corpus_of_English_The_Penn_Treebank",
            "https://www.researchgate.net/publication/2921800_In_Accurate_Unlexicalized_Parsing",
            "https://www.researchgate.net/publication/2912527_Probabilistic_Parsing_for_German_using_Sister-Head_Dependencies",
            "https://www.researchgate.net/publication/2522353_Factorial_Hidden_Markov_Models",
            "https://www.researchgate.net/publication/2445064_Valence_Induction_with_a_Head-Lexicalized_PCFG",
            "https://www.researchgate.net/publication/312607081_Building_a_large_annotated_corpus_of_english_The_penn_treebank"
        ]
    },
    "paper139": {
        "id": "277298117",
        "title": "Bridging Long Time Lags by Weight Guessing and Long Short Term Memory",
        "abstract": "Numerous recent papers (including many NIPS papers) focus on standard recurrent nets' inability to deal with long time lags between relevant input signals and teacher signals. Rather sophisticated, alternative methods were proposed. We first show: problems used to promote certain algorithms in numerous previous papers can be solved more quickly by random weight guessing than by the proposed algorithms. This does not mean that guessing is a good algorithm. It just casts doubt on whether the other algorithms are, or whether the chosen problems are meaningful. We then use long short term memory (LSTM), our own recent algorithm, to solve hard problems that can neither be quickly solved by random weight guessing nor by any other recurrent net algorithm we are aware of. 1 Introduction / Outline Many recent papers focus on standard recurrent nets' inability to deal with long time lags between relevant signals. See, e.g., Bengio et al., El Hihi and Bengio, and others [3, 1, 6, 15]. Rather s...",
        "date": "1996",
        "authers": [
            "Sepp Hochreiter",
            "J\u00fcrgen Schmidhuber"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/277295865_Guessing_Can_Outperform_Many_Long_Time_Lag_Algorithms",
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/243698906_Finite_State_Automata_and_Simple_Recurrent_Networks",
            "https://www.researchgate.net/publication/243683010_The_utility_driven_dynamic_error_propagation_network",
            "https://www.researchgate.net/publication/226171158_The_Induction_of_Dynamical_Recognizers",
            "https://www.researchgate.net/publication/313702304_Learning_sequential_structures_with_the_real-time_recurrent_learning_algorithm",
            "https://www.researchgate.net/publication/243763246_A_recurrent_cascade-correlation_learning_architecture",
            "https://www.researchgate.net/publication/240434405_A_focused_back_-_propagation_algorithm_for_temporal_sequence_recognition",
            "https://www.researchgate.net/publication/239594484_Dynamic_construction_of_finite-automata_from_examples_using_hill-climbing",
            "https://www.researchgate.net/publication/239062408_The_Cascade-Correlation_Learning_Algorithm"
        ]
    },
    "paper140": {
        "id": "277295865",
        "title": "Guessing Can Outperform Many Long Time Lag Algorithms",
        "abstract": "Numerous recent papers focus on standard recurrent nets' problems with long time lags between relevant signals. Some propose rather sophisticated, alternative methods. We show: many problems used to test previous methods can be solved more quickly by random weight guessing.",
        "date": "1996",
        "authers": [
            "J\u00fcrgen Schmidhuber",
            "Sepp Hochreiter"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/238833309_Learning_State_Space_Trajectories_in_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/226171158_The_Induction_of_Dynamical_Recognizers",
            "https://www.researchgate.net/publication/220500076_Induction_of_Finite-State_Languages_Using_Second-Order_Recurrent_Networks",
            "https://www.researchgate.net/publication/243683189_Complexity_of_exact_gradient_computation_algorithms_for_recurrent_neural_networks",
            "https://www.researchgate.net/publication/239594484_Dynamic_construction_of_finite-automata_from_examples_using_hill-climbing",
            "https://www.researchgate.net/publication/223416710_Discovering_Neural_Nets_with_Low_Kolmogorov_Complexity_and_High_Generalization_Capability",
            "https://www.researchgate.net/publication/220500234_Learning_Complex_Extended_Sequences_Using_the_Principle_of_History_Compression",
            "https://www.researchgate.net/publication/220500087_First-Order_Recurrent_Neural_Networks_and_Deterministic_Finite_State_Automata",
            "https://www.researchgate.net/publication/220359636_Experimental_Comparison_of_the_Effect_of_Order_in_Recurrent_Neural_Networks"
        ]
    },
    "paper141": {
        "id": "243698906",
        "title": "Finite State Automata and Simple Recurrent Networks",
        "abstract": "We explore a network architecture introduced by Elman (1988) for predicting successive elements of a sequence. The network uses the pattern of activation over a set of hidden units from time-step t\u22121, together with element t, to predict element t + 1. When the network is trained with strings from a particular finite-state grammar, it can learn to be a perfect finite-state recognizer for the grammar. When the network has a minimal number of hidden units, patterns on the hidden units come to correspond to the nodes of the grammar, although this correspondence is not necessary for the network to act as a perfect finite-state recognizer. We explore the conditions under which the network can carry information about distant sequential contingencies across intervening elements. Such information is maintained with relative ease if it is relevant at each intermediate step; it tends to be lost when intervening elements do not depend on it. At first glance this may suggest that such networks are not relevant to natural language, in which dependencies may span indefinite distances. However, embeddings in natural language are not completely independent of earlier information. The final simulation shows that long distance sequential contingencies can be encoded by the network even if only subtle statistical properties of embedded strings depend on the early information.",
        "date": "1989Neural",
        "authers": [
            "Axel Cleeremans",
            "David Servan-Schreiber",
            "James L Mcclelland"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/243743707_Learning_Internal_Representations_by_Error_Propagation",
            "https://www.researchgate.net/publication/242353012_NETtalk_a_Parallel_Network_that_Learns_to_Read_Aloud",
            "https://www.researchgate.net/publication/239059398_Leaning_internal_representations_by_back-propagating_errors",
            "https://www.researchgate.net/publication/230876307_The_case_for_interactionism_in_language_processing",
            "https://www.researchgate.net/publication/229091480_Learning_Representations_by_Back_Propagating_Errors",
            "https://www.researchgate.net/publication/222438973_Implicit_Learning_of_Artifical_Grammars"
        ]
    },
    "paper142": {
        "id": "243683010",
        "title": "The utility driven dynamic error propagation network",
        "abstract": "Error propagation networks are able to learn a variety of tasks in which a static input pattern is mapped onto a static output pattern. This paper presents a generalisation of these nets to deal with time varying, or dynamic patterns. Three possible architectures are explored which deal with learning sequences of known finite length and sequences of unknown and possibly infinite length. Several examples are given and an application to speech coding is discussed.\n\nA further development of dynamic nets is made which allows them to be trained by a signal which expresses the correctness of the output of the net, the utility signal. One possible architecture for such a utility driven dynandc net is given and a simple example is presented. Utility driven dynamic nets are potentially able to calculate and maximise any function of the input and output data streams, within the comidered conext. This is a very powerful property, and an appendix presents a comparison of the information processing in utility driven dynamic nets and that in the human brain.",
        "date": "1987",
        "authers": [
            "Tony Robinson",
            "F. Fallside"
        ],
        "refrences": []
    },
    "paper143": {
        "id": "313702304",
        "title": "Learning sequential structures with the real-time recurrent learning algorithm",
        "abstract": "",
        "date": "1989International",
        "authers": [
            "A.W. Smith",
            "D. Zipser"
        ],
        "refrences": []
    },
    "paper144": {
        "id": "263902178",
        "title": "LEARNING SEQUENTIAL STRUCTURE WITH THE REAL-TIME RECURRENT LEARNING ALGORITHM",
        "abstract": "Recurrent connections in neural networks potentially allow information about events occurring in the past to be preserved and used in current computations. How effectively this potential is realized depends on the power of the learning algorithm used. As an example of a task requiring recurrency, Servan-Schreiber, Cleeremans, and McClelland1 have applied a simple recurrent learning algorithm to the task of recognizing finite-state grammars of increasing difficulty. These nets showed considerable power and were able to learn fairly complex grammars by emulating the state machines that produced them. However, there was a limit to the difficulty of the grammars that could be learned. We have applied a more powerful recurrent learning procedure, called real-time recurrent learning2,6 (RTRL), to some of the same problems studied by Servan-Schreiber, Cleeremans, and McClelland. The RTRL algorithm solved more difficult forms of the task than the simple recurrent networks. The internal representations developed by RTRL networks revealed that they learn a rich set of internal states that represent more about the past than is required by the underlying grammar. The dynamics of the networks are determined by the state structure and are not chaotic.",
        "date": "2011International",
        "authers": [
            "Anthony W.smith",
            "Davidzipser"
        ],
        "refrences": []
    },
    "paper145": {
        "id": "243763246",
        "title": "A recurrent cascade-correlation learning architecture",
        "abstract": "",
        "date": "1991",
        "authers": [
            "Scott E. Fahlman",
            "Christian Lebiere"
        ],
        "refrences": []
    },
    "paper146": {
        "id": "243732587",
        "title": "Generalization of Back-Propagation to Recurrent Neural Networks",
        "abstract": "An adaptive neural network with asymmetric connections is introduced. This network is related to the Hopfield network with graded neurons and uses a recurrent generalization of the \u03b4 rule of Rumelhart, Hinton, and Williams to modify adaptively the synaptic weights. The new network bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler.",
        "date": "1987Physical",
        "authers": [
            "Fernando J. Pineda"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/16609657_Neurons_With_Graded_Response_Have_Collective_Computational_Properties_Like_Those_of_Two-State_Neurons",
            "https://www.researchgate.net/publication/345402887_Parallel_Distributed_Processing_Explorations_in_the_Microstructure_of_Cognition_Foundations",
            "https://www.researchgate.net/publication/243243435_A_self-optimizing_nonsymmetrical_neural_net_for_content_addressable_memory_and_pattern_recognition",
            "https://www.researchgate.net/publication/3115638_Characteristics_of_Random_Nets_of_Analog_Neuron-Like_Elements"
        ]
    },
    "paper147": {
        "id": "243683189",
        "title": "Complexity of exact gradient computation algorithms for recurrent neural networks",
        "abstract": "",
        "date": "",
        "authers": [
            "R. J. Williams"
        ],
        "refrences": []
    },
    "paper148": {
        "id": "319770123",
        "title": "Densely Connected Convolutional Networks",
        "abstract": "Recent work has shown that convolutional networks can be substantially deeper, more accurate and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper we embrace this observation and introduce the Dense Convolutional Network (DenseNet), where each layer is directly connected to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections, one between each layer and its subsequent layer (treating the input as layer 0), our network has L(L+1)/2 direct connections. For each layer, the feature maps of all preceding layers are treated as separate inputs whereas its own feature maps are passed on as inputs to all subsequent layers. Our proposed connectivity pattern has several compelling advantages: it alleviates the vanishing gradient problem and strengthens feature propagation; despite the increase in connections, it encourages feature reuse and leads to a substantial reduction of parameters; its models tend to generalize surprisingly well. We evaluate our proposed architecture on five highly competitive object recognition benchmark tasks. The DenseNet obtains significant improvements over the state-of-the-art on all five of them (e.g., yielding 3.74% test error on CIFAR-10, 19.25% on CIFAR-100 and 1.59% on SVHN).",
        "date": "2016",
        "authers": [
            "Gao Huang",
            "Zhuang Liu",
            "Kilian Weinberger"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth",
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770387_Deep_Sparse_Rectifier_Neural_Networks",
            "https://www.researchgate.net/publication/319770216_Deconstructing_the_Ladder_Network_Architecture",
            "https://www.researchgate.net/publication/319770191_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/309076254_Gradientbased_learning_applied_to_document_recognition",
            "https://www.researchgate.net/publication/306281834_Rethinking_the_Inception_Architecture_for_Computer_Vision",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images"
        ]
    },
    "paper149": {
        "id": "312216100",
        "title": "OpenNMT Open-Source Toolkit for Neural Machine Translation",
        "abstract": "We describe an open-source toolkit for neural machine translation (NMT). The toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques.",
        "date": "2017",
        "authers": [
            "Guillaume Klein",
            "Yoon Kim",
            "Yuntian Deng",
            "Jean Senellart"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308262743_What_You_Get_Is_What_You_See_A_Visual_Markup_Decompiler",
            "https://www.researchgate.net/publication/305334401_Hierarchical_Attention_Networks_for_Document_Classification",
            "https://www.researchgate.net/publication/272194766_Show_Attend_and_Tell_Neural_Image_Caption_Generation_with_Visual_Attention",
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/220874004_Moses_Open_Source_Toolkit_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/308646556_Google's_Neural_Machine_Translation_System_Bridging_the_Gap_between_Human_and_Machine_Translation",
            "https://www.researchgate.net/publication/306093856_Generating_Sentences_from_a_Continuous_Space",
            "https://www.researchgate.net/publication/284788001_rnn_Recurrent_Library_for_Torch"
        ]
    },
    "paper150": {
        "id": "311223153",
        "title": "Speedaccuracy trade-offs for modern convolutional object detectors",
        "abstract": "In this paper, we study the trade-off between accuracy and speed when building an object detection system based on convolutional neural networks. We consider three main families of detectors --- Faster R-CNN, R-FCN and SSD --- which we view as \"meta-architectures\". Each of these can be combined with different kinds of feature extractors, such as VGG, Inception or ResNet. In addition, we can vary other parameters, such as the image resolution, and the number of box proposals. We develop a unified framework (in Tensorflow) that enables us to perform a fair comparison between all of these variants. We analyze the performance of many different previously published model combinations, as well as some novel ones, and thus identify a set of models which achieve different points on the speed-accuracy tradeoff curve, ranging from fast models, suitable for use on a mobile phone, to a much slower model that achieves a new state of the art on the COCO detection challenge.",
        "date": "2016",
        "authers": [
            "Jonathan Huang",
            "Vivek Rathod",
            "Chen Sun",
            "Menglong Zhu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770289_Deep_Neural_Networks_for_Object_Detection",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/312759848_DSSD_Deconvolutional_Single_Shot_Detector",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770416_DRAW_A_Recurrent_Neural_Network_For_Image_Generation",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks",
            "https://www.researchgate.net/publication/313760952_Visual_Discovery_at_Pinterest",
            "https://www.researchgate.net/publication/312430297_Fast_Single_Shot_Detection_and_Pose_Estimation"
        ]
    },
    "paper151": {
        "id": "309766061",
        "title": "A Convolutional Encoder Model for Neural Machine Translation",
        "abstract": "The prevalent approach to neural machine translation relies on bi-directional LSTMs to encode the source sentence. In this paper we present a faster and conceptually simpler architecture based on a succession of convolutional layers. This allows to encode the entire source sentence simultaneously compared to recurrent networks for which computation is constrained by temporal dependencies. We achieve a new state-of-the-art on WMT'16 English-Romanian translation and outperform several recently published results on the WMT'15 English-German task. We also achieve almost the same accuracy as a very deep LSTM setup on WMT'14 English-French translation. Our convolutional encoder speeds up CPU decoding by more than two times at the same or higher accuracy as a strong bi-directional LSTM baseline.",
        "date": "2016",
        "authers": [
            "Jonas Gehring",
            "Michael Auli",
            "David Grangier",
            "Yann N. Dauphin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308884050_Is_Neural_Machine_Translation_Ready_for_Deployment_A_Case_Study_on_30_Translation_Directions",
            "https://www.researchgate.net/publication/308807302_Vocabulary_Selection_Strategies_for_Neural_Machine_Translation",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319769995_End-To-End_Memory_Networks",
            "https://www.researchgate.net/publication/319769905_Sequence_Level_Training_with_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/310626854_Convolutional_Neural_Network_Language_Models",
            "https://www.researchgate.net/publication/306094124_MetaMind_Neural_Machine_Translation_System_for_WMT_2016",
            "https://www.researchgate.net/publication/306093962_Edinburgh_Neural_Machine_Translation_Systems_for_WMT_16",
            "https://www.researchgate.net/publication/306093909_A_Character-level_Decoder_without_Explicit_Segmentation_for_Neural_Machine_Translation"
        ]
    },
    "paper152": {
        "id": "307747289",
        "title": "Show and tell A neural image caption generator",
        "abstract": "",
        "date": "2015",
        "authers": [
            "Oriol Vinyals",
            "Alexander Toshev",
            "Samy Bengio",
            "Dumitru Erhan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/329977566_T_ree_T_alk_Composition_and_Compression_of_Trees_for_Image_Descriptions",
            "https://www.researchgate.net/publication/329975395_Grounded_Compositional_Semantics_for_Finding_and_Describing_Images_with_Sentences",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/312714920_Improving_Image-Sentence_Embeddings_Using_Large_Weakly_Annotated_Photo_Collections",
            "https://www.researchgate.net/publication/308804607_CIDEr_Consensus-based_image_description_evaluation",
            "https://www.researchgate.net/publication/303721259_From_image_descriptions_to_visual_denotations_New_similarity_metrics_for_semantic_inference_over_event_descriptions",
            "https://www.researchgate.net/publication/290345348_Image_description_using_visual_dependency_representations",
            "https://www.researchgate.net/publication/272194743_Batch_Normalization_Accelerating_Deep_Network_Training_by_Reducing_Internal_Covariate_Shift"
        ]
    },
    "paper153": {
        "id": "306093640",
        "title": "Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond",
        "abstract": "In this work, we cast abstractive text summarization as a sequence-to-sequence problem and employ the framework of Attentional Encoder-Decoder Recurrent Neural Networks to this problem, outperforming state-of-the art model of Rush et. al. (2015) on two different corpora. We also move beyond the basic architecture, and propose several novel models to address important problems in summarization including modeling key-words, capturing the hierarchy of sentence-to-word structure and addressing the problem of words that are key to a document, but rare elsewhere. Our work shows that many of our proposed solutions contribute to further improvement in performance. In addition, we propose a new dataset consisting of multi-sentence summaries, and establish performance benchmarks for further research.",
        "date": "2016",
        "authers": [
            "Ramesh Nallapati",
            "Bowen Zhou",
            "Cicero Nogueira Dos Santos",
            "Caglar Gulcehre"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/306093072_Pointing_the_Unknown_Words",
            "https://www.researchgate.net/publication/301404465_HEADS_Headline_Generation_as_Sequence_Prediction_Using_an_Abstract_Feature-Rich_Space",
            "https://www.researchgate.net/publication/279068977_LCSTS_A_Large_Scale_Chinese_Short_Text_Summarization_Dataset",
            "https://www.researchgate.net/publication/306093832_Neural_Summarization_by_Extracting_Sentences_and_Words",
            "https://www.researchgate.net/publication/305334286_Abstractive_Sentence_Summarization_with_Attentive_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/301880883_Long_Short-Term_Memory-Networks_for_Machine_Reading",
            "https://www.researchgate.net/publication/288644117_Overcoming_the_lack_of_parallel_data_in_sentence_compression",
            "https://www.researchgate.net/publication/281487270_A_Neural_Attention_Model_for_Abstractive_Sentence_Summarization",
            "https://www.researchgate.net/publication/278048272_Teaching_Machines_to_Read_and_Comprehend",
            "https://www.researchgate.net/publication/277722709_A_Hierarchical_Neural_Autoencoder_for_Paragraphs_and_Documents"
        ]
    },
    "paper154": {
        "id": "303657108",
        "title": "TensorFlow A system for large-scale machine learning",
        "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",
        "date": "2016",
        "authers": [
            "Mart\u00edn Abadi",
            "Paul Barham",
            "Jianmin Chen",
            "Zhifeng Chen"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319769811_Fast_Algorithms_for_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/311610318_Fast_Algorithms_for_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/311474948_LINQits_big_data_on_little_clients",
            "https://www.researchgate.net/publication/308575069_Incremental_iterative_data_processing_with_timely_dataflow",
            "https://www.researchgate.net/publication/307799813_Toward_accelerating_deep_learning_at_scale_using_specialized_hardware_in_the_datacenter",
            "https://www.researchgate.net/publication/306209959_Project_adam_Building_an_efficient_and_scalable_deep_learning_training_system"
        ]
    },
    "paper155": {
        "id": "273640320",
        "title": "LSTM A search space odyssey",
        "abstract": "Several variants of the Long Short-Term Memory (LSTM) architecture for\nrecurrent neural networks have been proposed since its inception in 1995. In\nrecent years, these networks have become the state-of-the-art models for a\nvariety of machine learning problems. This has led to a renewed interest in\nunderstanding the role and utility of various computational components of\ntypical LSTM variants. In this paper, we present the first large-scale analysis\nof eight LSTM variants on three representative tasks: speech recognition,\nhandwriting recognition, and polyphonic music modeling. The hyperparameters of\nall LSTM variants for each task were optimized separately using random search\nand their importance was assessed using the powerful fANOVA framework. In\ntotal, we summarize the results of 5400 experimental runs (about 15 years of\nCPU time), which makes our study the largest of its kind on LSTM networks. Our\nresults show that none of the variants can improve upon the standard LSTM\narchitecture significantly, and demonstrate the forget gate and the output\nactivation function to be its most critical components. We further observe that\nthe studied hyperparameters are virtually independent and derive guidelines for\ntheir efficient adjustment.",
        "date": "2015IEEE",
        "authers": [
            "Klaus Greff",
            "Rupesh Kumar Srivastava",
            "Jan Koutn\u00edk",
            "Bas R. Steunebrink"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308034527_Long-term_recurrent_convolutional_networks_for_visual_recognition_and_description",
            "https://www.researchgate.net/publication/287850221_An_efficient_approach_for_assessing_hyperparameter_importance",
            "https://www.researchgate.net/publication/317646849_Dictionary_of_Linguistics_and_Phonetics",
            "https://www.researchgate.net/publication/287741874_TTS_synthesis_with_bidirectional_LSTM_based_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/287059155_Fast_and_Robust_Training_of_Recurrent_Neural_Networks_for_Offline_Handwriting_Recognition",
            "https://www.researchgate.net/publication/286271944_On_the_importance_of_initialization_and_momentum_in_deep_learning",
            "https://www.researchgate.net/publication/285008105_Gradient_Flow_in_Recurrent_Nets_The_Difficulty_of_Learning_LongTerm_Dependencies",
            "https://www.researchgate.net/publication/284867766_Distance_measures_for_speech_recognition_psychological_and_instrumental",
            "https://www.researchgate.net/publication/279815520_Heterogeneous_acoustic_measurements_and_multiple_classifiers_for_speech_recognition",
            "https://www.researchgate.net/publication/279714069_Long_short-term_memory_recurrent_neural_network_architectures_for_large_scale_acoustic_modeling"
        ]
    },
    "paper156": {
        "id": "273388012",
        "title": "Neural Responding Machine for Short-Text Conversation",
        "abstract": "We propose Neural Responding Machine (NRM), a neural network-based response\ngenerator for Short-Text Conversation. NRM takes the general encoder-decoder\nframework: it formalizes the generation of response as a decoding process based\non the latent representation of the input text, while both encoding and\ndecoding are realized with recurrent neural networks (RNN). The NRM is trained\nwith a large amount of one-round conversation data collected from a\nmicroblogging service. Empirical study shows that NRM can generate\ngrammatically correct and content-wise appropriate responses to over 75% of the\ninput text, outperforming state-of-the-arts in the same setting, including\nretrieval-based and SMT-based models.",
        "date": "2015",
        "authers": [
            "Lifeng Shang",
            "Zhengdong Lu",
            "Hang Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/287781150_A_dataset_for_research_on_short-text_conversation",
            "https://www.researchgate.net/publication/268382939_Reinforcement_Learning_of_Question-Answering_Dialogue_Policies_for_Virtual_Museum_Guides",
            "https://www.researchgate.net/publication/265252627_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate",
            "https://www.researchgate.net/publication/265209669_An_Information_Retrieval_Approach_to_Short_Text_Conversation",
            "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/311469848_Recurrent_neural_network_based_language_model",
            "https://www.researchgate.net/publication/289758666_Recurrent_continuous_translation_models",
            "https://www.researchgate.net/publication/283112108_Joint_language_and_translation_modeling_with_recurrent_neural_networks",
            "https://www.researchgate.net/publication/265554383_Sequence_to_Sequence_Learning_with_Neural_Networks"
        ]
    },
    "paper157": {
        "id": "272194766",
        "title": "Show Attend and Tell Neural Image Caption Generation with Visual Attention",
        "abstract": "Inspired by recent work in machine translation and object detection, we\nintroduce an attention based model that automatically learns to describe the\ncontent of images. We describe how we can train this model in a deterministic\nmanner using standard backpropagation techniques and stochastically by\nmaximizing a variational lower bound. We also show through visualization how\nthe model is able to automatically learn to fix its gaze on salient objects\nwhile generating the corresponding words in the output sequence. We validate\nthe use of attention with state-of-the-art performance on three benchmark\ndatasets: Flickr8k, Flickr30k and MS COCO.",
        "date": "2015",
        "authers": [
            "Kelvin Xu",
            "Jimmy Ba",
            "Ryan Kiros",
            "Kyunghyun Cho"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/307747289_Show_and_tell_A_neural_image_caption_generator",
            "https://www.researchgate.net/publication/270878844_Meteor_Universal_Language_Specific_Translation_Evaluation_for_Any_Target_Language",
            "https://www.researchgate.net/publication/329977566_T_ree_T_alk_Composition_and_Compression_of_Trees_for_Image_Descriptions",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770249_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/308871635_Mind's_eye_A_recurrent_visual_representation_for_image_caption_generation",
            "https://www.researchgate.net/publication/303721259_From_image_descriptions_to_visual_denotations_New_similarity_metrics_for_semantic_inference_over_event_descriptions",
            "https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting",
            "https://www.researchgate.net/publication/269935079_Adam_A_Method_for_Stochastic_Optimization"
        ]
    },
    "paper158": {
        "id": "319770289",
        "title": "Deep Neural Networks for Object Detection",
        "abstract": "Deep Neural Networks (DNNs) have recently shown outstanding performance on image classification tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing objects of various classes. We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks. We define a multi-scale inference procedure which is able to produce high-resolution object detections at a lowcost by a fewnetwork applications. State-of-the-art performance of the approach is shown on Pascal VOC.",
        "date": "2013",
        "authers": [
            "Christian Szegedy",
            "Alexander Toshev",
            "Dumitru Erhan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/240308781_Learning_Hierarchical_Features_for_Scene_Labeling",
            "https://www.researchgate.net/publication/230690781_Object-Class_Segmentation_using_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/221363369_Towards_Scalable_Representations_of_Object_Categories_Learning_a_Hierarchy_of_Parts",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/319770820_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/267709055_Deep_Neural_Networks_Segment_Neuronal_Membranes_in_Electron_Microscopy_Images",
            "https://www.researchgate.net/publication/237417270_Discriminatively_Trained_Mixtures_of_Deformable_Part_Models",
            "https://www.researchgate.net/publication/221497515_Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization",
            "https://www.researchgate.net/publication/221364242_Latent_Hierarchical_Structural_Learning_for_Object_Detection"
        ]
    },
    "paper159": {
        "id": "289917319",
        "title": "Deep Neural Networks for object detection",
        "abstract": "Deep Neural Networks (DNNs) have recently shown outstanding performance on image classification tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing objects of various classes. We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks. We define a multi-scale inference procedure which is able to produce high-resolution object detections at a low cost by a few network applications. State-of-the-art performance of the approach is shown on Pascal VOC.",
        "date": "2013Advances",
        "authers": [
            "C. Szegedy",
            "Alexander Toshev",
            "Dumitru Erhan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/240308781_Learning_Hierarchical_Features_for_Scene_Labeling",
            "https://www.researchgate.net/publication/230690781_Object-Class_Segmentation_using_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/319770820_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/281327886_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/267709055_Deep_Neural_Networks_Segment_Neuronal_Membranes_in_Electron_Microscopy_Images",
            "https://www.researchgate.net/publication/237417270_Discriminatively_Trained_Mixtures_of_Deformable_Part_Models",
            "https://www.researchgate.net/publication/221497515_Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization",
            "https://www.researchgate.net/publication/221364242_Latent_Hierarchical_Structural_Learning_for_Object_Detection"
        ]
    },
    "paper160": {
        "id": "266657849",
        "title": "Scaling up matrix computations on shared-memory manycore systems with 1000 CPU cores",
        "abstract": "While the growing number of cores per chip allows researchers to solve larger scientific and engineering problems, the parallel efficiency of the deployed parallel software starts to decrease. This unscalability problem happens to both vendor-provided and open-source software and wastes CPU cycles and energy. By expecting CPUs with hundreds of cores to be imminent, we have designed a new framework to perform matrix computations for massively many cores. Our performance analysis on manycore systems shows that the unscalability bottleneck is related to Non-Uniform Memory Access (NUMA): memory bus contention and remote memory access latency. To overcome the bottleneck, we have designed NUMA-aware tile algorithms with the help of a dynamic scheduling runtime system to minimize NUMA memory accesses. The main idea is to identify the data that is, either read a number of times or written once by a thread resident on a remote NUMA node, then utilize the runtime system to conduct data caching and movement between different NUMA nodes. Based on the experiments with QR factorizations, we demonstrate that our framework is able to achieve great scalability on a 48-core AMD Opteron system (e.g., parallel efficiency drops only 3% from one core to 48 cores). We also deploy our framework to an extreme-scale shared-memory SGI machine which has 1024 CPU cores and runs a single Linux operating system image. Our framework continues to scale well, and can outperform the vendor-optimized Intel MKL library by up to 750%.",
        "date": "2014",
        "authers": [
            "Fengguang Song",
            "Jack Dongarra"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262311378_KV-Cache_A_Scalable_High-Performance_Web-Object_Cache_for_Manycore",
            "https://www.researchgate.net/publication/262274001_NUMA-aware_shared-memory_collective_communication_for_MPI",
            "https://www.researchgate.net/publication/262159992_Traffic_Management_A_Holistic_Approach_to_Memory_Placement_on_NUMA_Systems",
            "https://www.researchgate.net/publication/258521061_NUMA-aware_graph_mining_techniques_for_performance_and_energy_efficiency",
            "https://www.researchgate.net/publication/224132799_Memphis_Finding_and_fixing_NUMA-related_performance_problems_on_multi-core_platforms",
            "https://www.researchgate.net/publication/286643249_Real-world_concurrency",
            "https://www.researchgate.net/publication/268461720_Traffic_management",
            "https://www.researchgate.net/publication/265478227_LAPACK_users'_guide",
            "https://www.researchgate.net/publication/261020725_Optimizing_Google's_warehouse_scale_computers_The_NUMA_experience",
            "https://www.researchgate.net/publication/256327878_ScaLAPACK_user's_guide"
        ]
    },
    "paper161": {
        "id": "266225209",
        "title": "Large Scale Distributed Deep Networks",
        "abstract": "Recent work in unsupervised feature learning and deep learning has shown that be-ing able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network train-ing. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k cate-gories. We show that these same techniques dramatically accelerate the training of a more modestly-sized deep network for a commercial speech recognition ser-vice. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.",
        "date": "2012Advances",
        "authers": [
            "Jeffrey Dean",
            "G.s. Corrado",
            "Rajat Monga",
            "Kai Chen"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/255564380_Scalable_stacking_and_learning_for_building_deep_architectures",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770111_Improving_the_speed_of_neural_networks_on_CPUs",
            "https://www.researchgate.net/publication/303256841_Theano_a_CPU_and_GPU_math_expression_compiler",
            "https://www.researchgate.net/publication/267429210_Improving_the_speed_of_neural_networks_on_CPUs",
            "https://www.researchgate.net/publication/265748773_Learning_Multiple_Layers_of_Features_from_Tiny_Images",
            "https://www.researchgate.net/publication/265178583_Deep_Neural_Networks_for_Acoustic_Modeling_in_Speech_Recognition",
            "https://www.researchgate.net/publication/261051511_Distributed_delayed_stochastic_optimization",
            "https://www.researchgate.net/publication/236736851_Stochastic_Gradient_Learning_in_Neural_Networks",
            "https://www.researchgate.net/publication/225818196_Neural_Probabilistic_Language_Models"
        ]
    },
    "paper162": {
        "id": "319770166",
        "title": "Provable Bounds for Learning Some Deep Representations",
        "abstract": "We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an $n$ node multilayer neural net that has degree at most $n^backslashgamma$ for some $backslashgamma textless1$ and each edge has a random edge weight in $[-1,1]$. Our algorithm learns $backslash$em almost all networks in this class with polynomial running time. The sample complexity is quadratic or cubic depending upon the details of the model. The algorithm uses layerwise learning. It is based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure. The analysis of the algorithm reveals interesting structure of neural networks with random edge weights.",
        "date": "2014",
        "authers": [
            "Sanjeev Arora",
            "Aditya Bhaskara",
            "Rong Ge",
            "Tengyu Ma"
        ],
        "refrences": []
    },
    "paper163": {
        "id": "310752533",
        "title": "Visualizing and understanding convolutional networks",
        "abstract": "",
        "date": "2013",
        "authers": [
            "M.D. Zeiler",
            "R. Fergus"
        ],
        "refrences": []
    },
    "paper164": {
        "id": "286271944",
        "title": "On the importance of initialization and momentum in deep learning",
        "abstract": "Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.",
        "date": "2013",
        "authers": [
            "I. Sutskever",
            "J. Martens",
            "G. Dahl",
            "G. Hinton"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/243648538_Some_methods_of_speeding_up_the_convergence_of_iteration_methods",
            "https://www.researchgate.net/publication/215616968_Understanding_the_difficulty_of_training_deep_feedforward_neural_networks",
            "https://www.researchgate.net/publication/2749736_Stochastic_Dynamics_of_Learning_with_Momentum_in_Neural_Networks",
            "https://www.researchgate.net/publication/265002936_Lecture_Notes_in_Computer_Science"
        ]
    },
    "paper165": {
        "id": "303137904",
        "title": "Greedy layer-wise training of deep networks",
        "abstract": "",
        "date": "2007",
        "authers": [
            "Y. Bengio",
            "Pascal Lamblin",
            "Dan Popovici",
            "Hugo Larochelle"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221620465_The_Curse_of_Highly_Variable_Functions_for_Local_Kernel_Machines",
            "https://www.researchgate.net/publication/221618913_Convex_Neural_Networks",
            "https://www.researchgate.net/publication/200744506_Exponential_family_harmoniums_with_an_application_to_information_retrieval",
            "https://www.researchgate.net/publication/11294735_A_Monte_Carlo_EM_Approach_for_Partially_Observable_Diffusion_Processes_Theory_and_Applications_to_Neural_Networks",
            "https://www.researchgate.net/publication/304109482_Training_products_of_experts_by_minimizing_contrastive_divergence",
            "https://www.researchgate.net/publication/274549920_Computational_Limitations_of_Small-Depth_Circuits",
            "https://www.researchgate.net/publication/226568893_Practical_Issues_in_Temporal_Difference_Learning",
            "https://www.researchgate.net/publication/222000227_Training_MLPS_layer_by_layer_using_an_objective_function_for_internal_representations",
            "https://www.researchgate.net/publication/201841044_Scaling_learning_algorithms_towards",
            "https://www.researchgate.net/publication/15437023_The_Wake-Sleep_Algorithm_for_Unsupervised_Neural_Networks"
        ]
    },
    "paper166": {
        "id": "267225654",
        "title": "A Two-Stage Pretraining Algorithm for Deep Boltzmann Machines",
        "abstract": "A deep Boltzmann machine (DBM) is a recently introduced Markov random field model that has multiple layers of hidden units. It has been shown empirically that it is difficult to train a DBM with approximate maximum- likelihood learning using the stochastic gradient unlike its simpler special case, restricted Boltzmann machine (RBM). In this paper, we propose a novel pretraining algorithm that consists of two stages; obtaining approximate posterior distributions over hidden units from a simpler model and maximizing the variational lower-bound given the fixed hidden posterior distributions. We show empirically that the proposed method overcomes the difficulty in training DBMs from randomly initialized parameters and results in a better, or comparable, generative model when compared to the conventional pretraining algorithm.",
        "date": "2013",
        "authers": [
            "Kyunghyun Cho",
            "Tapani Raiko",
            "Alexander Ilin",
            "Juha Karhunen"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/267972168_Parallel_Tempering_for_Training_of_Restricted_Boltzmann_Machines",
            "https://www.researchgate.net/publication/261122138_Gaussian-Bernoulli_Deep_Boltzmann_Machine",
            "https://www.researchgate.net/publication/240308775_Representation_Learning_A_Review_and_New_Perspectives",
            "https://www.researchgate.net/publication/231556969_Deep_Learning_Made_Easier_by_Linear_Transformations_in",
            "https://www.researchgate.net/publication/230555076_Learning_Two-Layer_Contractive_Encodings",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/304109482_Training_products_of_experts_by_minimizing_contrastive_divergence",
            "https://www.researchgate.net/publication/289098162_A_better_way_to_pretrain_Deep_Boltzmann_Machines",
            "https://www.researchgate.net/publication/280940018_Pattern_Recognition_and_Machine_Learning",
            "https://www.researchgate.net/publication/267783299_Deep_Boltzmann_Machines_and_the_Centering_Trick"
        ]
    },
    "paper167": {
        "id": "319770367",
        "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation",
        "abstract": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the linear structure present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2x, while keeping the accuracy within 1% of the original model.",
        "date": "2014",
        "authers": [
            "Emily Denton",
            "Wojciech Zaremba",
            "Joan Bruna",
            "Yann Lecun"
        ],
        "refrences": []
    },
    "paper168": {
        "id": "289733708",
        "title": "Do deep nets really need to be deep",
        "abstract": "Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this paper we empirically demonstrate that shallow feed-forward nets can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow nets can learn these deep functions using the same number of parameters as the original deep models. On the TIMIT phoneme recognition and CIFAR-10 image recognition tasks, shallow nets can be trained that perform similarly to complex, well-engineered, deeper convolutional models.",
        "date": "2014Advances",
        "authers": [
            "L.J. Ba",
            "R. Caruana"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221653840_Model_compression",
            "https://www.researchgate.net/publication/261230561_Low-rank_matrix_factorization_for_Deep_Neural_Network_training_with_high-dimensional_output_targets",
            "https://www.researchgate.net/publication/221487297_Conversational_Speech_Transcription_Using_Context-Dependent_Deep_Neural_Networks"
        ]
    },
    "paper169": {
        "id": "273387909",
        "title": "Distilling the Knowledge in a Neural Network",
        "abstract": "A very simple way to improve the performance of almost any machine learning\nalgorithm is to train many different models on the same data and then to\naverage their predictions. Unfortunately, making predictions using a whole\nensemble of models is cumbersome and may be too computationally expensive to\nallow deployment to a large number of users, especially if the individual\nmodels are large neural nets. Caruana and his collaborators have shown that it\nis possible to compress the knowledge in an ensemble into a single model which\nis much easier to deploy and we develop this approach further using a different\ncompression technique. We achieve some surprising results on MNIST and we show\nthat we can significantly improve the acoustic model of a heavily used\ncommercial system by distilling the knowledge in an ensemble of models into a\nsingle model. We also introduce a new type of ensemble composed of one or more\nfull models and many specialist models which learn to distinguish fine-grained\nclasses that the full models confuse. Unlike a mixture of experts, these\nspecialist models can be trained rapidly and in parallel.",
        "date": "2015",
        "authers": [
            "Geoffrey Hinton",
            "Oriol Vinyals",
            "Jeff Dean"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/233806999_Adaptive_Mixture_of_Local_Expert",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/221653840_Model_compression",
            "https://www.researchgate.net/publication/354167136_Learning_small-size_DNN_with_output-distribution-based_criteria",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/298606994_Ensemble_methods_in_machine_learning",
            "https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/260637318_Deep_Neural_Networks_for_Acoustic_Modeling_in_Speech_Recognition_The_Shared_Views_of_Four_Research_Groups"
        ]
    },
    "paper170": {
        "id": "269877085",
        "title": "Compressing Deep Convolutional Networks using Vector Quantization",
        "abstract": "Deep convolutional neural networks (CNN) has become the most promising method\nfor object recognition, repeatedly demonstrating record breaking results for\nimage classification and object detection in recent years. However, a very deep\nCNN generally involves many layers with millions of parameters, making the\nstorage of the network model to be extremely large. This prohibits the usage of\ndeep CNNs on resource limited hardware, especially cell phones or other\nembedded devices. In this paper, we tackle this model storage issue by\ninvestigating information theoretical vector quantization methods for\ncompressing the parameters of CNNs. In particular, we have found in terms of\ncompressing the most storage demanding dense connected layers, vector\nquantization methods have a clear gain over existing matrix factorization\nmethods. Simply applying k-means clustering to the weights or conducting\nproduct quantization can lead to a very good balance between model size and\nrecognition accuracy. For the 1000-category classification task in the ImageNet\nchallenge, we are able to achieve 16-24 times compression of the network with\nonly 1% loss of classification accuracy using the state-of-the-art CNN.",
        "date": "2014",
        "authers": [
            "Yunchao Gong",
            "Liu Liu",
            "Ming Yang",
            "Lubomir Bourdev"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/317083797_Hamming_Embedding_and_Weak_Geometric_Consistency_for_Large_Scale_Image_Search",
            "https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding",
            "https://www.researchgate.net/publication/51873001_Approximate_Nearest_Neighbor_Search_by_Residual_Vector_Quantization",
            "https://www.researchgate.net/publication/47815472_Product_Quantization_for_Nearest_Neighbor_Search",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/319770363_Deep_Fisher_Networks_for_Large-Scale_Image_Classification",
            "https://www.researchgate.net/publication/319770276_CNN_Features_off-the-shelf_an_Astounding_Baseline_for_Recognition",
            "https://www.researchgate.net/publication/319770111_Improving_the_speed_of_neural_networks_on_CPUs",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks"
        ]
    },
    "paper171": {
        "id": "266031774",
        "title": "Reading Digits in Natural Images with Unsupervised Feature Learning",
        "abstract": "Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the prob-lem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we intro-duce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed fea-tures. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks.",
        "date": "2011",
        "authers": [
            "Yuval Netzer",
            "Tao Wang",
            "Adam Coates",
            "Alessandro Bissacco"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/242737800_The_OCRopus_open_source_OCR_system_Proceedings_Paper",
            "https://www.researchgate.net/publication/224136091_Large-scale_privacy_protection_in_Google_Street_View",
            "https://www.researchgate.net/publication/221620343_Sparse_deep_belief_net_model_for_visual_area_V2",
            "https://www.researchgate.net/publication/221619818_Unsupervised_feature_learning_for_audio_classification_using_convolutional_deep_belief_networks",
            "https://www.researchgate.net/publication/221618416_Measuring_Invariances_in_Deep_Networks",
            "https://www.researchgate.net/publication/221364080_Linear_spatial_pyramid_matching_using_sparse_coding_for_image_classification",
            "https://www.researchgate.net/publication/221253776_The_OCRopus_open_source_OCR_system",
            "https://www.researchgate.net/publication/221110077_End-to-end_scene_text_recognition",
            "https://www.researchgate.net/publication/220933133_A_Robust_System_to_Detect_and_Localize_Texts_in_Natural_Scene_Images",
            "https://www.researchgate.net/publication/220478096_Google_Street_View_Capturing_the_World_at_Street_Level"
        ]
    },
    "paper172": {
        "id": "265748773",
        "title": "Learning Multiple Layers of Features from Tiny Images",
        "abstract": "April 8, 2009Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it di cult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signi cantly",
        "date": "2012",
        "authers": [
            "Alex Krizhevsky"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/239571798_Information_processing_in_dynamical_systems_Foundations_of_harmony_theory",
            "https://www.researchgate.net/publication/304109482_Training_products_of_experts_by_minimizing_contrastive_divergence",
            "https://www.researchgate.net/publication/263499383_The_''Independent_Components''_of_Natural_Scenes_are_Edge_Filters",
            "https://www.researchgate.net/publication/221346268_Training_Restricted_Boltzmann_Machines_using_Approximations_to_the_Likelihood_Gradient",
            "https://www.researchgate.net/publication/221346193_On_the_quantitative_analysis_of_deep_belief_networks",
            "https://www.researchgate.net/publication/200044309_WordNet_A_Lexical_Database_for_English",
            "https://www.researchgate.net/publication/23253323_80_Million_Tiny_Images_A_Large_Data_Set_for_Nonparametric_Object_and_Scene_Recognition",
            "https://www.researchgate.net/publication/6912170_Reducing_the_Dimensionality_of_Data_with_Neural_Networks",
            "https://www.researchgate.net/publication/2821917_Unsupervised_Learning_of_Distributions_on_Binary_Vectors_Using_Two_Layer_Networks"
        ]
    },
    "paper173": {
        "id": "319770626",
        "title": "Multi-column Deep Neural Networks for Image Classification",
        "abstract": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traf\ufb01c signs. Our biologically plausible, wide and deep arti\ufb01cial neural network architectures can. Small (often minimal) receptive \ufb01elds of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the \ufb01rst to achieve near-human performance. On a traf\ufb01c sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classi\ufb01cation benchmarks.",
        "date": "2012",
        "authers": [
            "Dan Ciresan",
            "Ueli Meier",
            "Jurgen Schmidhuber"
        ],
        "refrences": []
    },
    "paper174": {
        "id": "291735245",
        "title": "Regularization of neural networks using dropconnect",
        "abstract": "",
        "date": "2013",
        "authers": [
            "L. Wan",
            "M. Zeiler",
            "Sixn Zhang",
            "Y.L. Cun"
        ],
        "refrences": []
    },
    "paper175": {
        "id": "286569315",
        "title": "Discriminative transfer learning with tree-based priors",
        "abstract": "High capacity classifiers, such as deep neural networks, often struggle on classes that have very few training examples. We propose a method for improving classification performance for such classes by discovering similar classes and transferring knowledge among them. Our method learns to organize the classes into a tree hierarchy. This tree structure imposes a prior over the classifier's parameters. We show that the performance of deep neural networks can be improved by applying these priors to the weights in the last layer. Our method combines the strength of discriminatively trained deep neural networks, which typically require large amounts of training data, with tree-based priors, making deep neural networks work well on infrequent classes as well. We also propose an algorithm for learning the underlying tree structure. Starting from an initial pre-specified tree, this algorithm modifies the tree to make it more pertinent to the task being solved, for example, removing semantic relationships in favour of visual ones for an image classification task. Our method achieves state-of-the-art classification results on the CIFAR-100 image data set and the MIR Flickr image-text data set.",
        "date": "2013Advances",
        "authers": [
            "N. Srivastava",
            "R. Salakhutdinov"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/45489469_Unsupervised_learning_of_visual_taxonomies",
            "https://www.researchgate.net/publication/221345667_Learning_with_Whom_to_Share_in_Multi-task_Feature_Learning",
            "https://www.researchgate.net/publication/2123184_Improving_Classification_When_a_Class_Hierarchy_is_Available_Using_a_Hierarchy-Based_Prior"
        ]
    },
    "paper176": {
        "id": "278695382",
        "title": "The Nature of Statistical Learning Theory",
        "abstract": "In this chapter we consider bounds on the rate of uniform convergence. We consider upper bounds (there exist lower bounds as well (Vapnik and Chervonenkis, 1974); however, they are not as important for controlling the learning processes as the upper bounds).",
        "date": "2000",
        "authers": [
            "Vladimir N. Vapnik"
        ],
        "refrences": []
    },
    "paper177": {
        "id": "278651717",
        "title": "The Nature of Statistical Learning Theory",
        "abstract": "In the history of research of the learning problem one can extract four periods that can be characterized by four bright events: (i) Constructing the first learning machines, (ii) constructing the fundamentals of the theory, (iii) constructing neural networks, (iv) constructing the alternatives to neural networks.",
        "date": "2000",
        "authers": [
            "Vladimir N. Vapnik"
        ],
        "refrences": []
    },
    "paper178": {
        "id": "347495711",
        "title": "Learning Generative Visual Models from Few Training Examples An Incremental Bayesian Approach Tested on 101 Object Categories",
        "abstract": "",
        "date": "2004",
        "authers": [
            "Li Fei-Fei",
            "R. Fergus",
            "P. Perona"
        ],
        "refrences": []
    },
    "paper179": {
        "id": "319770439",
        "title": "Efficient Estimation of Word Representations in Vector Space",
        "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.",
        "date": "2013",
        "authers": [
            "Tomas Mikolov",
            "G.s. Corrado",
            "Kai Chen",
            "Jeffrey Dean"
        ],
        "refrences": []
    },
    "paper180": {
        "id": "319770430",
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "abstract": "Can a large convolutional neural network trained for whole-image classification on ImageNet be coaxed into detecting objects in PASCAL? We show that the answer is yes, and that the resulting system is simple, scalable, and boosts mean average precision, relative to the venerable deformable part model, by more than 40% (achieving a final mAP of 48% on VOC 2007). Our framework combines powerful computer vision techniques for generating bottom-up region proposals with recent advances in learning high-capacity convolutional neural networks. We call the resulting system R-CNN: Regions with CNN features. The same framework is also competitive with state-of-the-art semantic segmentation methods, demonstrating its flexibility. Beyond these results, we execute a battery of experiments that provide insight into what the network learns to represent, revealing a rich hierarchy of discriminative and often semantically meaningful features.",
        "date": "2014",
        "authers": [
            "Ross Girshick",
            "Jeff Donahue",
            "Trevor Darrell",
            "Jitendra Malik"
        ],
        "refrences": []
    },
    "paper181": {
        "id": "319770370",
        "title": "Three things everyone should know to improve object retrieval",
        "abstract": "The objective of this work is object retrieval in large scale image datasets, where the object is speci\ufb01ed by an image query and retrieval should be immediate at run time in the manner of Video Google [28]. We make the following three contributions: (i) a new method to compare SIFT descriptors (RootSIFT) which yields superior performance without increasing processing or storage requirements; (ii) a novel method for query expansion where a richer model for the query is learnt discriminatively in a form suited to immediate retrieval through ef\ufb01cient use of the inverted index; (iii) an improvement of the image augmentation method proposed by Turcot and Lowe [29], where only the augmenting features which are spatially consistent with the augmented image are kept. We evaluate these three methods over a number of standard benchmark datasets (Oxford Buildings 5k and 105k, and Paris 6k) and demonstrate substantial improvements in retrieval performance whilst maintaining immediate retrieval speeds. Combining these complementary methods achieves a new state-of-the-art performance on these datasets.",
        "date": "2012",
        "authers": [
            "Relja Arandjelovic",
            "Andrew Zisserman"
        ],
        "refrences": []
    },
    "paper182": {
        "id": "319770363",
        "title": "Deep Fisher Networks for Large-Scale Image Classification",
        "abstract": "As massively parallel computations have become broadly available with modern GPUs, deep architectures trained on very large datasets have risen in popularity. Discriminatively trained convolutional neural networks, in particular, were recently shown to yield state-of-the-art performance in challenging image classification benchmarks such as ImageNet. However, elements of these architectures are similar to standard hand-crafted representations used in computer vision. In this paper, we explore the extent of this analogy, proposing a version of the stateof- the-art Fisher vector image encoding that can be stacked in multiple layers. This architecture significantly improves on standard Fisher vectors, and obtains competitive results with deep convolutional networks at a smaller computational learning cost. Our hybrid architecture allows us to assess how the performance of a conventional hand-crafted image classification pipeline changes with increased depth. We also show that convolutional networks and Fisher vector encodings are complementary in the sense that their combination further improves the accuracy.",
        "date": "2013",
        "authers": [
            "Karen Simonyan",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "refrences": []
    },
    "paper183": {
        "id": "319770264",
        "title": "Regularization of Neural Networks using DropConnect",
        "abstract": "We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.",
        "date": "2013",
        "authers": [
            "Li Wan",
            "Matthew D Zeiler",
            "Sixn Zhang",
            "Yann Lecun"
        ],
        "refrences": []
    },
    "paper184": {
        "id": "316240097",
        "title": "Distinctive Image Features from Scale-Invariant Keypoints",
        "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
        "date": "2004International",
        "authers": [
            "David G. Lowe"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/244441057_Shape_recognition_with_edge-based_features",
            "https://www.researchgate.net/publication/225207866_The_Fundamental_Matrix_Theory_Algorithms_and_Stability_Analysis",
            "https://www.researchgate.net/publication/225133940_Phase-Based_Local_Features",
            "https://www.researchgate.net/publication/224377792_A_Representation_for_Shape_Based_on_Peaks_and_Ridges_in_the_Difference_of_Low-Pass_Transform",
            "https://www.researchgate.net/publication/224072186_Vision-based_mobile_robot_localization_and_mapping_using_scale-invariant_features",
            "https://www.researchgate.net/publication/222501480_View-based_object_recognition_using_saliency_maps",
            "https://www.researchgate.net/publication/200038914_Multi-view_Matching_for_Unordered_Image_Sets_or_How_Do_I_Organize_My_Holiday_Snaps",
            "https://www.researchgate.net/publication/3854190_Reliable_feature_matching_across_widely_separated_views",
            "https://www.researchgate.net/publication/2841703_Global_Localization_using_Distinctive_Visual_Features",
            "https://www.researchgate.net/publication/2816739_Recognition_Using_Region_Correspondences"
        ]
    },
    "paper185": {
        "id": "314450504",
        "title": "Object detection using a max-margin Hough transform",
        "abstract": "",
        "date": "2009",
        "authers": [
            "S. Maji",
            "J. Malik"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/227191648_A_Trainable_System_for_Object_Detection",
            "https://www.researchgate.net/publication/224323280_Beyond_sliding_windows_Object_localization_by_efficient_subwindow_search",
            "https://www.researchgate.net/publication/220660094_Robust_Real-Time_Face_Detection",
            "https://www.researchgate.net/publication/6731822_An_experimental_study_on_pedestrian_classification_IEEE_Trans_Pattern_Anal_Mach_Intell",
            "https://www.researchgate.net/publication/2464475_Training_Support_Vector_Machines_an_Application_to_Face_Detection",
            "https://www.researchgate.net/publication/319770820_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/313562430_Learning_a_sparse_representation_for_object_detection",
            "https://www.researchgate.net/publication/312915478_From_images_to_shape_models_for_object_detection",
            "https://www.researchgate.net/publication/312538118_Support-vector_networks",
            "https://www.researchgate.net/publication/308161149_Combined_object_categorization_and_segmentation_with_an_implicit_shape_model"
        ]
    },
    "paper186": {
        "id": "301463801",
        "title": "Open-vocabulary Object Retrieval",
        "abstract": "",
        "date": "2014",
        "authers": [
            "Sergio Guadarrama",
            "Erik Rodner",
            "Ryan Farrell",
            "Ning Zhang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/312995014_A_Discriminative_Kernel-based_Model_to_Rank_Images_from_Text_Queries",
            "https://www.researchgate.net/publication/329974353_Jointly_Learning_to_Parse_and_Perceive_Connecting_Natural_Language_to_the_Physical_World",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/304417828_Multi-label_learning_with_millions_of_labels_Recommending_advertiser_bid_phrases_for_web_pages",
            "https://www.researchgate.net/publication/291286882_DeViSE_A_deep_visual-semantic_embedding_model",
            "https://www.researchgate.net/publication/279843694_Toward_a_Probabilistic_Approach_to_Acquiring_Information_from_Human_Partners_Using_Language",
            "https://www.researchgate.net/publication/270878885_Generalizing_Image_Captions_for_Image-Text_Parallel_Corpus",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/267687028_Multiple_queries_for_large_scale_specific_object_retrieval",
            "https://www.researchgate.net/publication/262410602_From_Large_Scale_Image_Categorization_to_Entry-Level_Categories"
        ]
    },
    "paper187": {
        "id": "262270555",
        "title": "Selective Search for Object Recognition",
        "abstract": "This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99 % recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software: http://disi.unitn.it/~uijlings/SelectiveSearch.html).",
        "date": "2013International",
        "authers": [
            "Jasper R. R. Uijlings",
            "K. E. A. Sande",
            "T. Gevers",
            "A.W.M. Smeulders"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/228602850_Visual_categorization_with_bags_of_keypoints",
            "https://www.researchgate.net/publication/319770820_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/319770432_Evaluating_color_descriptors_for_object_and_scene_recognition",
            "https://www.researchgate.net/publication/314450504_Object_detection_using_a_max-margin_Hough_transform",
            "https://www.researchgate.net/publication/284040965_Mean_shift_A_robust_approach_toward_feature_space_analysis",
            "https://www.researchgate.net/publication/281327886_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/246418967_Image_Parsing_Segmentation_Detection_and_Recognition",
            "https://www.researchgate.net/publication/240224936_Rapid_object_detection_using_a_boosted_cascade_of_simple_features",
            "https://www.researchgate.net/publication/232626819_Recognition_using_regions",
            "https://www.researchgate.net/publication/232617564_Object_detection_using_a_max-margin_Hough_transform"
        ]
    },
    "paper188": {
        "id": "258520603",
        "title": "Recognizing Image Style",
        "abstract": "The style of an image plays a significant role in how it is viewed, but has\nreceived little attention in computer vision research. We describe an approach\nto predicting style of images, and perform a thorough evaluation of different\nimage features for these tasks. We find that features learned in a multi-layer\nnetwork generally perform best -- even when trained with object class (not\nstyle) labels. Our large-scale learning methods results in the best published\nperformance on an existing dataset of aesthetic ratings and photographic style\nannotations. We present two novel datasets: 55K Flickr photographs annotated\nwith curated style labels as well as free-form tags, and 85K paintings\nannotated with style and genre labels. Our approach shows excellent\nclassification performance on both datasets. We use the learned classifiers to\nextend traditional tag-based image search to consider stylistic constraints,\nand demonstrate cross-dataset understanding of style.",
        "date": "2013",
        "authers": [
            "Sergey Karayev",
            "Aaron Hertzmann",
            "Holger Winnemoeller",
            "Aseem Agarwala"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/302747723_Studying_aesthetics_in_photographic_images_using_a_computational_approach",
            "https://www.researchgate.net/publication/319770372_Object_Bank_A_High-Level_Image_Representation_for_Scene_Classification_Semantic_Feature_Sparsification",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/269128228_Learning_beautiful_attributes",
            "https://www.researchgate.net/publication/262390837_Dating_Historical_Color_Images",
            "https://www.researchgate.net/publication/262314937_Large-scale_visual_sentiment_ontology_and_detectors_using_adjective_noun_pairs",
            "https://www.researchgate.net/publication/262286466_The_Interestingness_of_Images",
            "https://www.researchgate.net/publication/261336804_AVA_A_large-scale_database_for_aesthetic_visual_analysis",
            "https://www.researchgate.net/publication/261168672_Meta-class_features_for_large-scale_object_categorization_on_a_budget",
            "https://www.researchgate.net/publication/257409887_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition"
        ]
    },
    "paper189": {
        "id": "319770411",
        "title": "Torch7 A Matlab-like Environment for Machine Learning",
        "abstract": "Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be in- terfaced to third-party software thanks to Lua's light interface.",
        "date": "2011",
        "authers": [
            "Ronan Collobert",
            "Koray Kavukcuoglu",
            "Clement Farabet"
        ],
        "refrences": []
    },
    "paper190": {
        "id": "272149731",
        "title": "Pylearn2 a machine learning research library",
        "abstract": "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
        "date": "2013",
        "authers": [
            "IJ Goodfellow",
            "D Warde-Farley"
        ],
        "refrences": []
    },
    "paper191": {
        "id": "264890087",
        "title": "Torch7 A Matlab-like Environment for Machine Learning",
        "abstract": "Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be in-terfaced to third-party software thanks to Lua's light interface.",
        "date": "2011",
        "authers": [
            "Ronan Collobert",
            "Koray Kavukcuoglu",
            "Clement Farabet"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/216792890_SN_A_Simulator_for_Connectionist_Models",
            "https://www.researchgate.net/publication/216792770_Lush_Reference_Manual"
        ]
    },
    "paper192": {
        "id": "258839715",
        "title": "PANDA Pose Aligned Networks for Deep Attribute Modeling",
        "abstract": "We propose a method for inferring human attributes (such as gender, hair\nstyle, clothes style, expression, action) from images of people under large\nvariation of viewpoint, pose, appearance, articulation and occlusion.\nConvolutional Neural Nets (CNN) have been shown to perform very well on large\nscale object recognition problems. In the context of attribute classification,\nhowever, the signal is often subtle and it may cover only a small part of the\nimage, while the image is dominated by the effects of pose and viewpoint.\nDiscounting for pose variation would require training on very large labeled\ndatasets which are not presently available. Part-based models, such as poselets\nand DPM have been shown to perform well for this problem but they are limited\nby flat low-level features. We propose a new method which combines part-based\nmodels and deep learning by training pose-normalized CNNs. We show substantial\nimprovement vs. state-of-the-art methods on challenging attribute\nclassification tasks in unconstrained settings. Experiments confirm that our\nmethod outperforms both the best part-based methods on this problem and\nconventional CNNs trained on the full bounding box of the person.",
        "date": "2013",
        "authers": [
            "Ning Zhang",
            "Manohar Paluri",
            "Marc'Aurelio Ranzato",
            "Trevor Darrell"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/261121695_Discovering_localized_attributes_for_fine-grained_recognition",
            "https://www.researchgate.net/publication/257052073_Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction",
            "https://www.researchgate.net/publication/238592859_Pose_Pooling_Kernels_for_Sub-category_Recognition",
            "https://www.researchgate.net/publication/227943302_Learning_To_Detect_Unseen_Object_Classes_by_Between-Class_Attribute_Transfer",
            "https://www.researchgate.net/publication/224716259_Unsupervised_Learning_of_Invariant_Feature_Hierarchies_with_Applications_to_Object_Recognition",
            "https://www.researchgate.net/publication/224135964_Attribute_and_Simile_Classifiers_for_Face_Verification",
            "https://www.researchgate.net/publication/221111309_Birdlets_Subordinate_categorization_using_volumetric_primitives_and_pose-normalized_appearance",
            "https://www.researchgate.net/publication/221111179_Relative_attributes",
            "https://www.researchgate.net/publication/51968606_Building_high-level_features_using_large_scale_unsupervised_learning",
            "https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition"
        ]
    },
    "paper193": {
        "id": "259400019",
        "title": "On the number of response regions of deep feed forward networks with piece-wise linear activations",
        "abstract": "This paper explores the complexity of deep feedforward networks with linear\npre-synaptic couplings and rectified linear activations. This is a\ncontribution to the growing body of work contrasting the representational power\nof deep and shallow network architectures. In particular, we offer a framework\nfor comparing deep and shallow models that belong to the family of piecewise\nlinear functions based on computational geometry. We look at a deep rectifier\nmulti-layer perceptron (MLP) with linear outputs units and compare it with a\nsingle layer version of the model. In the asymptotic regime, when the number\nof inputs stays constant, if the shallow model has $kn$ hidden units and $n_0$\ninputs, then the number of linear regions is $O(k^{n_0}n^{n_0})$. For a $k$\nlayer model with $n$ hidden units on each layer it is $\\Omega(\\left\\lfloor {n}/\n{n_0}\\right\\rfloor^{k-1}n^{n_0})$. The number\n$\\left\\lfloor{n}/{n_0}\\right\\rfloor^{k-1}$ grows faster than $k^{n_0}$ when $n$\ntends to infinity or when $k$ tends to infinity and $n \\geq 2n_0$.\nAdditionally, even when $k$ is small, if we restrict $n$ to be $2n_0$, we can\nshow that a deep model has considerably more linear regions that a shallow one.\nWe consider this as a first step towards understanding the complexity of these\nmodels and specifically towards providing suitable mathematical tools for\nfuture analysis.",
        "date": "2013",
        "authers": [
            "Razvan Pascanu",
            "Guido Montufar",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/263091596_Expressive_Power_and_Approximation_Errors_of_Restricted_Boltzmann_Machines",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/225098395_When_Does_a_Mixture_of_Products_Contain_a_Product_of_Mixtures",
            "https://www.researchgate.net/publication/319770386_Sum-Product_Networks_A_New_Deep_Architecture",
            "https://www.researchgate.net/publication/316519032_An_introduction_to_hyperplane_arrangements",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/267064227_Facing_up_to_Arrangements_Face-Count_Formulas_for_Partitions_of_Space_by_Hyperplanes",
            "https://www.researchgate.net/publication/265178583_Deep_Neural_Networks_for_Acoustic_Modeling_in_Speech_Recognition",
            "https://www.researchgate.net/publication/258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/221664789_Sum-Product_Networks_A_New_Deep_Architecture"
        ]
    },
    "paper194": {
        "id": "258816388",
        "title": "Revisiting Natural Gradient for Deep Networks",
        "abstract": "The aim of this paper is three-fold. First we show that Hessian-Free\n(Martens, 2010) and Krylov Subspace Descent (Vinyals and Povey, 2012)\ncan be described as implementations of natural gradient descent due to\ntheir use of the extended Gauss-Newton approximation of the Hessian.\nSecondly we re-derive natural gradient from basic principles,\ncontrasting the difference between two versions of the algorithm found\nin the neural network literature, as well as highlighting a few\ndifferences between natural gradient and typical second order methods.\nLastly we show empirically that natural gradient can be robust to\noverfitting and particularly it can be robust to the order in which the\ntraining data is presented to the model.",
        "date": "2013",
        "authers": [
            "Razvan Pascanu",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266463521_Improved_Preconditioner_for_Hessian_Free_Optimization",
            "https://www.researchgate.net/publication/235557274_Natural_Evolution_Strategies_Converge_on_Sphere_Functions",
            "https://www.researchgate.net/publication/234131091_Metric-Free_Natural_Gradient_for_Joint-Training_of_Boltzmann_Machines",
            "https://www.researchgate.net/publication/233753224_Theano_new_features_and_speed_improvements",
            "https://www.researchgate.net/publication/222348233_Natural_Actor-Critic",
            "https://www.researchgate.net/publication/285906939_Numerical_optimization",
            "https://www.researchgate.net/publication/235409844_Differential-Geometrical_Methods_in_Statistics",
            "https://www.researchgate.net/publication/234131187_Training_Neural_Networks_with_Stochastic_Hessian-Free_Optimization",
            "https://www.researchgate.net/publication/224926910_The_Natural_Gradient_by_Analogy_to_Signal_Whitening_and_Recipes_andTricks_for_its_Use",
            "https://www.researchgate.net/publication/224513847_Pattern_Recognition_and_Machine_Learning_Information_Science_and_Statistics"
        ]
    },
    "paper195": {
        "id": "316519032",
        "title": "An introduction to hyperplane arrangements",
        "abstract": "",
        "date": "2007",
        "authers": [
            "Richard Stanley"
        ],
        "refrences": []
    },
    "paper196": {
        "id": "284500238",
        "title": "Approximation by superposition of sigmoidale function",
        "abstract": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.",
        "date": "1989Mathematics",
        "authers": [
            "George Cybenko"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266002435_Some_remarks_on_ridge_functions",
            "https://www.researchgate.net/publication/226439292_Approximation_by_superpositions_of_a_sigmoidal_function_Math_Cont_Sig_Syst_MCSS_2303-314"
        ]
    },
    "paper197": {
        "id": "267064227",
        "title": "Facing up to Arrangements Face-Count Formulas for Partitions of Space by Hyperplanes",
        "abstract": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Dept. of Mathematics, 1974. Includes bibliographical references (leaves 135-139). Vita.",
        "date": "1975Memoirs",
        "authers": [
            "T. Zaslavsky"
        ],
        "refrences": []
    },
    "paper198": {
        "id": "265178583",
        "title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition",
        "abstract": "Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks with many hidden layers, that are trained using new methods have been shown to outperform Gaussian mixture models on a variety of speech recognition benchmarks, sometimes by a large margin. This paper provides an overview of this progress and represents the shared views of four research groups who have had recent successes in using deep neural networks for acoustic modeling in speech recognition.",
        "date": "2012",
        "authers": [
            "Geoffrey Hinton",
            "li Deng",
            "Dong Yu",
            "George Dahl"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/261119155_Applying_Convolutional_Neural_Networks_concepts_to_hybrid_NN-HMM_model_for_speech_recognition",
            "https://www.researchgate.net/publication/261090788_Understanding_how_Deep_Belief_Networks_perform_acoustic_modeling",
            "https://www.researchgate.net/publication/260693356_Sparse_Multilayer_Perceptron_for_Phoneme_Recognition",
            "https://www.researchgate.net/publication/239765773_Feature_engineering_in_Context-Dependent_Deep_Neural_Networks_for_conversational_speech_transcription",
            "https://www.researchgate.net/publication/228446017_Making_Deep_Belief_Networks_Effective_for_Large_Vocabulary_Continuous_Speech_Recognition",
            "https://www.researchgate.net/publication/224737607_Maximum_mutual_information_estimation_of_hidden_Markov_parameters_for_speech_recognition",
            "https://www.researchgate.net/publication/224327435_Learning_in_Sequential_Pattern_Recognition",
            "https://www.researchgate.net/publication/224216007_Acoustic_Modeling_Using_Deep_Belief_Networks",
            "https://www.researchgate.net/publication/221620570_Phone_Recognition_with_the_Mean-Covariance_Restricted_Boltzmann_Machine",
            "https://www.researchgate.net/publication/221619818_Unsupervised_feature_learning_for_audio_classification_using_convolutional_deep_belief_networks"
        ]
    },
    "paper199": {
        "id": "257672343",
        "title": "Object Recognition by Sequential Figure-Ground Ranking",
        "abstract": "We present an approach to visual object-class segmentation and recognition based on a pipeline that combines multiple figure-ground hypotheses with large object spatial support, generated by bottom-up computational processes that do not exploit knowledge of specific categories, and sequential categorization based on continuous estimates of the spatial overlap between the image segment hypotheses and each putative class. We differ from existing approaches not only in our seemingly unreasonable assumption that good object-level segments can be obtained in a feed-forward fashion, but also in formulating recognition as a regression problem. Instead of focusing on a one-vs.-all winning margin that may not preserve the ordering of segment qualities inside the non-maximum (non-winning) set, our learning method produces a globally consistent ranking with close ties to segment quality, hence to the extent entire object or part hypotheses are likely to spatially overlap the ground truth. We demonstrate results beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape as well as PASCAL VOC 2009 and 2010.",
        "date": "2012International",
        "authers": [
            "J. Carreira",
            "Fuxin Li",
            "Cristian Sminchisescu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770432_Evaluating_color_descriptors_for_object_and_scene_recognition",
            "https://www.researchgate.net/publication/319770425_Efficient_Match_Kernels_between_Sets_of_Features_for_Visual_Recognition",
            "https://www.researchgate.net/publication/319770260_Beyond_sliding_windows_Object_localization_by_efficient_subwindow_search",
            "https://www.researchgate.net/publication/319770213_Representing_shape_with_a_spatial_pyramid_kernel",
            "https://www.researchgate.net/publication/316240097_Distinctive_Image_Features_from_Scale-Invariant_Keypoints",
            "https://www.researchgate.net/publication/314405838_From_contours_to_regions_An_empirical_evaluation",
            "https://www.researchgate.net/publication/313530549_Learning_subcategory_relevances_for_category_recognition",
            "https://www.researchgate.net/publication/309532479_Random_features_for_large_scale_kernel_machines",
            "https://www.researchgate.net/publication/285058550_Exploratory_Data_Analysis",
            "https://www.researchgate.net/publication/279178907_Does_Image_Segmentation_Improve_Object_Categorization"
        ]
    },
    "paper200": {
        "id": "240308781",
        "title": "Learning Hierarchical Features for Scene Labeling",
        "abstract": "Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a $(320\\times 240)$ image labeling in less than a second, including feature extraction.",
        "date": "2013IEEE",
        "authers": [
            "Clement Farabet",
            "Camille Couprie",
            "Laurent Najman",
            "Yann Lecun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/241191907_A_committee_of_neural_networks_for_traffic_sign_classification",
            "https://www.researchgate.net/publication/230690782_Learning_Object-Class_Segmentation_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/225496431_TextonBoost_Joint_Appearance_Shape_and_Context_Modeling_for_Multi-class_Object_Recognition_and_Segmentation",
            "https://www.researchgate.net/publication/224716259_Unsupervised_Learning_of_Invariant_Feature_Hierarchies_with_Applications_to_Object_Recognition",
            "https://www.researchgate.net/publication/305083260_Learning_convolutional_feature_hierarchies_for_visual_recognition",
            "https://www.researchgate.net/publication/266439873_A_Pylon_Model_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/252482398_Interactive_Graph_Cuts_for_Optimal_Boundary_Region_Segmentation_of_Objects_in_N-D_Images",
            "https://www.researchgate.net/publication/243773059_Efficient_Approximate_Energy_Minimization_via_Graph_Cuts",
            "https://www.researchgate.net/publication/239344658_A_Simple_Algorith_for_Finding_Maximal_Network_Flows_and_an_Application_to_the_Hitchcock_Problem",
            "https://www.researchgate.net/publication/232649995_Nonparametric_scene_parsing_Label_transfer_via_dense_scene_alignment"
        ]
    },
    "paper201": {
        "id": "235360690",
        "title": "Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks",
        "abstract": "Deep Neural Networks now excel at image classification, detection and\nsegmentation. When used to scan images by means of a sliding window, however,\ntheir high computational complexity can bring even the most powerful hardware\nto its knees. We show how dynamic programming can speedup the process by orders\nof magnitude, even when max-pooling layers are present.",
        "date": "2013",
        "authers": [
            "Alessandro Giusti",
            "Dan C. Cire\u015fan",
            "Jonathan Masci",
            "Luca Maria Gambardella"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/224260296_The_German_Traffic_Sign_Recognition_Benchmark_A_multi-class_classification_competition",
            "https://www.researchgate.net/publication/224203140_Chinese_Handwriting_Recognition_Contest_2010",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/267709055_Deep_Neural_Networks_Segment_Neuronal_Membranes_in_Electron_Microscopy_Images",
            "https://www.researchgate.net/publication/265748773_Learning_Multiple_Layers_of_Features_from_Tiny_Images",
            "https://www.researchgate.net/publication/243659305_NIST_Special_Database_19_Handprinted_Forms_and_Characters_Database",
            "https://www.researchgate.net/publication/221663833_Multi-column_Deep_Neural_Networks_for_Image_Classification"
        ]
    },
    "paper202": {
        "id": "228102719",
        "title": "Improving neural networks by preventing co-adaptation of feature detectors",
        "abstract": "When a large feedforward neural network is trained on a small training set,\nit typically performs poorly on held-out test data. This \"overfitting\" is\ngreatly reduced by randomly omitting half of the feature detectors on each\ntraining case. This prevents complex co-adaptations in which a feature detector\nis only helpful in the context of several other specific feature detectors.\nInstead, each neuron learns to detect a feature that is generally helpful for\nproducing the correct answer given the combinatorially large variety of\ninternal contexts in which it must operate. Random \"dropout\" gives big\nimprovements on many benchmark tasks and sets new records for speech and object\nrecognition.",
        "date": "2012",
        "authers": [
            "Geoffrey E. Hinton",
            "Nitish Srivastava",
            "Alex Krizhevsky",
            "Ilya Sutskever"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/266248467_BAYESIAN_LEARNING_FOR_NEURAL_NETWORKS_Bayesian_Learning_for_Neural_Networks",
            "https://www.researchgate.net/publication/265350973_Application_of_Pretrained_Deep_Neural_Networks_to_Large_Vocabulary_Conversational_Speech_Recognition",
            "https://www.researchgate.net/publication/233822447_Learning_Internal_Representation_by_Back-Propagation_Errors",
            "https://www.researchgate.net/publication/226270700_Bagging_Predictors",
            "https://www.researchgate.net/publication/11207765_ARTICLE_Training_Products_of_Experts_by_Minimizing_Contrastive_Divergence"
        ]
    },
    "paper203": {
        "id": "262323276",
        "title": "Prime Object Proposals with Randomized Prim's Algorithm",
        "abstract": "Generic object detection is the challenging task of proposing windows that localize all the objects in an image, regardless of their classes. Such detectors have recently been shown to benefit many applications such as speeding-up class-specific object detection, weakly supervised learning of object detectors and object discovery. In this paper, we introduce a novel and very efficient method for generic object detection based on a randomized version of Prim's algorithm. Using the connectivity graph of an image's super pixels, with weights modelling the probability that neighbouring super pixels belong to the same object, the algorithm generates random partial spanning trees with large expected sum of edge weights. Object localizations are proposed as bounding-boxes of those partial trees. Our method has several benefits compared to the state-of-the-art. Thanks to the efficiency of Prim's algorithm, it samples proposals very quickly: 1000 proposals are obtained in about 0.7s. With proposals bound to super pixel boundaries yet diversified by randomization, it yields very high detection rates and windows that tightly fit objects. In extensive experiments on the challenging PASCAL VOC 2007 and 2012 and SUN2012 benchmark datasets, we show that our method improves over state-of-the-art competitors for a wide range of evaluation scenarios.",
        "date": "2013",
        "authers": [
            "Santiago Manen",
            "Matthieu Guillaumin",
            "Luc Van Gool"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/262203992_On_Recognizing_Actions_in_Still_Images_via_Multiple_Features",
            "https://www.researchgate.net/publication/221366761_The_2005_PASCAL_visual_object_classes_challenge",
            "https://www.researchgate.net/publication/221305138_Localizing_Objects_While_Learning_Their_Appearance",
            "https://www.researchgate.net/publication/221110937_Segmentation_as_selective_search_for_object_recognition",
            "https://www.researchgate.net/publication/221110458_Fusing_generic_objectness_and_visual_saliency_for_salient_object_detection",
            "https://www.researchgate.net/publication/221110086_Salient_object_detection_by_composition",
            "https://www.researchgate.net/publication/220320833_Efficient_Collapsed_Gibbs_Sampling_for_Latent_Dirichlet_Allocation",
            "https://www.researchgate.net/publication/51855547_CPMC_Automatic_Object_Segmentation_Using_Constrained_Parametric_Min-Cuts",
            "https://www.researchgate.net/publication/51539284_Weakly_Supervised_Learning_of_Interactions_between_Humans_and_Objects",
            "https://www.researchgate.net/publication/50999764_Hough_Forests_for_Object_Detection_Tracking_and_Action_Recognition"
        ]
    },
    "paper204": {
        "id": "233815499",
        "title": "Pedestrian Detection with Unsupervised Multi-Stage Feature Learning",
        "abstract": "Pedestrian detection is a problem of considerable practical interest. Adding\nto the list of successful applications of deep learning methods to vision, we\nreport state-of-the-art and competitive results on all major pedestrian\ndatasets with a convolutional network model. The model uses a few new twists,\nsuch as multi-stage features, connections that skip layers to integrate global\nshape information with local distinctive motif information, and an unsupervised\nmethod based on convolutional sparse coding to pre-train the filters at each\nstage.",
        "date": "2012Proceedings",
        "authers": [
            "Pierre Sermanet",
            "Koray Kavukcuoglu",
            "Soumith Chintala",
            "Yann Lecun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/261306330_Pedestrian_detection_at_100_frames_per_second",
            "https://www.researchgate.net/publication/246596930_K-SVD_and_its_non-negative_variant_for_dictionary_design",
            "https://www.researchgate.net/publication/243116386_Coordinate_Descent_Optimization_for_l_1_Minimization_with_Application_to_Compressed_Sensing_a_Greedy_Algorithm",
            "https://www.researchgate.net/publication/224579211_Learning_invariant_features_through_topographic_filter_maps",
            "https://www.researchgate.net/publication/224260345_Traffic_sign_recognition_with_multi-scale_Convolutional_Networks",
            "https://www.researchgate.net/publication/224164350_New_Features_and_Insights_for_Pedestrian_Detection",
            "https://www.researchgate.net/publication/221620168_Efficient_sparse_coding_algorithms",
            "https://www.researchgate.net/publication/221618859_Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition",
            "https://www.researchgate.net/publication/221363014_Discriminative_learned_dictionaries_for_local_image_analysis"
        ]
    },
    "paper205": {
        "id": "266463521",
        "title": "Improved Preconditioner for Hessian Free Optimization",
        "abstract": "We investigate the use of Hessian Free optimization for learning deep au-toencoders. One of the critical components in that algorithm is the choice of the preconditioner. We argue in this paper that the Jacobi precondi-tioner leads to faster optimization and we show how it can be accurately and efficiently estimated using a randomized algorithm.",
        "date": "",
        "authers": [
            "Olivier Chapelle",
            "Dumitru Erhan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/220320676_Stacked_Denoising_Autoencoders_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion",
            "https://www.researchgate.net/publication/215616968_Understanding_the_difficulty_of_training_deep_feedforward_neural_networks",
            "https://www.researchgate.net/publication/200744514_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/11294744_Fast_Curvature_Matrix-Vector_Products_for_Second-Order_Gradient_Descent",
            "https://www.researchgate.net/publication/303256841_Theano_a_CPU_and_GPU_math_expression_compiler",
            "https://www.researchgate.net/publication/222516810_A_survey_of_truncated-Newton_methods",
            "https://www.researchgate.net/publication/221345102_Deep_learning_via_Hessian-free_optimization",
            "https://www.researchgate.net/publication/221344937_On_Optimization_Methods_for_Deep_Learning",
            "https://www.researchgate.net/publication/6912170_Reducing_the_Dimensionality_of_Data_with_Neural_Networks"
        ]
    },
    "paper206": {
        "id": "234131129",
        "title": "Big Neural Networks Waste Capacity",
        "abstract": "This article exposes the failure of some big neural networks to leverage\nadded capacity to reduce underfitting. Past research suggest diminishing\nreturns when increasing the size of neural networks. Our experiments on\nImageNet LSVRC-2010 show that this may be due to the fact there are highly\ndiminishing returns for capacity in terms of training error, leading to\nunderfitting. This suggests that the optimization method - first order gradient\ndescent - fails at this regime. Directly attacking this problem, either through\nthe optimization method or the choices of parametrization, may allow to improve\nthe generalization error on large datasets, for which a large capacity is\nrequired.",
        "date": "2013",
        "authers": [
            "Yann N. Dauphin",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/239765773_Feature_engineering_in_Context-Dependent_Deep_Neural_Networks_for_conversational_speech_transcription",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/221345198_Unsupervised_Models_of_Images_by_Spike-and-Slab_RBMs",
            "https://www.researchgate.net/publication/319770395_An_Analysis_of_Single-Layer_Networks_in_Unsupervised_Feature_Learning",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/221619092_Topmoumoute_Online_Natural_Gradient_Algorithm",
            "https://www.researchgate.net/publication/221487297_Conversational_Speech_Transcription_Using_Context-Dependent_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/221480736_Empirical_Evaluation_and_Combination_of_Advanced_Language_Modeling_Techniques",
            "https://www.researchgate.net/publication/221345102_Deep_learning_via_Hessian-free_optimization"
        ]
    },
    "paper207": {
        "id": "233730646",
        "title": "On the difficulty of training Recurrent Neural Networks",
        "abstract": "There are two widely known issues with properly training Recurrent Neural\nNetworks, the vanishing and the exploding gradient problems detailed in Bengio\net al. (1994). In this paper we attempt to improve the understanding of the\nunderlying issues by exploring these problems from an analytical, a geometric\nand a dynamical systems perspective. Our analysis is used to justify a simple\nyet effective solution. We propose a gradient norm clipping strategy to deal\nwith exploding gradients and a soft constraint for the vanishing gradients\nproblem. We validate empirically our hypothesis and proposed solutions in the\nexperimental section.",
        "date": "2012",
        "authers": [
            "Razvan Pascanu",
            "Tomas Mikolov",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266485700_SUBWORD_LANGUAGE_MODELING_WITH_NEURAL_NETWORKS",
            "https://www.researchgate.net/publication/233836017_Advances_in_Optimizing_Recurrent_Networks",
            "https://www.researchgate.net/publication/233753224_Theano_new_features_and_speed_improvements",
            "https://www.researchgate.net/publication/228095594_Modeling_Temporal_Dependencies_in_High-Dimensional_SequencesApplication_to_Polyphonic_Music_Generation_and_Transcription",
            "https://www.researchgate.net/publication/224663746_Problem_of_learning_long-term_dependencies_in_recurrent_networks",
            "https://www.researchgate.net/publication/223074905_Generalization_of_Backpropagation_with_Application_to_a_Recurrent_Gas_Market_Model",
            "https://www.researchgate.net/publication/266458936_Statistical_Language_Models_Based_on_Neural_Networks",
            "https://www.researchgate.net/publication/243773399_Nonlinear_Dynamics_and_Chaos_With_Applications_to_Physics",
            "https://www.researchgate.net/publication/229091480_Learning_Representations_by_Back_Propagating_Errors",
            "https://www.researchgate.net/publication/222526235_Jaeger_H_Reservoir_computing_approaches_to_recurrent_neural_network_training_Computer_Science_Review_3_127-149"
        ]
    },
    "paper208": {
        "id": "270878508",
        "title": "Parsing with Compositional Vector Grammars",
        "abstract": "Natural language parsing has typically been done with small sets of discrete categories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases or splitting categories only partly address the problem at the cost of huge feature spaces and sparseness. Instead, we introduce a Compositional Vector Grammar (CVG), which combines PCFGs with a syntactically untied recursive neural network that learns syntactico-semantic, compositional vector representations. The CVG improves the PCFG of the Stanford Parser by 3.8% to obtain an F1 score of 90.4%. It is fast to train and implemented approximately as an efficient reranker it is about 20% faster than the current Stanford factored parser. The CVG learns a soft notion of head words and improves performance on the types of ambiguities that require semantic information such as PP attachments.",
        "date": "2013",
        "authers": [
            "Richard Socher",
            "John Bauer",
            "Christopher D. Manning",
            "Ng Andrew Y."
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220875081_Probabilistic_CFG_with_Latent_Annotations",
            "https://www.researchgate.net/publication/28763418_Towards_Incremental_Parsing_of_Natural_Language_Using_Recursive_Neural_Networks",
            "https://www.researchgate.net/publication/222681214_Wide_coverage_natural_language_processing_using_kernel_methods_and_neural_networks_for_structured_data"
        ]
    },
    "paper209": {
        "id": "231556969",
        "title": "Deep Learning Made Easier by Linear Transformations in",
        "abstract": "We transform the outputs of each hidden neuron in a multi-layer perceptron network to be zero mean and zero slope, and use separate shortcut connections to model the linear dependencies instead. This transformation aims at separating the problems of learning the linear and nonlinear parts of the whole input-output mapping, which has many benefits. We study the theoretical properties of the transformation by noting that they make the Fisher information matrix closer to a diagonal matrix, and thus standard gradient closer to the natural gradient. We experimentally confirm the usefulness of the transformations by noting that they make basic stochastic gradient learning competitive with state-of-the-art learning algorithms in speed, and that they seem also to help find solutions that generalize better. The experiments include both classification of handwritten digits with a 3-layer network and learning a low-dimensional representation for images by using a 6-layer auto-encoder network. The transformations were beneficial in all cases, with and without regularization. 1",
        "date": "2012",
        "authers": [
            "Tapani Raiko",
            "Harri Valpola",
            "Yann Lecun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221346269_Extracting_and_composing_robust_features_with_denoising_autoencoders",
            "https://www.researchgate.net/publication/215616968_Understanding_the_difficulty_of_training_deep_feedforward_neural_networks",
            "https://www.researchgate.net/publication/51888056_Adding_noise_to_the_input_of_a_model_trained_with_a_regularizedobjective",
            "https://www.researchgate.net/publication/319770436_Efficient_backprop",
            "https://www.researchgate.net/publication/306221946_Centering_neural_network_gradient_factors",
            "https://www.researchgate.net/publication/304533936_A_simple_weight_decay_can_improve_generalization",
            "https://www.researchgate.net/publication/289786324_Centering_Neural_Network_Gradient_Factors",
            "https://www.researchgate.net/publication/265748773_Learning_Multiple_Layers_of_Features_from_Tiny_Images",
            "https://www.researchgate.net/publication/221619092_Topmoumoute_Online_Natural_Gradient_Algorithm",
            "https://www.researchgate.net/publication/221345102_Deep_learning_via_Hessian-free_optimization"
        ]
    },
    "paper210": {
        "id": "215616968",
        "title": "Understanding the difficulty of training deep feedforward neural networks",
        "abstract": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.",
        "date": "2010Journal",
        "authers": [
            "Xavier Glorot",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/239033363_Accelerated_learning_in_layered_neural_networks",
            "https://www.researchgate.net/publication/221346269_Extracting_and_composing_robust_features_with_denoising_autoencoders",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/245993331_Efficient_Learning_of_Sparse_Overcomplete_Representations_with_an_Energy-Based_Model",
            "https://www.researchgate.net/publication/235130690_Learning_in_Modular_Systems",
            "https://www.researchgate.net/publication/229091480_Learning_Representations_by_Back_Propagating_Errors",
            "https://www.researchgate.net/publication/224309464_Unsupervised_Learning_of_Probabilistic_Grammar-Markov_Models_for_Object_Categories",
            "https://www.researchgate.net/publication/221618232_A_Scalable_Hierarchical_Distributed_Language_Model",
            "https://www.researchgate.net/publication/221346162_Lecture_Notes_in_Computer_Science"
        ]
    },
    "paper211": {
        "id": "289786324",
        "title": "Centering Neural Network Gradient Factors",
        "abstract": "It has long been known that neural networks can learn faster when their input and hidden unit activities are centered about zero; recently we have extended this approach to also encompass the centering of error signals [15]. Here we generalize this notion to all factors involved in the network's gradient, leading us to propose centering the slope of hidden unit activation functions as well. Slope centering removes the linear component of backpropagated error; this improves credit assignment in networks with shortcut connections. Benchmark results show that this can speed up learning significantly without adversely affecting the trained network's generalization ability.",
        "date": "1998Lecture",
        "authers": [
            "Nicol N. Schraudolph"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/237127809_Accelerated_backpropagation_learning_Two_optimization_methods",
            "https://www.researchgate.net/publication/221112207_Exploiting_Context_When_Learning_to_Classify",
            "https://www.researchgate.net/publication/216792866_Eigenvalues_of_covariance_matrices_Application_to_neural-network_learning",
            "https://www.researchgate.net/publication/34749594_Dynamic_error_propagation_networks",
            "https://www.researchgate.net/publication/22228479_Strong_Covariance_with_Nonlinearly_Interacting_Neurons",
            "https://www.researchgate.net/publication/2690080_Unsupervised_Discrimination_of_Clustered_Data_via_Optimization_of_Binary_Information_Gain",
            "https://www.researchgate.net/publication/2498372_First-_and_Second-Order_Methods_for_Learning_Between_Steepest_Descent_and_Newton's_Method",
            "https://www.researchgate.net/publication/324110517_Theory_for_the_development_of_neuron_selectivity_orientation_specificity_and_binocular_interaction_in_visual_cortex",
            "https://www.researchgate.net/publication/282260583_Theory_for_the_Development_of_Neuron_Selectivity_Orientation_Specificity_and_Binocular_Interaction_in_Visual_Cortex",
            "https://www.researchgate.net/publication/271236629_Neurocomputing_Foundations_of_Research"
        ]
    },
    "paper212": {
        "id": "235222671",
        "title": "Science and Spectacle the Work of Jodrell Bank in Post-War British Culture",
        "abstract": "",
        "date": "1999",
        "authers": [
            "Jon Agar"
        ],
        "refrences": []
    },
    "paper213": {
        "id": "225495886",
        "title": "Efficient BackProp",
        "abstract": "The convergence of back-propagation learning is analyzed so as to explain common phenomenon observedb y practitioners. Many\nundesirable behaviors of backprop can be avoided with tricks that are rarely exposedin serious technical publications. This\npaper gives some of those tricks, ando.ers explanations of why they work. Many authors have suggested that second-order optimization\nmethods are advantageous for neural net training. It is shown that most \u201cclassical\u201d second-order methods are impractical for\nlarge neural networks. A few methods are proposed that do not have these limitations.",
        "date": "1998",
        "authers": [
            "Yann Lecun",
            "Leon Bottou",
            "Genevieve B. Orr",
            "Klaus-Robert M\u00fcller"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/222482794_Moller_MF_A_Scaled_Conjugate_Gradient_Algorithm_For_Fast_Supervised_Learning_Neural_Networks_6_525-533",
            "https://www.researchgate.net/publication/221618539_Optimal_Brain_Damage",
            "https://www.researchgate.net/publication/220499843_Neural_Networks_and_the_BiasVariance_Dilemma",
            "https://www.researchgate.net/publication/216792889_Improving_the_Convergence_of_Back-Propagation_Learning_with_Second-Order_Methods",
            "https://www.researchgate.net/publication/216792843_Automatic_Learning_Rate_Maximization_by_On-Line_Estimation_of_the_Hessian's_Eigenvectors",
            "https://www.researchgate.net/publication/15149034_Supervised_learning_on_large_redundant_training_sets",
            "https://www.researchgate.net/publication/13383386_Learning_processes_in_neural_networks",
            "https://www.researchgate.net/publication/13230969_Exact_Solution_for_On-Line_Learning_in_Multilayer_Neural_Networks",
            "https://www.researchgate.net/publication/3175480_Phoneme_recognition_using_time-delay_neural_networks",
            "https://www.researchgate.net/publication/2822332_Fast_Exact_Multiplication_by_the_Hessian"
        ]
    },
    "paper214": {
        "id": "221619092",
        "title": "Topmoumoute Online Natural Gradient Algorithm",
        "abstract": "Guided by the goal of obtaining an optimization algorithm that is both fast and yielding good generalization, we study the descent direction maximizing the decrease in generalization error or the probability of not increasing generalization error. The surprising result is that from both the Bayesian and frequentist perspectives this can yield the natural gradient direction. Although that direction can be very expensive to compute we develop an efficient, general, online approximation to the natural gradient descent which is suited to large scale problems. We report experimental results showing much faster convergence in computation time and in number of iterations with TONGA (Topmoumoute Online natural Gradient Algorithm) than with stochastic gradient descent, even on very large datasets.",
        "date": "2007",
        "authers": [
            "Nicolas Le Roux",
            "Pierre-Antoine Manzagol",
            "Y. Bengio"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/221345414_An_empirical_evaluation_of_deep_architectures_on_problems_with_many_factors_of_variation",
            "https://www.researchgate.net/publication/11294744_Fast_Curvature_Matrix-Vector_Products_for_Second-Order_Gradient_Descent",
            "https://www.researchgate.net/publication/2577260_Natural_Gradient_Descent_for_Training_Multi-Layer_Perceptrons",
            "https://www.researchgate.net/publication/37433283_Large_Scale_Machine_Learning",
            "https://www.researchgate.net/publication/13481213_Complexity_Issues_in_Natural_Gradient_Descent_Method_for_Training_Multilayer_Perceptrons",
            "https://www.researchgate.net/publication/12384402_Adaptive_Method_of_Realizing_Natural_Gradient_Learning_for_Multilayer_Perceptrons",
            "https://www.researchgate.net/publication/2453999_Fast_Second-Order_Gradient_Descent_via_On_Curvature_Matrix-Vector_Products",
            "https://www.researchgate.net/publication/2433873_Natural_Gradient_Works_Efficiently_in_Learning"
        ]
    },
    "paper215": {
        "id": "221345102",
        "title": "Deep learning via Hessian-free optimization",
        "abstract": "We develop a 2 nd -order optimization method based on the \"Hessian-free\" approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks they considered. Our method is practical, easy to use, scales nicely to very large datasets, and isn't limited in applicability to auto- encoders, or any specific model class. We also discuss the issue of \"pathological curvature\" as a possible explanation for the difficulty of deep- learning and how 2 nd -order optimization, and our method in particular, effectively deals with it.",
        "date": "2010",
        "authers": [
            "James Martens"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/220319875_Why_Does_Unsupervised_Pre-training_Help_Deep_Learning",
            "https://www.researchgate.net/publication/200744514_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/11294744_Fast_Curvature_Matrix-Vector_Products_for_Second-Order_Gradient_Descent",
            "https://www.researchgate.net/publication/2822332_Fast_Exact_Multiplication_by_the_Hessian",
            "https://www.researchgate.net/publication/12384402_Adaptive_Method_of_Realizing_Natural_Gradient_Learning_for_Multilayer_Perceptrons",
            "https://www.researchgate.net/publication/6912170_Reducing_the_Dimensionality_of_Data_with_Neural_Networks",
            "https://www.researchgate.net/publication/5580442_Second-order_stagewise_backpropagation_for_Hessian-matrix_analyses_and_investigation_of_negative_curvature"
        ]
    },
    "paper216": {
        "id": "46392541",
        "title": "Deep Big Simple Neural Nets for Handwritten Digit Recognition",
        "abstract": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.",
        "date": "2010Neural",
        "authers": [
            "Dan Claudiu Cire\u015fan",
            "Ueli Meier",
            "Luca Maria Gambardella",
            "J\u00fcrgen Schmidhuber"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/279233597_Beyond_Regression_New_Tools_for_Prediction_and_Analysis_in_the_Behavioral_Science_Thesis_Ph_D_Appl_Math_Harvard_University",
            "https://www.researchgate.net/publication/243781690_Untersuchungen_zu_dynamischen_neuronalen_Netzen",
            "https://www.researchgate.net/publication/228871422_Deep_Belief_Networks_for_phone_recognition",
            "https://www.researchgate.net/publication/228344387_High_Performance_Convolutional_Neural_Networks_for_Document_Processing",
            "https://www.researchgate.net/publication/224716259_Unsupervised_Learning_of_Invariant_Feature_Hierarchies_with_Applications_to_Object_Recognition",
            "https://www.researchgate.net/publication/221080133_Accelerating_Large-Scale_Convolutional_Neural_Networks_with_Parallel_Graphics_Multiprocessors",
            "https://www.researchgate.net/publication/220860992_Best_Practices_for_Convolutional_Neural_Networks_Applied_to_Visual_Document_Analysis",
            "https://www.researchgate.net/publication/216792739_Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model",
            "https://www.researchgate.net/publication/200744514_Greedy_layer-wise_training_of_deep_networks"
        ]
    },
    "paper217": {
        "id": "324435700",
        "title": "NetAdapt Platform-Aware Neural Network Adaptation for Mobile Applications",
        "abstract": "This work proposes an automated algorithm, called NetAdapt, that adapts a pre-trained deep neural network to a mobile platform given a resource budget. While many existing algorithms simplify networks based on the number of MACs or the number of parameters, optimizing those indirect metrics may not necessarily reduce the direct metrics, such as latency and energy consumption. To solve this problem, NetAdapt incorporates direct metrics into its adaptation algorithm. These direct metrics are evaluated using empirical measurements, so that detailed knowledge of the platform and toolchain is not required. NetAdapt automatically and progressively simplifies a pre-trained network until the resource budget (e.g., latency) is met while maximizing the accuracy. Experiment results show that NetAdapt achieves better accuracy versus latency trade-offs on both mobile CPU and mobile GPU, compared with the state-of-the-art automated network simplification algorithms. For image classification on the ImageNet dataset, NetAdapt achieves up to a 1.66$\\times$ speedup in measured inference latency with higher accuracy.",
        "date": "2018",
        "authers": [
            "Tien-Ju Yang",
            "Andrew Howard",
            "Bo Chen",
            "Xiao Zhang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/315667264_Efficient_Processing_of_Deep_Neural_Networks_A_Tutorial_and_Survey",
            "https://www.researchgate.net/publication/349947240_A_method_to_estimate_the_energy_consumption_of_deep_neural_networks",
            "https://www.researchgate.net/publication/345080016_Scalpel_Customizing_DNN_Pruning_to_the_Underlying_Hardware_Parallelism",
            "https://www.researchgate.net/publication/329743813_MorphNet_Fast_Simple_Resource-Constrained_Structure_Learning_of_Deep_Networks",
            "https://www.researchgate.net/publication/323141651_ADC_Automated_Deep_Compression_and_Acceleration_with_Reinforcement_Learning",
            "https://www.researchgate.net/publication/322518045_Not_All_Ops_Are_Created_Equal",
            "https://www.researchgate.net/publication/321901991_Quantization_and_Training_of_Neural_Networks_for_Efficient_Integer-Arithmetic-Only_Inference",
            "https://www.researchgate.net/publication/320968331_Designing_Energy-Efficient_Convolutional_Neural_Networks_Using_Energy-Aware_Pruning",
            "https://www.researchgate.net/publication/319770346_Deep_Fried_Convnets",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition"
        ]
    },
    "paper218": {
        "id": "322059721",
        "title": "Channel Pruning for Accelerating Very Deep Neural Networks",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Yihui He",
            "Xiangyu Zhang",
            "Jian Sun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322649540_Factorized_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions",
            "https://www.researchgate.net/publication/320968331_Designing_Energy-Efficient_Convolutional_Neural_Networks_Using_Energy-Aware_Pruning",
            "https://www.researchgate.net/publication/320964885_SpeedAccuracy_Trade-Offs_for_Modern_Convolutional_Object_Detectors",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/319770349_Pascal_Visual_Object_Classes_Challenge_Results",
            "https://www.researchgate.net/publication/319770342_Compressing_Deep_Convolutional_Networks_using_Vector_Quantization",
            "https://www.researchgate.net/publication/319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding",
            "https://www.researchgate.net/publication/319770323_EIE_Efficient_Inference_Engine_on_Compressed_Deep_Neural_Network",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition"
        ]
    },
    "paper219": {
        "id": "322058668",
        "title": "Domain-Adaptive Deep Network Compression",
        "abstract": "Deep Neural Networks trained on large datasets can be easily transferred to new domains with far fewer labeled examples by a process called fine-tuning. This has the advantage that representations learned in the large source domain can be exploited on smaller target domains. However, networks designed to be optimal for the source task are often prohibitively large for the target task. In this work we address the compression of networks after domain transfer.\nWe focus on compression algorithms based on low-rank matrix decomposition. Existing methods base compression solely on learned network weights and ignore the statistics of network activations. We show that domain transfer leads to large shifts in network activations and that it is desirable to take this into account when compressing. We demonstrate that considering activation statistics when compressing weights leads to a rank-constrained regression problem with a closed-form solution. Because our method takes into account the target domain, it can more optimally remove the redundancy in the weights. Experiments show that our Domain Adaptive Low Rank (DALR) method significantly outperforms existing low-rank compression techniques. With our approach, the fc6 layer of VGG19 can be compressed more than 4x more than using truncated SVD alone \u2013 with only a minor or no loss in accuracy. When applied to domain-transferred networks it allows for compression down to only 5-20% of the original number of parameters with only a minor drop in performance.",
        "date": "2017",
        "authers": [
            "Marc Masana",
            "Joost van de Weijer",
            "Luis Herranz",
            "Andrew D. Bagdanov"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/310610589_Learning_the_Number_of_Neurons_in_Deep_Networks",
            "https://www.researchgate.net/publication/319770342_Compressing_Deep_Convolutional_Networks_using_Vector_Quantization",
            "https://www.researchgate.net/publication/319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding",
            "https://www.researchgate.net/publication/319770230_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/319770191_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks",
            "https://www.researchgate.net/publication/319769909_Distilling_the_Knowledge_in_a_Neural_Network",
            "https://www.researchgate.net/publication/313879156_PixelNet_Representation_of_the_pixels_by_the_pixels_and_for_the_pixels",
            "https://www.researchgate.net/publication/313601183_Optimal_brain_damage_in",
            "https://www.researchgate.net/publication/312222399_Sparse_Factorization_Layers_for_Neural_Networks_with_Limited_Supervision"
        ]
    },
    "paper220": {
        "id": "320971183",
        "title": "More is Less A More Complicated Network with Less Inference Complexity",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Xuanyi Dong",
            "Junshi Huang",
            "Yi Yang",
            "Shuicheng Yan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770230_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/319770191_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319769909_Distilling_the_Knowledge_in_a_Neural_Network",
            "https://www.researchgate.net/publication/319769906_Training_deep_neural_networks_with_low_precision_multiplications",
            "https://www.researchgate.net/publication/311610246_Fast_ConvNets_Using_Group-Wise_Brain_Damage",
            "https://www.researchgate.net/publication/311609205_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices"
        ]
    },
    "paper221": {
        "id": "329745708",
        "title": "Learning Transferable Architectures for Scalable Image Recognition",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Barret Zoph",
            "Vijay Vasudevan",
            "Jonathon Shlens",
            "Quoc V. Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/316598820_DeepArchitect_Automatically_Designing_and_Training_Deep_Architectures",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/313857509_Revisiting_Distributed_Synchronous_SGD",
            "https://www.researchgate.net/publication/311769895_Beyond_Skip_Connections_Top-Down_Modulation_for_Object_Detection",
            "https://www.researchgate.net/publication/311223153_Speedaccuracy_trade-offs_for_modern_convolutional_object_detectors",
            "https://www.researchgate.net/publication/310462326_PolyNet_A_Pursuit_of_Structural_Diversity_in_Very_Deep_Networks",
            "https://www.researchgate.net/publication/309738510_Designing_Neural_Network_Architectures_using_Reinforcement_Learning",
            "https://www.researchgate.net/publication/306885833_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/306187421_SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts"
        ]
    },
    "paper222": {
        "id": "328112952",
        "title": "NetAdapt Platform-Aware Neural Network Adaptation for Mobile Applications 15th European Conference Munich Germany September 8-14 2018 Proceedings Part X",
        "abstract": "This work proposes an algorithm, called NetAdapt, that automatically adapts a pre-trained deep neural network to a mobile platform given a resource budget. While many existing algorithms simplify networks based on the number of MACs or weights, optimizing those indirect metrics may not necessarily reduce the direct metrics, such as latency and energy consumption. To solve this problem, NetAdapt incorporates direct metrics into its adaptation algorithm. These direct metrics are evaluated using empirical measurements, so that detailed knowledge of the platform and toolchain is not required. NetAdapt automatically and progressively simplifies a pre-trained network until the resource budget is met while maximizing the accuracy. Experiment results show that NetAdapt achieves better accuracy versus latency trade-offs on both mobile CPU and mobile GPU, compared with the state-of-the-art automated network simplification algorithms. For image classification on the ImageNet dataset, NetAdapt achieves up to a 1.7\\(\\times \\) speedup in measured inference latency with equal or higher accuracy on MobileNets (V1&V2).",
        "date": "2018",
        "authers": [
            "Tien-Ju Yang",
            "Andrew Howard",
            "Bo Chen",
            "Xiao Zhang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319858391_Scalpel_Customizing_DNN_Pruning_to_the_Underlying_Hardware_Parallelism",
            "https://www.researchgate.net/publication/315667264_Efficient_Processing_of_Deep_Neural_Networks_A_Tutorial_and_Survey",
            "https://www.researchgate.net/publication/310440966_Designing_Energy-Efficient_Convolutional_Neural_Networks_using_Energy-Aware_Pruning",
            "https://www.researchgate.net/publication/280329902_Data-free_Parameter_Pruning_for_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/269932912_Deep_Fried_Convnets",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/2441749_Optimal_Brain_Damage",
            "https://www.researchgate.net/publication/329743813_MorphNet_Fast_Simple_Resource-Constrained_Structure_Learning_of_Deep_Networks",
            "https://www.researchgate.net/publication/329740172_ShuffleNet_An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices",
            "https://www.researchgate.net/publication/329740169_Quantization_and_Training_of_Neural_Networks_for_Efficient_Integer-Arithmetic-Only_Inference"
        ]
    },
    "paper223": {
        "id": "322517761",
        "title": "Inverted Residuals and Linear Bottlenecks Mobile Networks forClassification Detection and Segmentation",
        "abstract": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. The MobileNetV2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input an MobileNetV2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on Imagenet classification, COCO object detection, VOC image segmentation. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as the number of parameters",
        "date": "2018",
        "authers": [
            "Mark Sandler",
            "Andrew Howard",
            "Menglong Zhu",
            "Andrey Zhmoginov"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322539221_Notes_on_the_number_of_linear_regions_of_deep_neural_networks",
            "https://www.researchgate.net/publication/320075558_Connectivity_Learning_in_Multi-Branch_Networks",
            "https://www.researchgate.net/publication/317300069_Learning_Time-Efficient_Deep_Architectures_with_Budgeted_Super_Networks",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/308278279_SSD_Single_Shot_MultiBox_Detector",
            "https://www.researchgate.net/publication/307536925_Pruning_Filters_for_Efficient_ConvNets",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/303409435_Residual_Networks_Behave_Like_Ensembles_of_Relatively_Shallow_Networks",
            "https://www.researchgate.net/publication/301839500_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better"
        ]
    },
    "paper224": {
        "id": "322058064",
        "title": "ThiNet A Filter Level Pruning Method for Deep Neural Network Compression",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Jian-Hao Luo",
            "Jianxin Wu",
            "Weiyao Lin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/307536925_Pruning_Filters_for_Efficient_ConvNets",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/287853408_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices",
            "https://www.researchgate.net/publication/281895813_Guiding_Long-Short_Term_Memory_for_Image_Caption_Generation",
            "https://www.researchgate.net/publication/275279789_Compressing_Neural_Networks_with_the_Hashing_Trick",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/261368736_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/240308775_Representation_Learning_A_Review_and_New_Perspectives",
            "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors",
            "https://www.researchgate.net/publication/224342191_Fast_Solution_of_L1-Norm_Minimization_Problems_When_the_Solution_May_Be_Sparse"
        ]
    },
    "paper225": {
        "id": "320963610",
        "title": "LCNN Lookup-Based Convolutional Neural Network",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Hessam Bagherinezhad",
            "Mohammad Rastegari",
            "Ali Farhadi"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308457764_Quantized_Neural_Networks_Training_Neural_Networks_with_Low_Precision_Weights_and_Activations",
            "https://www.researchgate.net/publication/305881526_Matching_Networks_for_One_Shot_Learning",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/301878495_SqueezeNet_AlexNet-level_accuracy_with_50x_fewer_parameters_and_05MB_model_size",
            "https://www.researchgate.net/publication/301848151_Binarized_Neural_Networks_Training_Deep_Neural_Networks_with_Weights_and_Activations_Constrained_to_1_or_-1",
            "https://www.researchgate.net/publication/287853408_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices",
            "https://www.researchgate.net/publication/282844341_Neural_Networks_with_Few_Multiplications",
            "https://www.researchgate.net/publication/280329902_Data-free_Parameter_Pruning_for_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/275279789_Compressing_Neural_Networks_with_the_Hashing_Trick",
            "https://www.researchgate.net/publication/263352539_From_Generic_to_Specific_Deep_Representations_for_Visual_Recognition"
        ]
    },
    "paper226": {
        "id": "308896188",
        "title": "Error bounds for approximations with deep ReLU networks",
        "abstract": "We study how approximation errors of neural networks with ReLU activation functions depend on the depth of the network. We establish rigorous error bounds showing that deep ReLU networks are significantly more expressive than shallow ones as long as approximations of smooth functions are concerned. At the same time, we show that on a set of functions constrained only by their degree of smoothness, a ReLU network architecture cannot in general achieve approximation accuracy with better than a power law dependence on the network size, regardless of its depth.",
        "date": "2016Neural",
        "authers": [
            "Dmitry Yarotsky"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322539221_Notes_on_the_number_of_linear_regions_of_deep_neural_networks",
            "https://www.researchgate.net/publication/301841654_Learning_Real_and_Boolean_Functions_When_Is_Deep_Better_Than_Shallow",
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/277411157_Deep_Learning",
            "https://www.researchgate.net/publication/319770106_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/316349627_On_the_uniform_convergence_of_relative_frequencies_of_events_to_their_probabilities",
            "https://www.researchgate.net/publication/306186507_Deep_vs_shallow_networks_An_approximation_theory_perspective",
            "https://www.researchgate.net/publication/304018151_On_the_expressive_power_of_deep_neural_networks",
            "https://www.researchgate.net/publication/282403870_Representation_Benefits_of_Deep_Feedforward_Networks",
            "https://www.researchgate.net/publication/263894641_On_the_Complexity_of_Neural_Network_Classifiers_A_Comparison_Between_Shallow_and_Deep_Architectures"
        ]
    },
    "paper227": {
        "id": "281895600",
        "title": "On the Expressive Power of Deep Learning A Tensor Analysis",
        "abstract": "It has long been conjectured that hypothesis spaces suitable for data that is\ncompositional in nature, such as text or images, may be more efficiently\nrepresented with deep hierarchical architectures than with shallow ones.\nDespite the vast empirical evidence, formal arguments to date are limited and\ndo not capture the kind of networks used in practice. Using tensor\nfactorization, we derive a universal hypothesis space implemented by an\narithmetic circuit over functions applied to local data structures (e.g. image\npatches). The resulting networks first pass the input through a representation\nlayer, and then proceed with a sequence of layers comprising sum followed by\nproduct-pooling, where sum corresponds to the widely used convolution operator.\nThe hierarchical structure of networks is born from factorizations of tensors\nbased on the linear weights of the arithmetic circuits. We show that a shallow\nnetwork corresponds to a rank-1 decomposition, whereas a deep network\ncorresponds to a Hierarchical Tucker (HT) decomposition. Log-space computation\nfor numerical stability transforms the networks into SimNets.\nIn its basic form, our main theoretical result shows that the set of\npolynomially sized rank-1 decomposable tensors has measure zero in the\nparameter space of polynomially sized HT decomposable tensors. In deep learning\nterminology, this amounts to saying that besides a negligible set, all\nfunctions that can be implemented by a deep network of polynomial size, require\nan exponential size if one wishes to implement (or approximate) them with a\nshallow network. Our construction and theory shed new light on various\npractices and ideas employed by the deep learning community, and in that sense\nbear a paradigmatic contribution as well.",
        "date": "2016",
        "authers": [
            "Nadav Cohen",
            "Or Sharir",
            "Amnon Shashua"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322539221_Notes_on_the_number_of_linear_regions_of_deep_neural_networks",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/332138022_Beating_the_Perils_of_Non-Convexity_Guaranteed_Training_of_Neural_Networks_using_Tensor_Methods",
            "https://www.researchgate.net/publication/329651461_Circuit_Complexity_and_Neural_Networks",
            "https://www.researchgate.net/publication/319770386_Sum-Product_Networks_A_New_Deep_Architecture",
            "https://www.researchgate.net/publication/319770263_Reasoning_With_Neural_Tensor_Networks_for_Knowledge_Base_Completion",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/291295837_Reasoning_with_neural_tensor_networks_for_knowledge_base_completion",
            "https://www.researchgate.net/publication/289810433_Hierarchical_tensor_decomposition_of_latent_tree_graphical_models",
            "https://www.researchgate.net/publication/288359152_Natural_images_Gaussian_mixtures_and_dead_leaves"
        ]
    },
    "paper228": {
        "id": "319770106",
        "title": "On the Expressive Power of Deep Learning A Tensor Analysis",
        "abstract": "It has long been conjectured that hypothesis spaces suitable for data that is compositional in nature, such as text or images, may be more efficiently represented with deep hierarchical architectures than with shallow ones. Despite the vast empirical evidence, formal arguments to date are limited and do not capture the kind of networks used in practice. Using tensor factorization, we derive a universal hypothesis space implemented by an arithmetic circuit over functions applied to local data structures (e.g. image patches). The resulting networks first pass the input through a representation layer, and then proceed with a sequence of layers comprising sum followed by product-pooling, where sum corresponds to the widely used convolution operator. The hierarchical structure of networks is born from factorizations of tensors based on the linear weights of the arithmetic circuits. We show that a shallow network corresponds to a rank-1 decomposition, whereas a deep network corresponds to a Hierarchical Tucker (HT) decomposition. Log-space computation for numerical stability transforms the networks into SimNets. In its basic form, our main theoretical result shows that the set of polynomially sized rank-1 decomposable tensors has measure zero in the parameter space of polynomially sized HT decomposable tensors. In deep learning terminology, this amounts to saying that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require an exponential size if one wishes to implement (or approximate) them with a shallow network. Our construction and theory shed new light on various practices and ideas employed by the deep learning community, and in that sense bear a paradigmatic contribution as well.",
        "date": "2015",
        "authers": [
            "Nadav Cohen",
            "Or Sharir",
            "Amnon Shashua"
        ],
        "refrences": []
    },
    "paper229": {
        "id": "314361329",
        "title": "Nearly-tight VC-dimension bounds for piecewise linear neural networks",
        "abstract": "We prove new upper and lower bounds on the VC-dimension of deep neural networks with the ReLU activation function. These bounds are tight for almost the entire range of parameters. Letting $W$ be the number of weights and $L$ be the number of layers, we prove that the VC-dimension is $O(W L \\log(W))$ and $\\Omega( W L \\log(W/L) )$. This improves both the previously known upper bounds and lower bounds. In terms of the number $U$ of non-linear units, we prove a tight bound $\\Theta(W U)$ on the VC-dimension. All of these results generalize to arbitrary piecewise linear activation functions.",
        "date": "2017",
        "authers": [
            "Nick Harvey",
            "Chris Liaw",
            "Abbas Mehrabian"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/309131837_Why_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/308896188_Error_bounds_for_approximations_with_deep_ReLU_networks",
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/277411157_Deep_Learning",
            "https://www.researchgate.net/publication/2809085_Almost_Linear_VC_Dimension_Bounds_for_Piecewise_Polynomial_Networks",
            "https://www.researchgate.net/publication/319770106_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/309572399_Depth_Separation_in_ReLU_Networks_for_Approximating_Smooth_Non-Linear_Functions",
            "https://www.researchgate.net/publication/301857086_Benefits_of_depth_in_neural_networks",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/246732421_Lower_Bounds_for_Approximation_by_Nonlinear_Manifolds"
        ]
    },
    "paper230": {
        "id": "311609041",
        "title": "Deep Residual Learning for Image Recognition",
        "abstract": "",
        "date": "2016",
        "authers": [
            "Kaiming He",
            "Xiangyu Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/269935397_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/265908778_Deeply-Supervised_Nets",
            "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding",
            "https://www.researchgate.net/publication/264929445_A_Multigrid_Tutorial_2nd_edition_with_corrections",
            "https://www.researchgate.net/publication/260126867_On_the_Number_of_Linear_Regions_of_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/259440750_Exact_solutions_to_the_nonlinear_dynamics_of_learning_in_deep_linear_neural_networks"
        ]
    },
    "paper231": {
        "id": "301857086",
        "title": "Benefits of depth in neural networks",
        "abstract": "For any positive integer $k$, there exist neural networks with $\\Theta(k^3)$ layers, $\\Theta(1)$ nodes per layer, and $\\Theta(1)$ distinct parameters which can not be approximated by networks with $\\mathcal{O}(k)$ layers unless they are exponentially large --- they must possess $\\Omega(2^k)$ nodes. This result is proved here for a class of nodes termed \"semi-algebraic gates\" which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, and boosted decision trees (in this last case with a stronger separation: $\\Omega(2^{k^3})$ total tree nodes are required).",
        "date": "2016",
        "authers": [
            "Matus Telgarsky"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/260126867_On_the_Number_of_Linear_Regions_of_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/236736771_Shallow_vs_Deep_Sum-Product_Networks",
            "https://www.researchgate.net/publication/215990477_An_Empirical_Comparison_of_Supervised_Learning_Algorithms",
            "https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/303901717_Super-linear_gate_and_super-quadratic_wire_lower_bounds_for_depth-two_and_depth-three_threshold_circuits",
            "https://www.researchgate.net/publication/290161073_On_the_representation_of_continuous_functions_of_several_variables_by_superposition_of_continuous_functions_of_one_variable_and_addition",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/284788019_Super-Linear_Gate_and_Super-Quadratic_Wire_Lower_Bounds_for_Depth-Two_and_Depth-Three_Threshold_Circuits",
            "https://www.researchgate.net/publication/275055381_An_average-case_depth_hierarchy_theorem_for_Boolean_circuits"
        ]
    },
    "paper232": {
        "id": "287250773",
        "title": "The Power of Depth for Feedforward Neural Networks",
        "abstract": "We show that there are simple functions on $\\mathbb{R}^d$, expressible by\nsmall 3-layer feedforward neural networks, which cannot be approximated by any\n2-layer network, to more than a certain constant accuracy, unless its width is\nexponential in the dimension. The result holds for most continuous activation\nfunctions, including rectified linear units and sigmoids, and is a formal\ndemonstration that depth -- even if increased by 1 -- can be exponentially more\nvaluable than width for standard feedforward neural networks. Moreover,\ncompared to related results in the context of Boolean functions, our result\nrequires fewer assumptions, and the proof techniques and construction are very\ndifferent.",
        "date": "2015",
        "authers": [
            "Ronen Eldan",
            "Ohad Shamir"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/260126867_On_the_Number_of_Linear_Regions_of_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/259400019_On_the_number_of_response_regions_of_deep_feed_forward_networks_with_piece-wise_linear_activations",
            "https://www.researchgate.net/publication/236736771_Shallow_vs_Deep_Sum-Product_Networks",
            "https://www.researchgate.net/publication/225866987_Approximation_and_Estimation_Bounds_for_Artificial_Neural_Networks",
            "https://www.researchgate.net/publication/221497561_Approximation_and_Estimation_Bounds_for_Artificial_Neural_Networks",
            "https://www.researchgate.net/publication/220573544_Threshold_Circuits_of_Bounded_Depth",
            "https://www.researchgate.net/publication/220365641_Arithmetic_Circuits_A_survey_of_recent_results_and_open_questions",
            "https://www.researchgate.net/publication/51967354_On_Fourier_Transforms_of_Radial_Functions_and_Distributions",
            "https://www.researchgate.net/publication/2716732_A_Comparison_of_the_Computational_Power_of_Sigmoid_and_Boolean_Threshold_Circuits"
        ]
    },
    "paper233": {
        "id": "322539221",
        "title": "Notes on the number of linear regions of deep neural networks",
        "abstract": "We follow up on previous work addressing the number of response regions of the functions representable by feedforward neural networks with piecewise linear activation functions. We discuss upper bounds on the maximum number of linear regions for deep networks with rectified linear units. We elaborate on the identification of input regions as an analysis tool, and how it implies exponential gaps between shallow and deep networks, not only in terms of the maximum number of linear regions but also other additive properties over the input domain and more general types of activation functions.",
        "date": "2017",
        "authers": [
            "Guido Montufar"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/260126867_On_the_Number_of_Linear_Regions_of_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/220695511_Neural_Network_Learning_Theoretical_Foundations"
        ]
    },
    "paper234": {
        "id": "309131743",
        "title": "Tensorial Mixture Models",
        "abstract": "Casting neural networks in generative frameworks is a highly sought-after endeavor these days. Contemporary methods, such as Generative Adversarial Networks, capture some of the generative capabilities, but not all. In particular, they lack the ability of tractable marginalization, and thus are not suitable for many tasks. Other methods, based on arithmetic circuits and sum-product networks, do allow tractable marginalization, but their performance is challenged by the need to learn the structure of a circuit. Building on the tractability of arithmetic circuits, we leverage concepts from tensor analysis, and derive a family of generative models we call Tensorial Mixture Models (TMMs). TMMs assume a simple convolutional network structure, and in addition, lend themselves to theoretical analyses that allow comprehensive understanding of the relation between their structure and their expressive properties. We thus obtain a generative model that is tractable on one hand, and on the other hand, allows effective representation of rich distributions in an easily controlled manner. These two capabilities are brought together in the task of classification under missing data, where TMMs deliver state of the art accuracies with seamless implementation and design.",
        "date": "2016",
        "authers": [
            "Or Sharir",
            "Ronen Tamari",
            "Nadav Cohen",
            "Amnon Shashua"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/315457753_Boosting_Dilated_Convolutional_Networks_with_Mixed_Tensor_Decompositions",
            "https://www.researchgate.net/publication/305881127_Improved_Techniques_for_Training_GANs",
            "https://www.researchgate.net/publication/319770395_An_Analysis_of_Single-Layer_Networks_in_Unsupervised_Feature_Learning",
            "https://www.researchgate.net/publication/319770386_Sum-Product_Networks_A_New_Deep_Architecture",
            "https://www.researchgate.net/publication/319770355_Generative_Adversarial_Nets",
            "https://www.researchgate.net/publication/319770229_Auto-Encoding_Variational_Bayes",
            "https://www.researchgate.net/publication/319770144_Unsupervised_Representation_Learning_with_Deep_Convolutional_Generative_Adversarial_Networks",
            "https://www.researchgate.net/publication/309438886_Memory_access_patterns_the_missing_piece_of_the_multi-GPU_puzzle",
            "https://www.researchgate.net/publication/303993361_Improving_Variational_Inference_with_Inverse_Autoregressive_Flow",
            "https://www.researchgate.net/publication/303921589_Deep_Directed_Generative_Models_with_Energy-Based_Probability_Estimation"
        ]
    },
    "paper235": {
        "id": "308026508",
        "title": "WaveNet A Generative Model for Raw Audio",
        "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.",
        "date": "2016",
        "authers": [
            "Aaron van den oord",
            "Sander Dieleman",
            "Heiga Zen",
            "Karen Simonyan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/304671740_WORLD_A_Vocoder-Based_High-Quality_Speech_Synthesis_System_for_Real-Time_Applications",
            "https://www.researchgate.net/publication/304372544_Directly_modeling_voiced_and_unvoiced_components_in_speech_waveforms_by_neural_networks",
            "https://www.researchgate.net/publication/304335754_Recent_Advances_in_Google_Real-Time_HMM-Driven_Unit_Selection_Synthesizer",
            "https://www.researchgate.net/publication/308843134_Speech_acoustic_modeling_from_raw_multichannel_waveforms",
            "https://www.researchgate.net/publication/308805598_Directly_modeling_speech_waveforms_by_neural_networks_for_statistical_parametric_speech_synthesis",
            "https://www.researchgate.net/publication/304486081_VOCAINE_The_Vocoder_and_Applications_in_Speech_Synthesis",
            "https://www.researchgate.net/publication/304372081_A_deep_auto-encoder_based_low-dimensional_feature_extraction_from_FFT_spectral_envelopes_for_statistical_parametric_speech_synthesis",
            "https://www.researchgate.net/publication/304018350_Conditional_Image_Generation_with_PixelCNN_Decoders",
            "https://www.researchgate.net/publication/301874314_Pixel_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/301847993_Exploring_the_Limits_of_Language_Modeling"
        ]
    },
    "paper236": {
        "id": "304018355",
        "title": "Exponential expressivity in deep neural networks through transient chaos",
        "abstract": "We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic, deep neural networks with random weights. Our results reveal an order-to-chaos expressivity phase transition, with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width. We prove this generic class of deep random functions cannot be efficiently computed by any shallow network, going beyond prior work restricted to the analysis of single functions. Moreover, we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space. Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities, and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions.",
        "date": "2016",
        "authers": [
            "Ben Poole",
            "Subhaneil Lahiri",
            "Maithra Raghu",
            "Jascha Sohl-Dickstein"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/301841654_Learning_Real_and_Boolean_Functions_When_Is_Deep_Better_Than_Shallow",
            "https://www.researchgate.net/publication/278969484_Deep_Knowledge_Tracing",
            "https://www.researchgate.net/publication/260126867_On_the_Number_of_Linear_Regions_of_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/287469471_On_the_representational_efficiency_of_Restricted_Boltzmann_Machines",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/282403870_Representation_Benefits_of_Deep_Feedforward_Networks",
            "https://www.researchgate.net/publication/269722411_DeepSpeech_Scaling_up_end-to-end_speech_recognition",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/263894641_On_the_Complexity_of_Neural_Network_Classifiers_A_Comparison_Between_Shallow_and_Deep_Architectures",
            "https://www.researchgate.net/publication/259367763_Playing_Atari_with_Deep_Reinforcement_Learning"
        ]
    },
    "paper237": {
        "id": "303448829",
        "title": "Inductive Bias of Deep Convolutional Networks through Pooling Geometry",
        "abstract": "Our formal understanding of the inductive bias that drives the success of convolutional networks on computer vision tasks is limited. In particular, it is unclear what makes hypotheses spaces born from convolution and pooling operations so suitable for natural images. In this paper we study the ability of convolutional arithmetic circuits to model correlations among regions of their input. Correlations are formalized through the notion of separation rank, which for a given input partition, measures how far a function is from being separable. We show that a polynomially sized deep network supports exponentially high separation ranks for certain input partitions, while being limited to polynomial separation ranks for others. The network's pooling geometry effectively determines which input partitions are favored, thus serves as a means for controlling the inductive bias. Contiguous pooling windows as commonly employed in practice favor interleaved partitions over coarse ones, orienting the inductive bias towards the statistics of natural images. In addition to analyzing deep networks, we show that shallow ones support only linear separation ranks, and by this gain insight into the benefit of functions brought forth by depth - they are able to efficiently model strong correlation under favored partitions of the input.",
        "date": "2016",
        "authers": [
            "Nadav Cohen",
            "Amnon Shashua"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322539221_Notes_on_the_number_of_linear_regions_of_deep_neural_networks",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/301841654_Learning_Real_and_Boolean_Functions_When_Is_Deep_Better_Than_Shallow",
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/281285245_The_Zero_Set_of_a_Polynomial",
            "https://www.researchgate.net/publication/319769990_I-theory_on_depth_vs_width_hierarchical_function_composition",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/286512696_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/282403870_Representation_Benefits_of_Deep_Feedforward_Networks"
        ]
    },
    "paper238": {
        "id": "319770395",
        "title": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning",
        "abstract": "A great deal of research has focused on algorithms for learning features from un- labeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR by employing increasingly complex unsupervised learning al- gorithms and deep models. In this paper, however, we show that several very sim- ple factors, such as the number of hidden nodes in the model, may be as important to achieving high performance as the choice of learning algorithm or the depth of the model. Specifically, we will apply several off-the-shelf feature learning al- gorithms (sparse auto-encoders, sparse RBMs and K-means clustering, Gaussian mixtures) to NORB and CIFAR datasets using only single-layer networks. We then present a detailed analysis of the effect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (stride) be- tween extracted features, and the effect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are as critical to achieving high performance as the choice of algorithm itselfso critical, in fact, that when these parameters are pushed to their limits, we are able to achieve state-of-the- art performance on both CIFAR and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyper-parameters to tune beyond the model structure it- self, and is very easy implement. Despite the simplicity of our system, we achieve performance beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.0% accuracy respectively).",
        "date": "2011",
        "authers": [
            "Adam Coates",
            "Honglak Lee",
            "Andrew Y Ng"
        ],
        "refrences": []
    },
    "paper239": {
        "id": "319770007",
        "title": "Benefits of depth in neural networks",
        "abstract": "For any positive integer $k$, there exist neural networks with $backslashTheta(k^3)$ layers, $backslashTheta(1)$ nodes per layer, and $backslashTheta(1)$ distinct parameters which can not be approximated by networks with $backslashmathcalO(k)$ layers unless they are exponentially large --- they must possess $backslashOmega(2^k)$ nodes. This result is proved here for a class of nodes termed \"semi-algebraic gates\" which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, sum-product networks, and boosted decision trees (in this last case with a stronger separation: $backslashOmega(2^{k^}3)$ total tree nodes are required).",
        "date": "2016",
        "authers": [
            "Matus Telgarsky"
        ],
        "refrences": []
    },
    "paper240": {
        "id": "312461699",
        "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks",
        "abstract": "We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field. We analyze the effective receptive field in several architecture designs, and the effect of nonlinear activations, dropout, sub-sampling and skip connections on it. This leads to suggestions for ways to address its tendency to be too small.",
        "date": "2017",
        "authers": [
            "Wenjie Luo",
            "Yujia Li",
            "Raquel Urtasun",
            "Richard Zemel"
        ],
        "refrences": []
    },
    "paper241": {
        "id": "309572399",
        "title": "Depth Separation in ReLU Networks for Approximating Smooth Non-Linear Functions",
        "abstract": "We provide a depth-based separation result for feed-forward ReLU neural networks, showing that a wide family of non-linear, twice-differentiable functions on $[0,1]^d$, which can be approximated to accuracy $\\epsilon$ by ReLU networks of depth and width $\\mathcal{O}(\\text{poly}(\\log(1/\\epsilon)))$, cannot be approximated to similar accuracy by constant-depth ReLU networks, unless their width is at least $\\Omega(1/\\epsilon)$.",
        "date": "2016",
        "authers": [
            "Itay Safran",
            "Ohad Shamir"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/319770007_Benefits_of_depth_in_neural_networks",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/286512696_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/226439292_Approximation_by_superpositions_of_a_sigmoidal_function_Math_Cont_Sig_Syst_MCSS_2303-314"
        ]
    },
    "paper242": {
        "id": "307627766",
        "title": "From free energy to expected energy Improving energy-based value function approximation in reinforcement learning",
        "abstract": "Free-energy based reinforcement learning (FERL) was proposed for learning in high-dimensional state- and action spaces. However, the FERL method does only really work well with binary, or close to binary, state input, where the number of active states are fewer than the number of non-active states. In the FERL method the value function is approximated by the negative free energy of a restricted Boltzmann machine (RBM). In our earlier study, we demonstrated that the performance and the robustness of the FERL method can be improved by scaling the free energy by a constant that is related to the size of network. In this study, we propose that RBM function approximation can be further improved by approximating the value function by the negative expected energy (EERL), instead of the negative free energy, as well as being able to handle continuous state input. We validate our proposed method by demonstrating that EERL: 1) outperforms FERL, as well as standard neural network and linear function approximation, for three versions of a gridworld task with high-dimensional image state input; 2) achieves new state-of-the-art results in stochastic SZ-Tetris in both model-free and model-based learning settings; and 3) significantly outperforms FERL and standard neural network function approximation for a robot navigation task with raw and noisy RGB images as state input and a large number of actions.",
        "date": "2016Neural",
        "authers": [
            "Stefan Elfwing",
            "Eiji Uchibe",
            "Kenji Doya"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/266205382_Expected_energy-based_restricted_Boltzmann_machine_for_classification",
            "https://www.researchgate.net/publication/265588028_Neural_Network_Ensembles_in_Reinforcement_Learning",
            "https://www.researchgate.net/publication/239571798_Information_processing_in_dynamical_systems_Foundations_of_harmony_theory",
            "https://www.researchgate.net/publication/235756951_Scaled_Free-Energy_Based_Reinforcement_Learning_for_Robust_and_Efficient_Learning_in_High-Dimensional_State_Spaces",
            "https://www.researchgate.net/publication/304109482_Training_products_of_experts_by_minimizing_contrastive_divergence",
            "https://www.researchgate.net/publication/284106719_Advances_in_neural_information_processing_systems_8",
            "https://www.researchgate.net/publication/272161307_Reinforcement_Learning_An_Introduction",
            "https://www.researchgate.net/publication/265748773_Learning_Multiple_Layers_of_Features_from_Tiny_Images",
            "https://www.researchgate.net/publication/247757128_The_Cyber_Rodent_Project_Exploration_of_Adaptive_Mechanisms_for_Self-Preservation_and_Self-Reproduction",
            "https://www.researchgate.net/publication/247709546_Temporal_Differences-Based_Policy_Iteration_and_Applications_in_Neuro-Dynamic_Programming1"
        ]
    },
    "paper243": {
        "id": "292074166",
        "title": "Mastering the game of Go with deep neural networks and tree search",
        "abstract": "The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses \u2018value networks\u2019 to evaluate board positions and \u2018policy networks\u2019 to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.",
        "date": "2016Nature",
        "authers": [
            "David Silver",
            "Aja Huang",
            "Christopher Maddison",
            "Arthur Guez"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/277411157_Deep_Learning",
            "https://www.researchgate.net/publication/269935589_Move_Evaluation_in_Go_Using_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/312990324_Td-gammon_a_self-Teaching_backgammon_program_achieves_master-level_play",
            "https://www.researchgate.net/publication/312986214_Some_studies_in_machine_learning_using_the_game_of_checkers",
            "https://www.researchgate.net/publication/300449670_Investigating_the_Limits_of_Monte-Carlo_Tree_Search_Methods_in_Computer_Go",
            "https://www.researchgate.net/publication/286329574_Monte-Carlo_simulation_balancing_applied_to_9_9_Go",
            "https://www.researchgate.net/publication/279964320_Simple_statistical_gradient-following_algorithms_for_connectionist_reinforcement_learning",
            "https://www.researchgate.net/publication/272837232_Human-level_control_through_deep_reinforcement_learning",
            "https://www.researchgate.net/publication/269417695_Teaching_Deep_Convolutional_Neural_Networks_to_Play_Go"
        ]
    },
    "paper244": {
        "id": "282182152",
        "title": "Deep Reinforcement Learning with Double Q-learning",
        "abstract": "The popular Q-learning algorithm is known to overestimate action values under\ncertain conditions. It was not previously known whether, in practice, such\noverestimations are common, whether this harms performance, and whether they\ncan generally be prevented. In this paper, we answer all these questions\naffirmatively. In particular, we first show that the recent DQN algorithm,\nwhich combines Q-learning with a deep neural network, suffers from substantial\noverestimations in some games in the Atari 2600 domain. We then show that the\nidea behind the Double Q-learning algorithm, which was introduced in a tabular\nsetting, can be generalized to work with large-scale function approximation. We\npropose a specific adaptation to the DQN algorithm and show that the resulting\nalgorithm not only reduces the observed overestimations, as hypothesized, but\nthat this also leads to much better performance on several games.",
        "date": "2015",
        "authers": [
            "Hado Van Hasselt",
            "Arthur Guez",
            "David Silver"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/280104499_Massively_Parallel_Methods_for_Deep_Reinforcement_Learning",
            "https://www.researchgate.net/publication/273704409_An_Emphatic_Approach_to_the_Problem_of_Off-policy_Temporal-Difference_Learning",
            "https://www.researchgate.net/publication/229328831_The_Arcade_Learning_Environment_An_Evaluation_Platform_for_General_Agents",
            "https://www.researchgate.net/publication/221619239_Double_Q-learning",
            "https://www.researchgate.net/publication/322808208_Temporal_Difference_Learning_and_TD-Gammon",
            "https://www.researchgate.net/publication/272837232_Human-level_control_through_deep_reinforcement_learning",
            "https://www.researchgate.net/publication/268352406_Gradient_Temporal-Difference_Learning_Algorithms",
            "https://www.researchgate.net/publication/263757661_Learning_to_Predict_by_the_Methods_of_Temporal_Differences",
            "https://www.researchgate.net/publication/235709806_Reinforcement_Learning_A_Survey",
            "https://www.researchgate.net/publication/222440273_Neocognitron_A_hierarchical_neural_network_capable_of_visual_pattern_recognition"
        ]
    },
    "paper245": {
        "id": "280898866",
        "title": "Approximate Modified Policy Iteration and its Application to the Game of Tetris",
        "abstract": "Modified policy iteration (MPI) is a dynamic programming (DP) algorithm that contains the two celebrated policy and value iteration methods. Despite its generality, MPI has not been thoroughly studied, especially its approximation form which is used when the state and/or action spaces are large or infinite. In this paper, we propose three implementations of approximate MPI (AMPI) that are extensions of the well-known approximate DP algorithms: fitted-value iteration, fitted-Q iteration, and classification-based policy iteration. We provide error propagation analysis that unify those for approximate policy and value iteration. We develop the finite-sample analysis of these algorithms, which highlights the influence of their parameters. In the classification-based version of the algorithm (CBMPI), the analysis shows that MPI's main parameter controls the balance between the estimation error of the classifier and the overall value function approximation. We illustrate and evaluate the behavior of these new algorithms in the Mountain Car and Tetris problems. Remarkably, in Tetris, CBMPI outperforms the existing DP approaches by a large margin, and competes with the current state-of-the-art methods while using fewer samples.1 \u00a9 2015 Bruno Scherrer, Mohammad Ghavamzadeh, Victor Gabillon, Boris Lesner, Matthieu Geist.",
        "date": "2015",
        "authers": [
            "Bruno Scherrer",
            "Mohammad Ghavamzadeh",
            "Victor Gabillon",
            "Boris Lesner"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/280700426_Approximate_Dynamic_Programming_Finally_Performs_Well_in_the_Game_of_Tetris",
            "https://www.researchgate.net/publication/313991982_Reinforcement_Learning_Algorithms_for_MDPs",
            "https://www.researchgate.net/publication/313505421_Completely_derandomized_self-adaptation_in_evolution_strategies",
            "https://www.researchgate.net/publication/311672961_A_distribution-free_theory_of_nonparametric_regression",
            "https://www.researchgate.net/publication/307881957_LIBSVM_A_library_for_support_vector_machines",
            "https://www.researchgate.net/publication/290113970_Chapter_8_Markov_decision_processes",
            "https://www.researchgate.net/publication/286474367_A_Unifying_Perspective_of_Parametric_Policy_Search_Methods_for_Markov_Decision_Processes",
            "https://www.researchgate.net/publication/272623654_Libsvm",
            "https://www.researchgate.net/publication/266952772_Performance_Bounds_for_Lambda_Policy_Iteration_and_Application_to_the_Game_of_Tetris",
            "https://www.researchgate.net/publication/263242310_An_Upper_Bound_on_the_Loss_from_Approximate_Optimal-Value_Functions"
        ]
    },
    "paper246": {
        "id": "280104499",
        "title": "Massively Parallel Methods for Deep Reinforcement Learning",
        "abstract": "We present the first massively distributed architecture for deep\nreinforcement learning. This architecture uses four main components: parallel\nactors that generate new behaviour; parallel learners that are trained from\nstored experience; a distributed neural network to represent the value function\nor behaviour policy; and a distributed store of experience. We used our\narchitecture to implement the Deep Q-Network algorithm (DQN). Our distributed\nalgorithm was applied to 49 games from Atari 2600 games from the Arcade\nLearning Environment, using identical hyperparameters. Our performance\nsurpassed non-distributed DQN in 41 of the 49 games and also reduced the\nwall-time required to achieve these results by an order of magnitude on most\ngames.",
        "date": "2015",
        "authers": [
            "Arun Nair",
            "Praveen Srinivasan",
            "Sam Blackwell",
            "Cagdas Alcicek"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions",
            "https://www.researchgate.net/publication/229328831_The_Arcade_Learning_Environment_An_Evaluation_Platform_for_General_Agents",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/272837232_Human-level_control_through_deep_reinforcement_learning",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/262355828_MapReduce_for_Parallel_Reinforcement_Learning",
            "https://www.researchgate.net/publication/259367763_Playing_Atari_with_Deep_Reinforcement_Learning",
            "https://www.researchgate.net/publication/258818168_Speech_Recognition_with_Deep_Recurrent_Neural_Networks"
        ]
    },
    "paper247": {
        "id": "280043948",
        "title": "High-Dimensional Function Approximation for Knowledge-Free Reinforcement Learning a Case Study in SZ-Tetris",
        "abstract": "SZ-Tetris, a restricted version of Tetris, is a dicult reinforcement learning task. Previous research showed that, similarly to the original Tetris, value function-based methods such as temporal dierence learning, do not work well for SZ-Tetris. The best performance in this game was achieved by employing direct policy search techniques, in particular the cross-entropy method in combination with handcrafted features. Nonetheless, a simple heuristic hand-coded player scores even higher. Here we show that it is possible to equal its performance with CMA-ES (Covariance Matrix Adaptation Evolution Strategy). We demonstrate that further improvement is possible by employing systematic n-tuple network, a knowledge-free function approximator, and VD-CMA-ES, a linear variant of CMA-ES for high dimension optimization. Last but not least, we show that a large systematic n-tuple network (involving more than 4 million parameters) allows the classical temporal dierence learning algorithm to obtain similar average performance to VD-CMA-ES, but at 20 times lower computational expense, leading to the best policy for SZ-Tetris known to date. These results enrich the current understanding of diculty of SZ-Tetris, and shed new light on the capabilities of particular search paradigms when applied to representations of various characteristics and dimensionality.",
        "date": "2015",
        "authers": [
            "Wojciech Ja\u015bkowski",
            "Marcin Szubert",
            "Pawe\u0142 Liskowski",
            "Krzysztof Krawiec"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/269333585_Systematic_N-Tuple_Networks_for_Othello_Position_Evaluation",
            "https://www.researchgate.net/publication/266656106_Comparison-Based_Natural_Gradient_Optimization_in_High_Dimension",
            "https://www.researchgate.net/publication/265612548_Selective_Neural_Network_Ensembles_in_Reinforcement_Learning",
            "https://www.researchgate.net/publication/265588028_Neural_Network_Ensembles_in_Reinforcement_Learning",
            "https://www.researchgate.net/publication/263198856_Temporal_Difference_Learning_of_N-Tuple_Networks_for_the_Game_2048",
            "https://www.researchgate.net/publication/322808208_Temporal_Difference_Learning_and_TD-Gammon",
            "https://www.researchgate.net/publication/313505421_Completely_derandomized_self-adaptation_in_evolution_strategies",
            "https://www.researchgate.net/publication/290106209_Reinforcement_Learning_in_Games",
            "https://www.researchgate.net/publication/263757661_Learning_to_Predict_by_the_Methods_of_Temporal_Differences",
            "https://www.researchgate.net/publication/247709546_Temporal_Differences-Based_Policy_Iteration_and_Applications_in_Neuro-Dynamic_Programming1"
        ]
    },
    "paper248": {
        "id": "319770330",
        "title": "Prioritized Experience Replay",
        "abstract": "Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.",
        "date": "2016",
        "authers": [
            "Tom Schaul",
            "John Quan",
            "Ioannis Antonoglou",
            "David Silver"
        ],
        "refrences": []
    },
    "paper249": {
        "id": "312990324",
        "title": "Td-gammon a self-Teaching backgammon program achieves master-level play",
        "abstract": "",
        "date": "1994Neural",
        "authers": [
            "G. Tesauro"
        ],
        "refrences": []
    },
    "paper250": {
        "id": "306218037",
        "title": "Learning multiple layers of features from tiny images",
        "abstract": "",
        "date": "2009Handbook",
        "authers": [
            "A. Krizhevsky",
            "G. Hinton"
        ],
        "refrences": []
    },
    "paper251": {
        "id": "304109482",
        "title": "Training products of experts by minimizing contrastive divergence",
        "abstract": "",
        "date": "2000Neural",
        "authers": [
            "G. Hinton"
        ],
        "refrences": []
    },
    "paper252": {
        "id": "320965021",
        "title": "Lip Reading Sentences in the Wild",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Joon Son Chung",
            "Andrew Senior",
            "Oriol Vinyals",
            "Andrew Zisserman"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/315311266_Out_of_Time_Automated_Lip_Sync_in_the_Wild",
            "https://www.researchgate.net/publication/314520875_Lip_Reading_in_the_Wild",
            "https://www.researchgate.net/publication/312320208_An_audio-visual_corpus_for_multimodal_automatic_speech_recognition",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/313195364_Reliable_transition_detection_in_videos_A_survey_and_practitioners_guide",
            "https://www.researchgate.net/publication/311610155_Convolutional_Two-Stream_Network_Fusion_for_Video_Action_Recognition",
            "https://www.researchgate.net/publication/308856024_Deep_multimodal_learning_for_Audio-Visual_Speech_Recognition",
            "https://www.researchgate.net/publication/304415024_Audio-visual_speech_recognition_using_deep_bottleneck_features_and_high-performance_lipreading",
            "https://www.researchgate.net/publication/304372660_Lipreading_with_long_short-term_memory"
        ]
    },
    "paper253": {
        "id": "316450913",
        "title": "Residual Attention Network for Image Classification",
        "abstract": "In this work, we propose \"Residual Attention Network\", a convolutional neural network using attention mechanism which can incorporate with state-of-art feed forward network architecture in an end-to-end training fashion. Our Residual Attention Network is built by stacking Attention Modules which generate attention-aware features. The attention-aware features from different modules change adaptively as layers going deeper. Inside each Attention Module, bottom-up top-down feedforward structure is used to unfold the feedforward and feedback attention process into a single feedforward process. Importantly, we propose attention residual learning to train very deep Residual Attention Networks which can be easily scaled up to hundreds of layers. Extensive analyses are conducted on CIFAR-10 and CIFAR-100 datasets to verify the effectiveness of every module mentioned above. Our Residual Attention Network achieves state-of-the-art object recognition performance on three benchmark datasets including CIFAR-10 (3.90% error), CIFAR-100 (20.45% error) and ImageNet (4.8% single model and single crop, top-5 error). Note that, our method achieves 0.6% top-1 accuracy improvement with 46% trunk depth and 69% forward FLOPs comparing to ResNet-200. The experiment also demonstrates that our network is robust against noisy labels.",
        "date": "2017",
        "authers": [
            "Fei Wang",
            "Mengqing Jiang",
            "Chen Qian",
            "Shuo Yang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308845461_The_application_of_two-level_attention_models_in_deep_convolutional_neural_network_for_fine-grained_image_classification",
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/312727767_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/311610237_Deep_Compositional_Captioning_Describing_Novel_Object_Categories_without_Paired_Training_Data",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/310441005_Aggregated_Residual_Transformations_for_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/308859280_Convolutional_feature_masking_for_joint_object_and_stuff_segmentation",
            "https://www.researchgate.net/publication/308277376_Stacked_Hourglass_Networks_for_Human_Pose_Estimation",
            "https://www.researchgate.net/publication/308277253_Contextual_Priming_and_Feedback_for_Faster_R-CNN"
        ]
    },
    "paper254": {
        "id": "316184205",
        "title": "MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications",
        "abstract": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.",
        "date": "2017",
        "authers": [
            "Andrew G. Howard",
            "Menglong Zhu",
            "Bo Chen",
            "Dmitry Kalenichenko"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/311223153_Speedaccuracy_trade-offs_for_modern_convolutional_object_detectors",
            "https://www.researchgate.net/publication/308457764_Quantized_Neural_Networks_Training_Neural_Networks_with_Low_Precision_Weights_and_Activations",
            "https://www.researchgate.net/publication/320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions",
            "https://www.researchgate.net/publication/319770346_Deep_Fried_Convnets",
            "https://www.researchgate.net/publication/319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks",
            "https://www.researchgate.net/publication/319769906_Training_deep_neural_networks_with_low_precision_multiplications",
            "https://www.researchgate.net/publication/308277794_PlaNet_-_Photo_Geolocation_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/308277088_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks"
        ]
    },
    "paper255": {
        "id": "310462326",
        "title": "PolyNet A Pursuit of Structural Diversity in Very Deep Networks",
        "abstract": "A number of studies have shown that increasing the depth or width of convolutional networks is a rewarding approach to improve the performance of image recognition. In our study, however, we observed difficulties along both directions. On one hand, the pursuit for very deep networks are met with diminishing return and increased training difficulty; on the other hand, widening a network would result in a quadratic growth in both computational cost and memory demand. These difficulties motivate us to explore structural diversity in designing deep networks, a new dimension beyond just depth and width. Specifically, we present a new family of modules, namely the PolyInception, which can be flexibly inserted in isolation or in a composition as replacements of different parts of a network. Choosing PolyInception modules with the guidance of architectural efficiency can improve the expressive power while preserving comparable computational cost. A benchmark on the ILSVRC 2012 validation set demonstrates substantial improvements over the state-of-the-art. Compared to Inception-ResNet-v2, it reduces the top-5 error on single crops from 4.9% to 4.25%, and that on multi-crops from 3.7% to 3.45%.",
        "date": "2016",
        "authers": [
            "Xingcheng Zhang",
            "Zhizhong Li",
            "Chen Change Loy",
            "Dahua Lin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/316970253_Systematic_Evaluation_of_Convolution_Neural_Network_Advances_on_the_ImageNet",
            "https://www.researchgate.net/publication/308320871_Multi-Residual_Networks",
            "https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth",
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770387_Deep_Sparse_Rectifier_Neural_Networks",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770264_Regularization_of_Neural_Networks_using_DropConnect",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/308821532_Convolutional_neural_networks_at_constrained_time_cost"
        ]
    },
    "paper256": {
        "id": "303409658",
        "title": "Deep Roots Improving CNN Efficiency with Hierarchical Filter Groups",
        "abstract": "We propose a new method for training computationally efficient and compact convolutional neural networks (CNNs) using a novel sparse connection structure that resembles a tree root. Our sparse connection structure facilitates a significant reduction in computational cost and number of parameters of state-of-the-art deep CNNs without compromising accuracy. We validate our approach by using it to train more efficient variants of state-of-the-art CNN architectures, evaluated on the CIFAR10 and ILSVRC datasets. Our results show similar or higher accuracy than the baseline architectures with much less compute, as measured by CPU and GPU timings. For example, for ResNet 50, our model has 40% fewer parameters, 45% fewer floating point operations, and is 31% (12%) faster on a CPU (GPU). For the deeper ResNet 200 our model has 25% fewer floating point operations and 44% fewer parameters, while maintaining state-of-the-art accuracy. For GoogLeNet, our model has 7% fewer parameters and is 21% (16%) faster on a CPU (GPU).",
        "date": "2017",
        "authers": [
            "Yani Ioannou",
            "Duncan P. Robertson",
            "Roberto Cipolla",
            "Antonio Criminisi"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308833537_Deformable_part_models_are_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770418_Maxout_Networks",
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/319770343_Predicting_Parameters_in_Deep_Learning",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770137_Compression_of_Deep_Convolutional_Neural_Networks_for_Fast_and_Low_Power_Mobile_Applications",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images"
        ]
    },
    "paper257": {
        "id": "263891809",
        "title": "Deep Networks with Internal Selective Attention through Feedback Connections",
        "abstract": "Traditional convolutional neural networks (CNN) are stationary and\nfeedforward. They neither change their parameters during evaluation nor use\nfeedback from higher to lower layers. Real brains, however, do. So does our\nDeep Attention Selective Network (dasNet) architecture. DasNets feedback\nstructure can dynamically alter its convolutional filter sensitivities during\nclassification. It harnesses the power of sequential processing to improve\nclassification performance, by allowing the network to iteratively focus its\ninternal attention on some of its convolutional filters. Feedback is trained\nthrough direct policy search in a huge million-dimensional parameter space,\nthrough scalable natural evolution strategies (SNES). On the CIFAR-10 and\nCIFAR-100 datasets, dasNet outperforms the previous state-of-the-art model.",
        "date": "2014Advances",
        "authers": [
            "Marijn Stollenga",
            "Jonathan Masci",
            "Faustino Gomez",
            "Juergen Schmidhuber"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/286966779_Compete_to_compute",
            "https://www.researchgate.net/publication/319770626_Multi-column_Deep_Neural_Networks_for_Image_Classification",
            "https://www.researchgate.net/publication/319770264_Regularization_of_Neural_Networks_using_DropConnect",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/313706874_Adaptation_in_natural_and_artificial_systems",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/291777069_Distributed_Hierarchical_Processing_in_the_Primate_Cerebral_Cortex",
            "https://www.researchgate.net/publication/291735245_Regularization_of_neural_networks_using_dropconnect",
            "https://www.researchgate.net/publication/287124401_Hierarchies_of_Cortical_Areas"
        ]
    },
    "paper258": {
        "id": "319770160",
        "title": "Show and Tell A Neural Image Caption Generator",
        "abstract": "Automatically describing the content of an image is a fundamental problem in\nartificial intelligence that connects computer vision and natural language\nprocessing. In this paper, we present a generative model based on a deep\nrecurrent architecture that combines recent advances in computer vision and\nmachine translation and that can be used to generate natural sentences\ndescribing an image. The model is trained to maximize the likelihood of the\ntarget description sentence given the training image. Experiments on several\ndatasets show the accuracy of the model and the fluency of the language it\nlearns solely from image descriptions. Our model is often quite accurate, which\nwe verify both qualitatively and quantitatively. For instance, while the\ncurrent state-of-the-art BLEU score (the higher the better) on the Pascal\ndataset is 25, our approach yields 59, to be compared to human performance\naround 69. We also show BLEU score improvements on Flickr30k, from 55 to 66,\nand on SBU, from 19 to 27.",
        "date": "2014",
        "authers": [
            "Oriol Vinyals",
            "Alexander Toshev",
            "Samy Bengio",
            "Dumitru Erhan"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/329977566_T_ree_T_alk_Composition_and_Compression_of_Trees_for_Image_Descriptions",
            "https://www.researchgate.net/publication/329975395_Grounded_Compositional_Semantics_for_Finding_and_Describing_Images_with_Sentences",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/312714920_Improving_Image-Sentence_Embeddings_Using_Large_Weakly_Annotated_Photo_Collections",
            "https://www.researchgate.net/publication/303721259_From_image_descriptions_to_visual_denotations_New_similarity_metrics_for_semantic_inference_over_event_descriptions",
            "https://www.researchgate.net/publication/290345348_Image_description_using_visual_dependency_representations",
            "https://www.researchgate.net/publication/268155634_Unifying_Visual-Semantic_Embeddings_with_Multimodal_Neural_Language_Models"
        ]
    },
    "paper259": {
        "id": "318337293",
        "title": "Primal-Dual Group Convolutions for Deep Neural Networks",
        "abstract": "In this paper, we present a simple and modularized neural network architecture, named primal-dual group convolutional neural networks (PDGCNets). The main point lies in a novel building block, a pair of two successive group convolutions: primal group convolution and dual group convolution. The two group convolutions are complementary: (i) the convolution on each primal partition in primal group convolution is a spatial convolution, while on each dual partition in dual group convolution, the convolution is a point-wise convolution; (ii) the channels in the same dual partition come from different primal partitions. We discuss one representative advantage: Wider than a regular convolution with the number of parameters and the computation complexity preserved. We also show that regular convolutions, group convolution with summation fusion (as used in ResNeXt), and the Xception block are special cases of primal-dual group convolutions. Empirical results over standard benchmarks, CIFAR-$10$, CIFAR-$100$, SVHN and ImageNet demonstrate that our networks are more efficient in using parameters and computation complexity with similar or higher accuracy.",
        "date": "2017",
        "authers": [
            "Ting Zhang",
            "Guo-Jun Qi",
            "Bin Xiao",
            "Jingdong Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308320871_Multi-Residual_Networks",
            "https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth",
            "https://www.researchgate.net/publication/320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions",
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/313879627_The_Power_of_Sparsity_in_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/312727767_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/310769931_On_the_Connection_of_Deep_Fusion_to_Ensembling",
            "https://www.researchgate.net/publication/310441005_Aggregated_Residual_Transformations_for_Deep_Neural_Networks"
        ]
    },
    "paper260": {
        "id": "313645102",
        "title": "Incremental Network Quantization Towards Lossless CNNs with Low-Precision Weights",
        "abstract": "This paper presents incremental network quantization (INQ), a novel method, targeting to efficiently convert any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version whose weights are constrained to be either powers of two or zero. Unlike existing methods which are struggled in noticeable accuracy loss, our INQ has the potential to resolve this issue, as benefiting from two innovations. On one hand, we introduce three interdependent operations, namely weight partition, group-wise quantization and re-training. A well-proven measure is employed to divide the weights in each layer of a pre-trained CNN model into two disjoint groups. The weights in the first group are responsible to form a low-precision base, thus they are quantized by a variable-length encoding method. The weights in the other group are responsible to compensate for the accuracy loss from the quantization, thus they are the ones to be re-trained. On the other hand, these three operations are repeated on the latest re-trained group in an iterative manner until all the weights are converted into low-precision ones, acting as an incremental network quantization and accuracy enhancement procedure. Extensive experiments on the ImageNet classification task using almost all known deep CNN architectures including AlexNet, VGG-16, GoogleNet and ResNets well testify the efficacy of the proposed method. Specifically, at 5-bit quantization, our models have improved accuracy than the 32-bit floating-point references. Taking ResNet-18 as an example, we further show that our quantized models with 4-bit, 3-bit and 2-bit ternary weights have improved or very similar accuracy against its 32-bit floating-point baseline. Besides, impressive results with the combination of network pruning and INQ are also reported. The code will be made publicly available.",
        "date": "2017",
        "authers": [
            "Aojun Zhou",
            "Anbang Yao",
            "Guo Yiwen",
            "Lin Xu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/306227124_Dynamic_Network_Surgery_for_Efficient_DNNs",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/304163898_DoReFa-Net_Training_Low_Bitwidth_Convolutional_Neural_Networks_with_Low_Bitwidth_Gradients",
            "https://www.researchgate.net/publication/303270485_Ternary_Weight_Networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/319770132_Dynamic_Network_Surgery_for_Efficient_DNNs",
            "https://www.researchgate.net/publication/319770111_Improving_the_speed_of_neural_networks_on_CPUs",
            "https://www.researchgate.net/publication/308277088_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/301921832_Fully_convolutional_networks_for_semantic_segmentation",
            "https://www.researchgate.net/publication/301874967_Inception-v4_Inception-ResNet_and_the_Impact_of_Residual_Connections_on_Learning"
        ]
    },
    "paper261": {
        "id": "301878495",
        "title": "SqueezeNet AlexNet-level accuracy with 50x fewer parameters and 05MB model size",
        "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet",
        "date": "2016",
        "authers": [
            "Forrest N. Iandola",
            "Song Han",
            "Matthew W. Moskewicz",
            "Khalid Ashraf"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/316970253_Systematic_Evaluation_of_Convolution_Neural_Network_Advances_on_the_ImageNet",
            "https://www.researchgate.net/publication/316867991_Shallow_Networks_for_High-accuracy_Road_Object-detection",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding",
            "https://www.researchgate.net/publication/319770323_EIE_Efficient_Inference_Engine_on_Compressed_Deep_Neural_Network",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770219_3D_Object_Proposals_for_Accurate_Object_Class_Detection",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks"
        ]
    },
    "paper262": {
        "id": "301839500",
        "title": "TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "date": "2016",
        "authers": [
            "Mart\u00edn Abadi",
            "Ashish Agarwal",
            "Paul Barham",
            "Eugene Brevdo"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/319770465_Sequence_to_Sequence_Learning_with_Neural_Networks",
            "https://www.researchgate.net/publication/319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space",
            "https://www.researchgate.net/publication/306209959_Project_adam_Building_an_efficient_and_scalable_deep_learning_training_system",
            "https://www.researchgate.net/publication/304533937_Learning_representations_by_back_propagating_errors_Cogn",
            "https://www.researchgate.net/publication/303256841_Theano_a_CPU_and_GPU_math_expression_compiler",
            "https://www.researchgate.net/publication/291286882_DeViSE_A_deep_visual-semantic_embedding_model",
            "https://www.researchgate.net/publication/286594438_Large-Scale_Video_Classification_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/283780337_Pedestrian_detection_with_a_Large-Field-Of-View_deep_network",
            "https://www.researchgate.net/publication/281952292_Large-scale_cluster_management_at_Google_with_Borg"
        ]
    },
    "paper263": {
        "id": "287853408",
        "title": "Quantized Convolutional Neural Networks for Mobile Devices",
        "abstract": "Recently, convolutional neural networks (CNN) have demonstrated impressive\nperformance in various computer vision tasks. However, high performance\nhardware is typically indispensable for the application of CNN models due to\nthe high computation complexity, which prohibits their further extensions. In\nthis paper, we propose an efficient framework, namely Quantized CNN, to\nsimultaneously speed-up the computation and reduce the storage and memory\noverhead of CNN models. Both filter kernels in convolutional layers and\nweighting matrices in fully-connected layers are quantized, aiming at\nminimizing the estimation error of each layer's response. Extensive experiments\non the ILSVRC-12 benchmark demonstrate $4 \\sim 6 \\times$ speed-up and $15 \\sim\n20 \\times$ compression with merely one percentage loss of classification\naccuracy. With our quantized CNN model, even mobile devices can accurately\nclassify images within one second.",
        "date": "2015",
        "authers": [
            "Jiaxiang Wu",
            "Cong Leng",
            "Yuhang Wang",
            "Qingzhu Lin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770109_Fast_ConvNets_Using_Group-wise_Brain_Damage",
            "https://www.researchgate.net/publication/319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks",
            "https://www.researchgate.net/publication/309076254_Gradientbased_learning_applied_to_document_recognition",
            "https://www.researchgate.net/publication/308867995_Efficient_and_accurate_approximations_of_nonlinear_convolutional_networks",
            "https://www.researchgate.net/publication/308854323_Online_sketching_hashing",
            "https://www.researchgate.net/publication/308299971_Age_and_gender_classification_using_convolutional_neural_networks"
        ]
    },
    "paper264": {
        "id": "282005595",
        "title": "Expectation Backpropagation Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights",
        "abstract": "Multilayer Neural Networks (MNNs) are commonly trained using gradient descent-based methods, such as BackPropagation (BP). Inference in probabilistic graphical models is often done using variational Bayes methods, such as Expectation Propagation (EP). We show how an EP based approach can also be used to train deterministic MNNs. Specifically, we approximate the posterior of the weights given the data using a \" mean-field \" factorized distribution, in an online setting. Using online EP and the central limit theorem we find an analytical approximation to the Bayes update of this posterior, as well as the resulting Bayes estimates of the weights and outputs. Despite a different origin, the resulting algorithm, Expectation BackPropagation (EBP), is very similar to BP in form and efficiency. However, it has several additional advantages: (1) Training is parameter-free, given initial conditions (prior) and the MNN architecture. This is useful for large-scale problems, where parameter tuning is a major challenge. (2) The weights can be restricted to have discrete values. This is especially useful for implementing trained MNNs in precision limited hardware chips, thus improving their speed and energy efficiency by several orders of magnitude. We test the EBP algorithm numerically in eight binary text classification tasks. In all tasks, EBP outperforms: (1) standard BP with the optimal constant learning rate (2) previously reported state of the art. Interestingly, EBP-trained MNNs with binary weights usually perform better than MNNs with continuous (real) weights-if we average the MNN output using the inferred posterior.",
        "date": "2014Advances",
        "authers": [
            "Daniel Soudry",
            "Itay Hubara",
            "Ron Meir"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting",
            "https://www.researchgate.net/publication/280940018_Pattern_Recognition_and_Machine_Learning",
            "https://www.researchgate.net/publication/272825857_UCI_Machine_Learning_Repository",
            "https://www.researchgate.net/publication/268853624_Training_feed_forward_nets_with_binary_weights_via_a_modified_CHIR_algorithm",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/267706055_Practical_Variational_Inference_for_Neural_Networks",
            "https://www.researchgate.net/publication/260637318_Deep_Neural_Networks_for_Acoustic_Modeling_in_Speech_Recognition_The_Shared_Views_of_Four_Research_Groups",
            "https://www.researchgate.net/publication/254062444_11_TMACSmW_Fine-Grained_Stochastic_Resonant_Charge-Recycling_Array_Processor",
            "https://www.researchgate.net/publication/248512106_Pattern_Recognition_and_Machine_Learning_Errata"
        ]
    },
    "paper265": {
        "id": "325673550",
        "title": "Efficient Architecture Search by Network Transformation",
        "abstract": "Techniques for automatically designing deep neural network architectures such as reinforcement learning based approaches have recently shown promising results. However, their success is based on vast computational resources (e.g. hundreds of GPUs), making them difficult to be widely used. A noticeable limitation is that they still design and train each network from scratch during the exploration of the architecture space, which is highly inefficient. In this paper, we propose a new framework toward efficient architecture search by exploring the architecture space based on the current network and reusing its weights. We employ a reinforcement learning agent as the meta-controller, whose action is to grow the network depth or layer width with function-preserving transformations. As such, the previously validated networks can be reused for further exploration, thus saves a large amount of computational cost. We apply our method to explore the architecture space of the plain convolutional neural networks (no skip-connections, branching etc.) on image benchmark datasets (CIFAR-10, SVHN) with restricted computational resources (5 GPUs). Our method can design highly competitive networks that outperform existing networks using the same design scheme. On CIFAR-10, our model without skip-connections achieves 4.23% test error rate, exceeding a vast majority of modern architectures and approaching DenseNet. Furthermore, by applying our method to explore the DenseNet architecture space, we are able to achieve more accurate networks with fewer parameters.",
        "date": "2018",
        "authers": [
            "Han Cai",
            "Tianyao Chen",
            "Weinan Zhang",
            "Yong Yu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/318813751_Real-Time_Bidding_by_Reinforcement_Learning_in_Display_Advertising",
            "https://www.researchgate.net/publication/309738510_Designing_Neural_Network_Architectures_using_Reinforcement_Learning",
            "https://www.researchgate.net/publication/319770422_Net2Net_Accelerating_Learning_via_Knowledge_Transfer",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319769991_Trust_Region_Policy_Optimization",
            "https://www.researchgate.net/publication/314237511_Large-Scale_Evolution_of_Image_Classifiers",
            "https://www.researchgate.net/publication/309738632_Neural_Architecture_Search_with_Reinforcement_Learning",
            "https://www.researchgate.net/publication/308277201_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images"
        ]
    },
    "paper266": {
        "id": "321902574",
        "title": "Deep Neuroevolution Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning",
        "abstract": "Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of techniques that have been developed in the neuroevolution community to improve performance on RL problems. To demonstrate the latter, we show that combining DNNs with novelty search, which was designed to encourage exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA parallelizes better than ES, A3C, and DQN, and enables a state-of-the-art compact encoding technique that can represent million-parameter DNNs in thousands of bytes.",
        "date": "2017",
        "authers": [
            "Felipe Petroski Such",
            "Vashisht Madhavan",
            "Edoardo Conti",
            "Joel Lehman"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/321902735_Improving_Exploration_in_Evolution_Strategies_for_Deep_Reinforcement_Learning_via_a_Population_of_Novelty-Seeking_Agents",
            "https://www.researchgate.net/publication/321902224_ES_Is_More_Than_Just_a_Traditional_Finite-Difference_Approximator",
            "https://www.researchgate.net/publication/317425537_Self-Normalizing_Neural_Networks",
            "https://www.researchgate.net/publication/320798539_Hierarchical_Representations_for_Efficient_Architecture_Search",
            "https://www.researchgate.net/publication/320280165_Rainbow_Combining_Improvements_in_Deep_Reinforcement_Learning",
            "https://www.researchgate.net/publication/319769991_Trust_Region_Policy_Optimization",
            "https://www.researchgate.net/publication/319164082_Scalable_trust-region_method_for_deep_reinforcement_learning_using_Kronecker-factored_approximation",
            "https://www.researchgate.net/publication/318652786_A_Distributional_Perspective_on_Reinforcement_Learning",
            "https://www.researchgate.net/publication/318584439_Proximal_Policy_Optimization_Algorithms",
            "https://www.researchgate.net/publication/314943017_Evolution_Strategies_as_a_Scalable_Alternative_to_Reinforcement_Learning"
        ]
    },
    "paper267": {
        "id": "318255371",
        "title": "Dual Path Networks",
        "abstract": "In this work, we present a simple, highly efficient and modularized Dual Path Network (DPN) for image classification which presents a new topology of connection paths internally. By revealing the equivalence of the state-of-the-art Residual Network (ResNet) and Densely Convolutional Network (DenseNet) within the HORNN framework, we find that ResNet enables feature re-usage while DenseNet enables new features exploration which are both important for learning good representations. To enjoy the benefits from both path topologies, our proposed Dual Path Network shares common features while maintaining the flexibility to explore new features through dual path architectures. Extensive experiments on three benchmark datasets, ImagNet-1k, Places365 and PASCAL VOC, clearly demonstrate superior performance of the proposed DPN over state-of-the-arts. In particular, on the ImagNet-1k dataset, a shallow DPN surpasses the best ResNeXt-101(64x4d) with 26% smaller model size, 25% less computational cost and 8% lower memory consumption, and a deeper DPN (DPN-131) further pushes the state-of-the-art single model performance with more than 3 times faster training speed. Experiments on the Places365 large-scale scene dataset, PASCAL VOC detection dataset, and PASCAL VOC segmentation dataset also demonstrate its consistently better performance than DenseNet, ResNet and the latest ResNeXt model over various applications.",
        "date": "2017",
        "authers": [
            "Yunpeng Chen",
            "Jianan Li",
            "Huaxin Xiao",
            "Xiaojie Jin"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/318652675_Memory-Efficient_Implementation_of_DenseNets",
            "https://www.researchgate.net/publication/310462326_PolyNet_A_Pursuit_of_Structural_Diversity_in_Very_Deep_Networks",
            "https://www.researchgate.net/publication/308964584_Places_An_Image_Database_for_Deep_Scene_Understanding",
            "https://www.researchgate.net/publication/306885833_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/314283062_Sharing_Residual_Units_Through_Collective_Tensor_Factorization_in_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/311610731_Accurate_Image_Super-Resolution_Using_Very_Deep_Convolutional_Networks",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/310441005_Aggregated_Residual_Transformations_for_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/308277376_Stacked_Hourglass_Networks_for_Human_Pose_Estimation",
            "https://www.researchgate.net/publication/308277201_Identity_Mappings_in_Deep_Residual_Networks"
        ]
    },
    "paper268": {
        "id": "316598820",
        "title": "DeepArchitect Automatically Designing and Training Deep Architectures",
        "abstract": "In deep learning, performance is strongly affected by the choice of architecture and hyperparameters. While there has been extensive work on automatic hyperparameter optimization for simple spaces, complex spaces such as the space of deep architectures remain largely unexplored. As a result, the choice of architecture is done manually by the human expert through a slow trial and error process guided mainly by intuition. In this paper we describe a framework for automatically designing and training deep models. We propose an extensible and modular language that allows the human expert to compactly represent complex search spaces over architectures and their hyperparameters. The resulting search spaces are tree-structured and therefore easy to traverse. Models can be automatically compiled to computational graphs once values for all hyperparameters have been chosen. We can leverage the structure of the search space to introduce different model search algorithms, such as random search, Monte Carlo tree search (MCTS), and sequential model-based optimization (SMBO). We present experiments comparing the different algorithms on CIFAR-10 and show that MCTS and SMBO outperform random search. In addition, these experiments show that our framework can be used effectively for model discovery, as it is possible to describe expressive search spaces and discover competitive models without much effort from the human expert. Code for our framework and experiments has been made publicly available.",
        "date": "2017",
        "authers": [
            "Renato Negrinho",
            "Geoff Gordon"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/309738510_Designing_Neural_Network_Architectures_using_Reinforcement_Learning",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/301839500_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/314237511_Large-Scale_Evolution_of_Image_Classifiers",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/308813785_Deep_visual-semantic_alignments_for_generating_image_descriptions",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/304781977_Algorithms_for_hyper-parameter_optimization"
        ]
    },
    "paper269": {
        "id": "313096253",
        "title": "PathNet Evolution Channels Gradient Descent in Super Neural Networks",
        "abstract": "For artificial general intelligence (AGI) it would be efficient if multiple users trained the same giant neural network, permitting parameter reuse, without catastrophic forgetting. PathNet is a first step in this direction. It is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re-use for new tasks. Agents are pathways (views) through the network which determine the subset of parameters that are used and updated by the forwards and backwards passes of the backpropogation algorithm. During learning, a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation. Pathway fitness is the performance of that pathway measured according to a cost function. We demonstrate successful transfer learning; fixing the parameters along a path learned on task A and re-evolving a new population of paths for task B, allows task B to be learned faster than it could be learned from scratch or after fine-tuning. Paths evolved on task B re-use parts of the optimal path evolved on task A. Positive transfer was demonstrated for binary MNIST, CIFAR, and SVHN supervised learning classification tasks, and a set of Atari and Labyrinth reinforcement learning tasks, suggesting PathNets have general applicability for neural network training. Finally, PathNet also significantly improves the robustness to hyperparameter choices of a parallel asynchronous reinforcement learning algorithm (A3C).",
        "date": "2017",
        "authers": [
            "Chrisantha Fernando",
            "Dylan Banarse",
            "Charles Blundell",
            "Yori Zwols"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/310440792_Reinforcement_Learning_with_Unsupervised_Auxiliary_Tasks",
            "https://www.researchgate.net/publication/303859203_Convolutional_Neural_Fabrics",
            "https://www.researchgate.net/publication/301847678_Asynchronous_Methods_for_Deep_Reinforcement_Learning",
            "https://www.researchgate.net/publication/284219622_Net2Net_Accelerating_Learning_via_Knowledge_Transfer",
            "https://www.researchgate.net/publication/312619873_Outrageously_Large_Neural_Networks_The_Sparsely-Gated_Mixture-of-Experts_Layer",
            "https://www.researchgate.net/publication/303734483_Selectionist_and_evolutionary_approaches_to_brain_function_a_critical_appraisal",
            "https://www.researchgate.net/publication/303409493_Swapout_Learning_an_ensemble_of_deep_architectures",
            "https://www.researchgate.net/publication/301846299_Deep_Exploration_via_Bootstrapped_DQN",
            "https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting",
            "https://www.researchgate.net/publication/273387909_Distilling_the_Knowledge_in_a_Neural_Network"
        ]
    },
    "paper270": {
        "id": "309738510",
        "title": "Designing Neural Network Architectures using Reinforcement Learning",
        "abstract": "At present, designing convolutional neural network (CNN) architectures requires both human expertise and labor. New architectures are handcrafted by careful experimentation or modified from a handful of existing networks. We propose a meta-modelling approach based on reinforcement learning to automatically generate high-performing CNN architectures for a given learning task. The learning agent is trained to sequentially choose CNN layers using Q-learning with an $\\epsilon$-greedy exploration strategy and experience replay. The agent explores a large but finite space of possible architectures and iteratively discovers designs with improved performance on the learning task. On image classification benchmarks, the agent-designed networks (consisting of only standard convolution, pooling, and fully-connected layers) beat existing networks designed with the same layer types and are competitive against the state-of-the-art methods that use more complex layer types. We also outperform existing network design meta-modelling approaches on image classification.",
        "date": "2016",
        "authers": [
            "Bowen Baker",
            "Otkrist Gupta",
            "Nikhil Naik",
            "Ramesh Raskar"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319769813_Fast_and_Accurate_Deep_Network_Learning_by_Exponential_Linear_Units_ELUs",
            "https://www.researchgate.net/publication/292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search",
            "https://www.researchgate.net/publication/277411157_Deep_Learning",
            "https://www.researchgate.net/publication/308846031_Recurrent_convolutional_neural_network_for_object_recognition",
            "https://www.researchgate.net/publication/304781977_Algorithms_for_hyper-parameter_optimization",
            "https://www.researchgate.net/publication/287175820_Multi-task_Bayesian_optimization",
            "https://www.researchgate.net/publication/286512696_Deep_Residual_Learning_for_Image_Recognition",
            "https://www.researchgate.net/publication/277290316_Convex_Optimization_Algorithms_Contents",
            "https://www.researchgate.net/publication/274572264_End-to-End_Training_of_Deep_Visuomotor_Policies",
            "https://www.researchgate.net/publication/272837232_Human-level_control_through_deep_reinforcement_learning"
        ]
    },
    "paper271": {
        "id": "308981007",
        "title": "Deep Pyramidal Residual Networks",
        "abstract": "Deep convolutional neural networks (DCNNs) have shown remarkable performance in image classification tasks in recent years. Generally, deep neural network architectures are stacks consisting of a large number of convolution layers, and they perform downsampling along the spatial dimension via pooling to reduce memory usage. At the same time, the feature map dimension (i.e., the number of channels) is sharply increased at downsampling locations, which is essential to ensure effective performance because it increases the capability of high-level attributes. Moreover, this also applies to residual networks and is very closely related to their performance. In this research, instead of using downsampling to achieve a sharp increase at each residual unit, we gradually increase the feature map dimension at all the units to involve as many locations as possible. This is discussed in depth together with our new insights as it has proven to be an effective design to improve the generalization ability. Furthermore, we propose a novel residual unit capable of further improving the classification accuracy with our new network architecture. Experiments on benchmark CIFAR datasets have shown that our network architecture has a superior generalization ability compared to the original residual networks. Code is available at https://github.com/jhkim89/PyramidNet",
        "date": "2016",
        "authers": [
            "Dongyoon Han",
            "Jiwhan Kim",
            "Junmo Kim"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770191_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/312256274_Weighted_residuals_for_very_deep_networks",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition"
        ]
    },
    "paper272": {
        "id": "306885833",
        "title": "Densely Connected Convolutional Networks",
        "abstract": "Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and models are available at https://github.com/liuzhuang13/DenseNet.",
        "date": "2017",
        "authers": [
            "Gao Huang",
            "Zhuang Liu",
            "Laurens van der Maaten",
            "Kilian Weinberger"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770414_Identity_Mappings_in_Deep_Residual_Networks",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770387_Deep_Sparse_Rectifier_Neural_Networks",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770216_Deconstructing_the_Ladder_Network_Architecture",
            "https://www.researchgate.net/publication/319770191_FitNets_Hints_for_Thin_Deep_Nets",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/312727767_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/311609041_Deep_Residual_Learning_for_Image_Recognition"
        ]
    },
    "paper273": {
        "id": "304857984",
        "title": "AdaNet Adaptive Structural Learning of Artificial Neural Networks",
        "abstract": "We present a new theoretical framework for analyzing and learning artificial neural networks. Our approach simultaneously and adaptively learns both the structure of the network as well as its weights. The methodology is based upon and accom- panied by strong data-dependent theoretical learning guarantees, so that the final network architecture provably adapts to the complexity of any given problem.",
        "date": "2016",
        "authers": [
            "Corinna Cortes",
            "Xavi Gonzalvo",
            "Vitaly Kuznetsov",
            "Mehryar Mohri"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/284219370_Why_are_deep_nets_reversible_A_simple_theory_with_implications_for_training",
            "https://www.researchgate.net/publication/282906751_ell_1-regularized_Neural_Networks_are_Improperly_Learnable_in_Polynomial_Time",
            "https://www.researchgate.net/publication/281895600_On_the_Expressive_Power_of_Deep_Learning_A_Tensor_Analysis",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770166_Provable_Bounds_for_Learning_Some_Deep_Representations",
            "https://www.researchgate.net/publication/313501588_Accelerating_stochastic_gradient_descent_using_predictive_variance_reduction",
            "https://www.researchgate.net/publication/304781977_Algorithms_for_hyper-parameter_optimization",
            "https://www.researchgate.net/publication/287250773_The_Power_of_Depth_for_Feedforward_Neural_Networks",
            "https://www.researchgate.net/publication/281487015_Train_faster_generalize_better_Stability_of_stochastic_gradient_descent",
            "https://www.researchgate.net/publication/279458887_Asynchronous_Parallel_Stochastic_Gradient_for_Nonconvex_Optimization"
        ]
    },
    "paper274": {
        "id": "319769813",
        "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units ELUs",
        "abstract": "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network.",
        "date": "2016",
        "authers": [
            "Djork-Arn\u00e9 Clevert",
            "Thomas Unterthiner",
            "Sepp Hochreiter"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/273157730_Toxicity_Prediction_using_Deep_Learning",
            "https://www.researchgate.net/publication/272752025_Rectified_Factor_Networks",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/306221946_Centering_neural_network_gradient_factors",
            "https://www.researchgate.net/publication/280329704_Training_Very_Deep_Networks",
            "https://www.researchgate.net/publication/276461438_Riemannian_metrics_for_neural_networks_I_feedforward_networks",
            "https://www.researchgate.net/publication/275974753_Empirical_Evaluation_of_Rectified_Activations_in_Convolutional_Network",
            "https://www.researchgate.net/publication/272194743_Batch_Normalization_Accelerating_Deep_Network_Training_by_Reducing_Internal_Covariate_Shift",
            "https://www.researchgate.net/publication/269935358_Striving_for_Simplicity_The_All_Convolutional_Net"
        ]
    },
    "paper275": {
        "id": "284579051",
        "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units ELUs",
        "abstract": "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in\ndeep neural networks and leads to higher classification accuracies. Like\nrectified linear units (ReLUs), leaky ReLUs (LReLUs) and parameterized ReLUs\n(PReLUs), ELUs also avoid a vanishing gradient via the identity for positive\nvalues. However, ELUs have improved learning characteristics compared to the\nunits with other activation functions. In contrast to ReLUs, ELUs have negative\nvalues which allows them to push mean unit activations closer to zero. Zero\nmeans speed up learning because they bring the gradient closer to the unit\nnatural gradient. We show that the unit natural gradient differs from the\nnormal gradient by a bias shift term, which is proportional to the mean\nactivation of incoming units. Like batch normalization, ELUs push the mean\ntowards zero, but with a significantly smaller computational footprint. While\nother activation functions like LReLUs and PReLUs also have negative values,\nthey do not ensure a noise-robust deactivation state. ELUs saturate to a\nnegative value with smaller inputs and thereby decrease the propagated\nvariation and information. Therefore, ELUs code the degree of presence of\nparticular phenomena in the input, while they do not quantitatively model the\ndegree of their absence. Consequently, dependencies between ELUs are much\neasier to model and distinct concepts are less likely to interfere. We found\nthat ELUs lead not only to faster learning, but also to better generalization\nperformance once networks have many layers (>= 5). Using ELUs, we obtained the\nbest published single-crop result on CIFAR-100 and CIFAR-10. On ImageNet, ELU\nnetworks considerably speed up learning compared to a ReLU network with similar\nclassification performance, obtaining less than 10% classification error for a\nsingle crop, single model network.",
        "date": "2015",
        "authers": [
            "Djork-Arn\u00e9 Clevert",
            "Thomas Unterthiner",
            "Sepp Hochreiter"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/281118645_Deep_Learning_as_an_Opportunity_in_Virtual_Screening",
            "https://www.researchgate.net/publication/277282943_Recurrent_Neural_Net_Learning_and_Vanishing_Gradient",
            "https://www.researchgate.net/publication/273157730_Toxicity_Prediction_using_Deep_Learning",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/306221946_Centering_neural_network_gradient_factors",
            "https://www.researchgate.net/publication/289786324_Centering_Neural_Network_Gradient_Factors",
            "https://www.researchgate.net/publication/280329704_Training_Very_Deep_Networks",
            "https://www.researchgate.net/publication/276461438_Riemannian_metrics_for_neural_networks_I_feedforward_networks",
            "https://www.researchgate.net/publication/275974753_Empirical_Evaluation_of_Rectified_Activations_in_Convolutional_Network"
        ]
    },
    "paper276": {
        "id": "269722508",
        "title": "Flattened Convolutional Neural Networks for Feedforward Acceleration",
        "abstract": "We present flattened convolutional neural networks that are designed for fast\nfeedforward execution. The redundancy of the parameters, especially weights of\nthe convolutional filters in convolutional neural networks has been extensively\nstudied and different heuristics have been proposed to construct a low rank\nbasis of the filters after training. In this work, we train flattened networks\nthat consist of consecutive sequence of one-dimensional filters across all\ndirections in 3D space to obtain comparable performance as conventional\nconvolutional networks. We tested flattened model on different datasets and\nfound that the flattened layer can effectively substitute for the 3D filters\nwithout loss of accuracy. The flattened convolution pipelines provide around\ntwo times speed-up during feedforward pass compared to the baseline model due\nto the significant reduction of learning parameters. Furthermore, the proposed\nmethod does not require efforts in manual tuning or post processing once the\nmodel is trained.",
        "date": "2014",
        "authers": [
            "Jonghoon Jin",
            "Aysegul Dundar",
            "Eugenio Culurciello"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/269935399_Speeding-up_Convolutional_Neural_Networks_Using_Fine-tuned_CP-Decomposition",
            "https://www.researchgate.net/publication/319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning",
            "https://www.researchgate.net/publication/319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation",
            "https://www.researchgate.net/publication/319770342_Compressing_Deep_Convolutional_Networks_using_Vector_Quantization",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770111_Improving_the_speed_of_neural_networks_on_CPUs",
            "https://www.researchgate.net/publication/306218037_Learning_multiple_layers_of_features_from_tiny_images",
            "https://www.researchgate.net/publication/286569315_Discriminative_transfer_learning_with_tree-based_priors",
            "https://www.researchgate.net/publication/268624415_Kernel_Analysis_of_Deep_Networks"
        ]
    },
    "paper277": {
        "id": "260642043",
        "title": "Rigid-Motion Scattering for Texture Classification",
        "abstract": "A rigid-motion scattering computes adaptive invariants along translations and\nrotations, with a deep convolutional network. Convolutions are calculated on\nthe rigid-motion group, with wavelets defined on the translation and rotation\nvariables. It preserves joint rotation and translation information, while\nproviding global invariants at any desired scale. Texture classification is\nstudied, through the characterization of stationary processes from a single\nrealization. State-of-the-art results are obtained on multiple texture data\nbases, with important rotation and scaling variabilities.",
        "date": "2014",
        "authers": [
            "Laurent SIfre",
            "St\u00e9phane Georges Mallat"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/279843675_The_computational_magic_of_the_ventral_stream_sketch_of_a_theory_and_why_some_deep_architectures_work",
            "https://www.researchgate.net/publication/268406254_Combined_scattering_for_rotation_invariant_texture",
            "https://www.researchgate.net/publication/266225209_Large_Scale_Distributed_Deep_Networks",
            "https://www.researchgate.net/publication/259399834_Generic_Deep_Networks_with_Wavelet_Scattering",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/316588757_A_Wavelet_Tour_of_Signal_Processing",
            "https://www.researchgate.net/publication/313527089_Distinctive_image_features_from_scale-invariant_key_points",
            "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/261226002_Rotation_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination"
        ]
    },
    "paper278": {
        "id": "236736831",
        "title": "Acceleration of Stochastic Approximation by Averaging",
        "abstract": "A new recursive algorithm of stochastic approximation type with the averaging of trajectories is investigated. Convergence with probability one is proved for a variety of classical optimization and identification problems. It is also demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence.",
        "date": "1992SIAM",
        "authers": [
            "Boris T. Polyak",
            "Anatoli Juditsky"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/284151356_Comparison_of_convergence_rate_of_one-step_and_multistep_optimization_algorithms_in_the_presence_of_noise",
            "https://www.researchgate.net/publication/267439735_Adaptive_estimation_algorithms_Convergence_optimality_stability",
            "https://www.researchgate.net/publication/279958061_Applied_Mathematical_Sciences",
            "https://www.researchgate.net/publication/268996515_Multidimensional_asymptotically_optimal_procedure_of_stochastic_approximation",
            "https://www.researchgate.net/publication/268682619_An_adaptive_Robbins-Monro_procedure",
            "https://www.researchgate.net/publication/268645196_Adaptation_and_Learning_in_Automatic_Systems",
            "https://www.researchgate.net/publication/267129803_Estimation_of_parameters_of_linear_and_nonlinear_stochastic_systems_by_the_method_of_averaged_residuals",
            "https://www.researchgate.net/publication/266978677_Convergence_analysis_of_smoothed_stochastic_gradient-type_algorithm",
            "https://www.researchgate.net/publication/266523004_Herbert_Robbins_Selected_Papers",
            "https://www.researchgate.net/publication/266066589_Convergence_and_optimality_of_realizable_adaptation_algorithms_the_information_approach"
        ]
    },
    "paper279": {
        "id": "230867026",
        "title": "Simplifying ConvNets for Fast Learning",
        "abstract": "In this paper, we propose different strategies for simplifying filters, used as feature extractors, to be learnt in convolutional neural networks (ConvNets) in order to modify the hypothesis space, and to speed-up learning and processing times. We study two kinds of filters that are known to be computationally efficient in feed-forward processing: fused convolution/sub-sampling filters, and separable filters. We compare the complexity of the back-propagation algorithm on ConvNets based on these different kinds of filters. We show that using these filters allows to reach the same level of recognition performance as with classical ConvNets for handwritten digit recognition, up to 3.3 times faster.",
        "date": "2012",
        "authers": [
            "Franck Mamalet",
            "Christophe Garcia"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/251423608_Automatic_Scene_Text_Recognition_using_a_Convolutional_Neural_Network",
            "https://www.researchgate.net/publication/231556969_Deep_Learning_Made_Easier_by_Linear_Transformations_in",
            "https://www.researchgate.net/publication/228344387_High_Performance_Convolutional_Neural_Networks_for_Document_Processing",
            "https://www.researchgate.net/publication/224340092_Deep_Belief_Net_Learning_in_a_Long-Range_Vision_System_for_Autonomous_Off-Road_Driving",
            "https://www.researchgate.net/publication/221415287_text_Detection_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/220320307_Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models",
            "https://www.researchgate.net/publication/344849828_Facial_Image_Processing_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/313139691_Real-Time_Video_Convolutional_Face_Finder_on_Embedded_Platforms",
            "https://www.researchgate.net/publication/224164036_Embedded_facial_image_processing_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/216792756_Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Model"
        ]
    },
    "paper280": {
        "id": "319770291",
        "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively.",
        "date": "2014",
        "authers": [
            "Karen Simonyan",
            "Andrew Zisserman"
        ],
        "refrences": []
    },
    "paper281": {
        "id": "324584089",
        "title": "Simple Baselines for Human Pose Estimation and Tracking",
        "abstract": "There has been significant progress on pose estimation and increasing interests on pose tracking in recent years. At the same time, the overall algorithm and system complexity increases as well, making the algorithm analysis and comparison more difficult. This work provides simple and effective baseline methods. They are helpful for inspiring and evaluating new ideas for the field. State-of-the-art results are achieved on challenging benchmarks. The code will be available at https://github.com/leoxiaobin/pose.pytorch.",
        "date": "2018",
        "authers": [
            "Bin Xiao",
            "Haiping Wu",
            "Yichen Wei"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/329747444_Cascaded_Pyramid_Network_for_Multi-person_Pose_Estimation",
            "https://www.researchgate.net/publication/322059684_Learning_Feature_Pyramids_for_Human_Pose_Estimation",
            "https://www.researchgate.net/publication/329747604_Detect-and-Track_Efficient_Pose_Estimation_in_Videos",
            "https://www.researchgate.net/publication/329740421_PoseTrack_A_Benchmark_for_Human_Pose_Estimation_and_Tracking",
            "https://www.researchgate.net/publication/329488196_R-fcn_Object_detection_via_region-based_fully_convolutional_networks",
            "https://www.researchgate.net/publication/322076361_Detect-and-Track_Efficient_Pose_Estimation_in_Videos",
            "https://www.researchgate.net/publication/322060558_Deformable_Convolutional_Networks",
            "https://www.researchgate.net/publication/322060396_Mask_R-CNN",
            "https://www.researchgate.net/publication/322059217_Adversarial_PoseNet_A_Structure-Aware_Convolutional_Network_for_Human_Pose_Estimation",
            "https://www.researchgate.net/publication/322057861_Flow-Guided_Feature_Aggregation_for_Video_Object_Detection"
        ]
    },
    "paper282": {
        "id": "335144529",
        "title": "Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Vladimir Nekrasov",
            "Thanuja Dharmasiri",
            "Andrew Spek",
            "Tom Drummond"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319035939_BlitzNet_A_Real-Time_Deep_Network_for_Scene_Understanding",
            "https://www.researchgate.net/publication/317887394_Joint_Prediction_of_Depths_Normals_and_Surface_Curvature_from_RGB_Images_using_CNNs",
            "https://www.researchgate.net/publication/317823343_Joint_Prediction_of_Depths_Normals_and_Surface_Curvature_from_RGB_Images_using_CNNs",
            "https://www.researchgate.net/publication/317040443_Multi-Task_Learning_Using_Uncertainty_to_Weigh_Losses_for_Scene_Geometry_and_Semantics",
            "https://www.researchgate.net/publication/315796330_Not_All_Pixels_Are_Equal_Difficulty-aware_Semantic_Segmentation_via_Deep_Layer_Cascade",
            "https://www.researchgate.net/publication/315096611_What_Uncertainties_Do_We_Need_in_Bayesian_Deep_Learning_for_Computer_Vision",
            "https://www.researchgate.net/publication/311756352_Joint_Semantic_Segmentation_and_Depth_Estimation_with_Deep_Convolutional_Networks",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/303840621_ENet_A_Deep_Neural_Network_Architecture_for_Real-Time_Semantic_Segmentation",
            "https://www.researchgate.net/publication/303750237_Deeper_Depth_Prediction_with_Fully_Convolutional_Residual_Networks"
        ]
    },
    "paper283": {
        "id": "330595799",
        "title": "CReaM Condensed Real-time Models for Depth Prediction using Convolutional Neural Networks",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Andrew Spek",
            "Thanuja Dharmasiri",
            "Tom Drummond"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/327807807_Fusion_of_Stereo_and_Still_Monocular_Depth_Estimates_in_a_Self-Supervised_Learning_Context",
            "https://www.researchgate.net/publication/323904676_Fusion_of_stereo_and_still_monocular_depth_estimates_in_a_self-supervised_learning_context",
            "https://www.researchgate.net/publication/322221144_Restricted_Deformable_Convolution-Based_Road_Scene_Semantic_Segmentation_Using_Surround_View_Cameras",
            "https://www.researchgate.net/publication/320293291_ERFNet_Efficient_Residual_Factorized_ConvNet_for_Real-Time_Semantic_Segmentation",
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/317887394_Joint_Prediction_of_Depths_Normals_and_Surface_Curvature_from_RGB_Images_using_CNNs",
            "https://www.researchgate.net/publication/317823343_Joint_Prediction_of_Depths_Normals_and_Surface_Curvature_from_RGB_Images_using_CNNs",
            "https://www.researchgate.net/publication/316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications",
            "https://www.researchgate.net/publication/316075716_CNN-SLAM_Real-time_dense_monocular_SLAM_with_learned_depth_prediction",
            "https://www.researchgate.net/publication/303840621_ENet_A_Deep_Neural_Network_Architecture_for_Real-Time_Semantic_Segmentation"
        ]
    },
    "paper284": {
        "id": "329748830",
        "title": "Taskonomy Disentangling Task Transfer Learning",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Amir R. Zamir",
            "Alexander Sax",
            "William Shen",
            "Leonidas J. Guibas"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/314092103_Identifying_beneficial_task_relations_for_multi-task_learning_in_deep_neural_networks",
            "https://www.researchgate.net/publication/313366031_Joint_2D-3D-Semantic_Data_for_Indoor_Scene_Understanding",
            "https://www.researchgate.net/publication/311585806_Random_walks_and_diffusion_on_networks",
            "https://www.researchgate.net/publication/310769756_Fully_Convolutional_Instance-aware_Semantic_Segmentation",
            "https://www.researchgate.net/publication/303970238_Learning_to_learn_by_gradient_descent_by_gradient_descent",
            "https://www.researchgate.net/publication/303822170_Integrated_perception_with_recurrent_multi-task_neural_networks",
            "https://www.researchgate.net/publication/303750237_Deeper_Depth_Prediction_with_Fully_Convolutional_Residual_Networks",
            "https://www.researchgate.net/publication/301879687_Building_Machines_That_Learn_and_Think_Like_People",
            "https://www.researchgate.net/publication/301837491_Unsupervised_Learning_of_Visual_Representations_by_Solving_Jigsaw_Puzzles",
            "https://www.researchgate.net/publication/301648368_A_Deep_Hierarchical_Approach_to_Lifelong_Learning_in_Minecraft"
        ]
    },
    "paper285": {
        "id": "323570681",
        "title": "On the Power of Over-parametrization in Neural Networks with Quadratic Activation",
        "abstract": "We provide new theoretical insights on why over-parametrization is effective in learning neural networks. For a $k$ hidden node shallow network with quadratic activation and $n$ training data points, we show as long as $ k \\ge \\sqrt{2n}$, over-parametrization enables local search algorithms to find a \\emph{globally} optimal solution for general smooth and convex loss functions. Further, despite that the number of parameters may exceed the sample size, using theory of Rademacher complexity, we show with weight decay, the solution also generalizes well if the data is sampled from a regular distribution such as Gaussian. To prove when $k\\ge \\sqrt{2n}$, the loss function has benign landscape properties, we adopt an idea from smoothed analysis, which may have other applications in studying loss surfaces of neural networks.",
        "date": "2018",
        "authers": [
            "Simon Du",
            "Jason Lee"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/320975973_Learning_Non-overlapping_Convolutional_Neural_Networks_with_Multiple_Kernels",
            "https://www.researchgate.net/publication/320707672_SGD_Learns_Over-parameterized_Networks_that_Provably_Generalize_on_Linearly_Separable_Data",
            "https://www.researchgate.net/publication/318107236_Towards_Understanding_Generalization_of_Deep_Learning_Perspective_of_Loss_Landscapes",
            "https://www.researchgate.net/publication/316663833_Optimal_Approximation_with_Sparsely_Connected_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/314093619_Globally_Optimal_Gradient_Descent_for_a_ConvNet_with_Gaussian_Inputs",
            "https://www.researchgate.net/publication/311900760_Language_Modeling_with_Gated_Convolutional_Networks",
            "https://www.researchgate.net/publication/310329204_The_Power_of_Normalization_Faster_Evasion_of_Saddle_Points",
            "https://www.researchgate.net/publication/309738231_Topology_and_Geometry_of_Deep_Rectified_Network_Optimization_Landscapes",
            "https://www.researchgate.net/publication/304017872_The_non-convex_Burer-Monteiro_approach_works_on_smooth_semidefinite_programs",
            "https://www.researchgate.net/publication/292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search"
        ]
    },
    "paper286": {
        "id": "323302973",
        "title": "Neural Architecture Search with Bayesian Optimisation and Optimal Transport",
        "abstract": "Bayesian Optimisation (BO) refers to a class of methods for global optimisation of a function $f$ which is only accessible via point evaluations. It is typically used in settings where $f$ is expensive to evaluate. A common use case for BO in machine learning is model selection, where it is not possible to analytically model the generalisation performance of a statistical model, and we resort to noisy and expensive training and validation procedures to choose the best model. Conventional BO methods have focused on Euclidean and categorical domains, which, in the context of model selection, only permits tuning scalar hyper-parameters of machine learning algorithms. However, with the surge of interest in deep learning, there is an increasing demand to tune neural network \\emph{architectures}. In this work, we develop NASBOT, a Gaussian process based BO framework for neural architecture search. To accomplish this, we develop a distance metric in the space of neural network architectures which can be computed efficiently via an optimal transport program. This distance might be of independent interest to the deep learning community as it may find applications outside of BO. We demonstrate that NASBOT outperforms other alternatives for architecture search in several cross validation based model selection tasks on multi-layer perceptrons and convolutional neural networks.",
        "date": "2018",
        "authers": [
            "Kirthevasan Kandasamy",
            "Willie Neiswanger",
            "Jeff Schneider",
            "Barnabas Poczos"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/309738510_Designing_Neural_Network_Architectures_using_Reinforcement_Learning"
        ]
    },
    "paper287": {
        "id": "323118469",
        "title": "Efficient Neural Architecture Search via Parameters Sharing",
        "abstract": "We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. In ENAS, a controller learns to discover neural network architectures by searching for an optimal subgraph within a large computational graph. The controller is trained with policy gradient to select a subgraph that maximizes the expected reward on the validation set. Meanwhile the model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Thanks to parameter sharing between child models, ENAS is fast: it delivers strong empirical performances using much fewer GPU-hours than all existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On the Penn Treebank dataset, ENAS discovers a novel architecture that achieves a test perplexity of 55.8, establishing a new state-of-the-art among all methods without post-training processing. On the CIFAR-10 dataset, ENAS designs novel architectures that achieve a test error of 2.89%, which is on par with NASNet (Zoph et al., 2018), whose test error is 2.65%.",
        "date": "2018",
        "authers": [
            "Hieu Pham",
            "Melody Y. Guan",
            "Barret Zoph",
            "Quoc V. Le"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/317300069_Learning_Time-Efficient_Deep_Architectures_with_Budgeted_Super_Networks",
            "https://www.researchgate.net/publication/316598820_DeepArchitect_Automatically_Designing_and_Training_Deep_Architectures",
            "https://www.researchgate.net/publication/311222630_Capacity_and_Trainability_in_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/309738510_Designing_Neural_Network_Architectures_using_Reinforcement_Learning",
            "https://www.researchgate.net/publication/306885833_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/306187421_SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts",
            "https://www.researchgate.net/publication/305229133_Recurrent_Highway_Networks",
            "https://www.researchgate.net/publication/261100864_CNN_Features_Off-the-Shelf_An_Astounding_Baseline_for_Recognition",
            "https://www.researchgate.net/publication/221489926_Recurrent_neural_network_based_language_model",
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory"
        ]
    },
    "paper288": {
        "id": "323027025",
        "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
        "abstract": "Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at multiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information. In this work, we propose to combine the advantages from both methods. Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. We demonstrate the effectiveness of the proposed model on the PASCAL VOC 2012 semantic image segmentation dataset and achieve a performance of 89% on the test set without any post-processing. Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow.",
        "date": "2018",
        "authers": [
            "Liang-Chieh Chen",
            "Yukun Zhu",
            "George Papandreou",
            "Florian Schroff"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/320974965_Gated_Feedback_Refinement_Network_for_Dense_Image_Labeling",
            "https://www.researchgate.net/publication/314115448_Understanding_Convolution_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/312759848_DSSD_Deconvolutional_Single_Shot_Detector",
            "https://www.researchgate.net/publication/311769895_Beyond_Skip_Connections_Top-Down_Modulation_for_Object_Detection",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/310610877_RefineNet_Multi-Path_Refinement_Networks_with_Identity_Mappings_for_High-Resolution_Semantic_Segmentation",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/301839500_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network"
        ]
    },
    "paper289": {
        "id": "335463411",
        "title": "Semantic Correlation Promoted Shape-Variant Context for Segmentation",
        "abstract": "Context is essential for semantic segmentation. Due to the diverse shapes of objects and their complex layout in various scene images, the spatial scales and shapes of contexts for different objects have very large variation. It is thus ineffective or inefficient to aggregate various context information from a predefined fixed region. In this work, we propose to generate a scale-and shape-variant semantic mask for each pixel to confine its contextual region. To this end, we first propose a novel paired convolution to infer the semantic correlation of the pair and based on that to generate a shape mask. Using the inferred spatial scope of the contextual region, we propose a shape-variant convolution, of which the receptive field is controlled by the shape mask that varies with the appearance of input. In this way, the proposed network aggregates the context information of a pixel from its semantic-correlated region instead of a predefined fixed region. Furthermore, this work also proposes a labeling denoising model to reduce wrong predictions caused by the noisy low-level features. Without bells and whistles, the proposed segmentation network achieves new state-of-the-arts consistently on the six public segmentation datasets.",
        "date": "2019",
        "authers": [
            "Henghui Ding",
            "Xudong Jiang",
            "Bing Shuai",
            "Ai Qun Liu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/330411441_Feature_Boosting_Network_For_3D_Pose_Estimation",
            "https://www.researchgate.net/publication/329740318_Error_Correction_for_Dense_Semantic_Image_Labeling",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/338512713_AANet_Attribute_Attention_Network_for_Person_Re-Identifications",
            "https://www.researchgate.net/publication/338509793_Scene_Graph_Generation_With_External_Knowledge_and_Image_Reconstruction",
            "https://www.researchgate.net/publication/338508333_Towards_Robust_Curve_Text_Detection_With_Conditional_Spatial_Expansion",
            "https://www.researchgate.net/publication/329745999_Dense_Decoder_Shortcut_Connections_for_Single-Pass_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329743799_Recurrent_Scene_Parsing_with_Perspective_Understanding_in_the_Loop",
            "https://www.researchgate.net/publication/329743787_Learning_a_Discriminative_Feature_Network_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329743448_Learning_Markov_Clustering_Networks_for_Scene_Text_Detection"
        ]
    },
    "paper290": {
        "id": "339558864",
        "title": "Dynamic Multi-Scale Filters for Semantic Segmentation",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Junjun He",
            "Zhongying Deng",
            "Yu Qiao"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/329743873_Context_Encoding_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/329442528_DenseASPP_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/315666513_StyleBank_An_Explicit_Representation_for_Neural_Image_Style_Transfer",
            "https://www.researchgate.net/publication/314115448_Understanding_Convolution_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/308278279_SSD_Single_Shot_MultiBox_Detector",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions"
        ]
    },
    "paper291": {
        "id": "339558490",
        "title": "Unpaired Image Captioning via Scene Graph Alignments",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Jiuxiang Gu",
            "Shafiq Joty",
            "Jianfei Cai",
            "Handong Zhao"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/322060135_Unpaired_Image-to-Image_Translation_Using_Cycle-Consistent_Adversarial_Networks",
            "https://www.researchgate.net/publication/321160935_Neural_Motifs_Scene_Graph_Parsing_with_Global_Context",
            "https://www.researchgate.net/publication/321160918_Look_Imagine_and_Match_Improving_Textual-Visual_Cross-Modal_Retrieval_with_Generative_Models",
            "https://www.researchgate.net/publication/320727406_Unsupervised_Neural_Machine_Translation",
            "https://www.researchgate.net/publication/319643556_Stack-Captioning_Coarse-to-Fine_Learning_for_Image_Captioning",
            "https://www.researchgate.net/publication/311411280_Self-Critical_Sequence_Training_for_Image_Captioning",
            "https://www.researchgate.net/publication/308320812_Graph-Structured_Representations_for_Visual_Question_Answering"
        ]
    },
    "paper292": {
        "id": "339556516",
        "title": "Joint Learning of Saliency Detection and Weakly Supervised Semantic Segmentation",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Zeng Yu",
            "Yunzhi Zhuge",
            "Huchuan Lu",
            "Lihe Zhang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/334987659_Multi-Source_Weak_Supervision_for_Saliency_Detection",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/325718841_PAD-Net_Multi-Tasks_Guided_Prediction-and-Distillation_Network_for_Simultaneous_Depth_Estimation_and_Scene_Parsing",
            "https://www.researchgate.net/publication/319770123_Densely_Connected_Convolutional_Networks",
            "https://www.researchgate.net/publication/319186937_Self-explanatory_Deep_Salient_Object_Detection",
            "https://www.researchgate.net/publication/318981857_Learning_Uncertain_Convolutional_Features_for_Accurate_Saliency_Detection",
            "https://www.researchgate.net/publication/318981480_Amulet_Aggregating_Multi-level_Convolutional_Features_for_Salient_Object_Detection",
            "https://www.researchgate.net/publication/311842448_MultiNet_Real-time_Joint_Semantic_Reasoning_for_Autonomous_Driving"
        ]
    },
    "paper293": {
        "id": "339555830",
        "title": "Deep Learning for Light Field Saliency Detection",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Tiantian Wang",
            "Yongri Piao",
            "Huchuan Lu",
            "Xiao Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/334844293_Deep_Light-field-driven_Saliency_Detection_from_a_Single_View",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/326200125_R3_Net_Recurrent_Residual_Refinement_Network_for_Saliency_Detection",
            "https://www.researchgate.net/publication/322058016_A_Stagewise_Refinement_Model_for_Detecting_Salient_Objects_in_Images",
            "https://www.researchgate.net/publication/318981857_Learning_Uncertain_Convolutional_Features_for_Accurate_Saliency_Detection",
            "https://www.researchgate.net/publication/318981480_Amulet_Aggregating_Multi-level_Convolutional_Features_for_Salient_Object_Detection",
            "https://www.researchgate.net/publication/314634750_Locality-Sensitive_Deconvolution_Networks_with_Gated_Fusion_for_RGB-D_Indoor_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311459324_FLIC_Fast_Linear_Iterative_Clustering_with_Active_Search"
        ]
    },
    "paper294": {
        "id": "339555410",
        "title": "Adaptive Context Network for Scene Parsing",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Jun Fu",
            "Jing Liu",
            "Yuhang Wang",
            "Yong Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/329743873_Context_Encoding_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/329442528_DenseASPP_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/314115448_Understanding_Convolution_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better"
        ]
    },
    "paper295": {
        "id": "339554650",
        "title": "Fast Video Object Segmentation via Dynamic Targeting Network",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Lu Zhang",
            "Zhe Lin",
            "Jianming Zhang",
            "Huchuan Lu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/329743795_Efficient_Video_Object_Segmentation_via_Network_Modulation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/325809224_MoNet_Deep_Motion_Exploitation_for_Video_Object_Segmentation",
            "https://www.researchgate.net/publication/324104851_MaskRNN_Instance_Level_Video_Object_Segmentation",
            "https://www.researchgate.net/publication/319164056_Pixel-Level_Matching_for_Video_Object_Segmentation_using_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/318959852_Pixel-Level_Matching_for_Video_Object_Segmentation_Using_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/311715217_Video_Propagation_Networks",
            "https://www.researchgate.net/publication/311459265_FlowNet_20_Evolution_of_Optical_Flow_Estimation_with_Deep_Networks"
        ]
    },
    "paper296": {
        "id": "338512016",
        "title": "Dual Attention Network for Scene Segmentation",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Jun Fu",
            "Jing Liu",
            "Haijie Tian",
            "Yong Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/329743873_Context_Encoding_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/329442528_DenseASPP_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/319736499_DiSAN_Directional_Self-Attention_Network_for_RNNCNN-free_Language_Understanding",
            "https://www.researchgate.net/publication/314115448_Understanding_Convolution_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/276923248_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation",
            "https://www.researchgate.net/publication/264975444_The_Role_of_Context_for_Object_Detection_and_Semantic_Segmentation_in_the_Wild",
            "https://www.researchgate.net/publication/234768533_Image_Annotation_by_kNN-Sparse_Graph-Based_Label_Propagation_over_Noisily_Tagged_Web_Images"
        ]
    },
    "paper297": {
        "id": "338509793",
        "title": "Scene Graph Generation With External Knowledge and Image Reconstruction",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Jiuxiang Gu",
            "Handong Zhao",
            "Zhe Lin",
            "Sheng Li"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation",
            "https://www.researchgate.net/publication/329740252_Context_Contrasted_Feature_and_Gated_Multi-scale_Aggregation_for_Scene_Segmentation",
            "https://www.researchgate.net/publication/324492738_Zero-Shot_Object_Detection",
            "https://www.researchgate.net/publication/322060440_Scene_Graph_Generation_from_Objects_Phrases_and_Region_Captions",
            "https://www.researchgate.net/publication/321498323_Explicit_Reasoning_over_End-to-End_Neural_Architectures_for_Visual_Question_Answering",
            "https://www.researchgate.net/publication/321160935_Neural_Motifs_Scene_Graph_Parsing_with_Global_Context",
            "https://www.researchgate.net/publication/321160918_Look_Imagine_and_Match_Improving_Textual-Visual_Cross-Modal_Retrieval_with_Generative_Models",
            "https://www.researchgate.net/publication/321124901_Natural_Language_Guided_Visual_Relationship_Detection",
            "https://www.researchgate.net/publication/319643556_Stack-Captioning_Coarse-to-Fine_Learning_for_Image_Captioning",
            "https://www.researchgate.net/publication/318814060_Visual_Relationship_Detection_with_Internal_and_External_Linguistic_Knowledge_Distillation"
        ]
    },
    "paper298": {
        "id": "338506535",
        "title": "Adaptive Pyramid Context Network for Semantic Segmentation",
        "abstract": "",
        "date": "2019",
        "authers": [
            "Junjun He",
            "Zhongying Deng",
            "Lei Zhou",
            "Yali Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/329743873_Context_Encoding_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/303448993_Bridging_Category-level_and_Instance-level_Semantic_Image_Segmentation",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/283471087_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better",
            "https://www.researchgate.net/publication/268689640_Hypercolumns_for_Object_Segmentation_and_Fine-grained_Localization",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge",
            "https://www.researchgate.net/publication/264975444_The_Role_of_Context_for_Object_Detection_and_Semantic_Segmentation_in_the_Wild"
        ]
    },
    "paper299": {
        "id": "322749812",
        "title": "SegNet A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation",
        "abstract": "We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1]. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.",
        "date": "2017",
        "authers": [
            "Vijay Badrinarayanan",
            "Alex Kendall",
            "Roberto Cipolla"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/332814678_Bayesian_SegNet_Model_Uncertainty_in_Deep_Convolutional_Encoder-Decoder_Architectures_for_Scene_Understanding",
            "https://www.researchgate.net/publication/319770420_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_and_Fully_Connected_CRFs",
            "https://www.researchgate.net/publication/319770305_Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition",
            "https://www.researchgate.net/publication/319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition",
            "https://www.researchgate.net/publication/319770284_Edge_Boxes_Locating_Object_Proposals_from_Edges",
            "https://www.researchgate.net/publication/319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification",
            "https://www.researchgate.net/publication/319770198_Learning_a_Deep_Convolutional_Network_for_Image_Super-Resolution",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/314100361_Indoor_Segmentation_and_Support_Inference_from_RGBD_Images",
            "https://www.researchgate.net/publication/311610893_Efficient_Piecewise_Training_of_Deep_Structured_Models_for_Semantic_Segmentation"
        ]
    },
    "paper300": {
        "id": "324996175",
        "title": "Understanding Convolution for Semantic Segmentation",
        "abstract": "",
        "date": "2018",
        "authers": [
            "Panqu Wang",
            "Pengfei Chen",
            "Ye Yuan",
            "Ding Liu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308262491_Real-Time_Single_Image_and_Video_Super-Resolution_Using_an_Efficient_Sub-Pixel_Convolutional_Neural_Network",
            "https://www.researchgate.net/publication/306357649_Semantic_Understanding_of_Scenes_Through_the_ADE20K_Dataset",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301899012_Optical_Flow_with_Semantic_Segmentation_and_Localized_Layers",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/301877264_High-performance_Semantic_Segmentation_Using_Very_Deep_Fully_Convolutional_Networks",
            "https://www.researchgate.net/publication/286134669_MXNet_A_Flexible_and_Efficient_Machine_Learning_Library_for_Heterogeneous_Distributed_Systems",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/275588416_FlowNet_Learning_Optical_Flow_with_Convolutional_Networks",
            "https://www.researchgate.net/publication/265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge"
        ]
    },
    "paper301": {
        "id": "322058210",
        "title": "Video Scene Parsing with Predictive Feature Learning",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Xiaojie Jin",
            "Xin Li",
            "Huaxin Xiao",
            "Xiaohui Shen"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770165_Optical_Flow_with_Semantic_Segmentation_and_Localized_Layers",
            "https://www.researchgate.net/publication/308190263_Recurrent_Temporal_Deep_Field_for_Semantic_Video_Labeling",
            "https://www.researchgate.net/publication/307984819_Generating_Videos_with_Scene_Dynamics",
            "https://www.researchgate.net/publication/307307331_Multi-Path_Feedback_Recurrent_Neural_Network_for_Scene_Parsing",
            "https://www.researchgate.net/publication/305655121_Approximate_Policy_Iteration_for_Budgeted_Semantic_Video_Segmentation",
            "https://www.researchgate.net/publication/303544998_Deep_Predictive_Coding_Networks_for_Video_Prediction_and_Unsupervised_Learning",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301899012_Optical_Flow_with_Semantic_Segmentation_and_Localized_Layers",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/301877264_High-performance_Semantic_Segmentation_Using_Very_Deep_Fully_Convolutional_Networks"
        ]
    },
    "paper302": {
        "id": "320971443",
        "title": "Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Tobias Pohlen",
            "Alexander Hermans",
            "Markus Mathias",
            "Bastian Leibe"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322749812_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/311610734_The_SYNTHIA_Dataset_A_Large_Collection_of_Synthetic_Images_for_Semantic_Segmentation_of_Urban_Scenes",
            "https://www.researchgate.net/publication/306376589_VoxResNet_Deep_Voxelwise_Residual_Networks_for_Volumetric_Brain_Segmentation",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/303840621_ENet_A_Deep_Neural_Network_Architecture_for_Real-Time_Semantic_Segmentation",
            "https://www.researchgate.net/publication/303448993_Bridging_Category-level_and_Instance-level_Semantic_Image_Segmentation",
            "https://www.researchgate.net/publication/302569301_Theano_A_Python_framework_for_fast_computation_of_mathematical_expressions",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/283471087_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation"
        ]
    },
    "paper303": {
        "id": "320968233",
        "title": "RefineNet Multi-path Refinement Networks for High-Resolution Semantic Segmentation",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Guosheng Lin",
            "Anton Milan",
            "Chunhua Shen",
            "Ian Reid"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322749812_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/308278291_Higher_Order_Conditional_Random_Fields_in_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/283658606_Bayesian_SegNet_Model_Uncertainty_in_Deep_Convolutional_Encoder-Decoder_Architectures_for_Scene_Understanding",
            "https://www.researchgate.net/publication/283471087_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/272845187_Learning_Depth_from_Single_Monocular_Images_Using_Deep_Convolutional_Neural_Fields",
            "https://www.researchgate.net/publication/272194536_Conditional_Random_Fields_as_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/268747978_Deep_Convolutional_Neural_Fields_for_Depth_Estimation_from_a_Single_Image"
        ]
    },
    "paper304": {
        "id": "320968206",
        "title": "Pyramid Scene Parsing Network",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Hengshuang Zhao",
            "Jianping Shi",
            "Xiaojuan Qi",
            "Xiaogang Wang"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/322749812_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/306357649_Semantic_Understanding_of_Scenes_Through_the_ADE20K_Dataset",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/303448993_Bridging_Category-level_and_Instance-level_Semantic_Image_Segmentation",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/283471087_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/279968654_Towards_Good_Practices_for_Very_Deep_Two-Stream_ConvNets",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better"
        ]
    },
    "paper305": {
        "id": "320964900",
        "title": "Large Kernel Matters - Improve Semantic Segmentation by Global Convolutional Network",
        "abstract": "",
        "date": "2017",
        "authers": [
            "Chao Peng",
            "Xiangyu Zhang",
            "Gang Yu",
            "Guiming Luo"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/308278291_Higher_Order_Conditional_Random_Fields_in_Deep_Neural_Networks",
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/301877264_High-performance_Semantic_Segmentation_Using_Very_Deep_Fully_Convolutional_Networks",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better",
            "https://www.researchgate.net/publication/277334270_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Robust_Semantic_Pixel-Wise_Labelling",
            "https://www.researchgate.net/publication/276923248_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation",
            "https://www.researchgate.net/publication/272194536_Conditional_Random_Fields_as_Recurrent_Neural_Networks"
        ]
    },
    "paper306": {
        "id": "319770420",
        "title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs",
        "abstract": "Deep Convolutional Neural Networks (DCNNs) have recently shown state of the art performance in high level vision tasks, such as image classification and object detection. This work brings together methods from DCNNs and probabilistic graphical models for addressing the task of pixel-level classification (also called \"semantic image segmentation\"). We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation. This is due to the very invariance properties that make DCNNs good for high level tasks. We overcome this poor localization property of deep networks by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF). Qualitatively, our \"DeepLab\" system is able to localize segment boundaries at a level of accuracy which is beyond previous methods. Quantitatively, our method sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 71.6% IOU accuracy in the test set. We show how these results can be obtained efficiently: Careful network re-purposing and a novel application of the 'hole' algorithm from the wavelet community allow dense computation of neural net responses at 8 frames per second on a modern GPU.",
        "date": "2015",
        "authers": [
            "Liang-Chieh Chen",
            "George Papandreou",
            "Iasonas Kokkinos",
            "Kevin Murphy"
        ],
        "refrences": []
    },
    "paper307": {
        "id": "319770168",
        "title": "Fully Convolutional Networks for Semantic Segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of\nfeatures. We show that convolutional networks by themselves, trained\nend-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic\nsegmentation. Our key insight is to build \"fully convolutional\" networks that\ntake input of arbitrary size and produce correspondingly-sized output with\nefficient inference and learning. We define and detail the space of fully\nconvolutional networks, explain their application to spatially dense prediction\ntasks, and draw connections to prior models. We adapt contemporary\nclassification networks (AlexNet, the VGG net, and GoogLeNet) into fully\nconvolutional networks and transfer their learned representations by\nfine-tuning to the segmentation task. We then define a novel architecture that\ncombines semantic information from a deep, coarse layer with appearance\ninformation from a shallow, fine layer to produce accurate and detailed\nsegmentations. Our fully convolutional network achieves state-of-the-art\nsegmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012),\nNYUDv2, and SIFT Flow, while inference takes one third of a second for a\ntypical image.",
        "date": "2014",
        "authers": [
            "Jonathan Long",
            "Evan Shelhamer",
            "Trevor Darrell"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/272845187_Learning_Depth_from_Single_Monocular_Images_Using_Deep_Convolutional_Neural_Fields",
            "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions",
            "https://www.researchgate.net/publication/264160686_Learning_Rich_Features_from_RGB-D_Images_for_Object_Detection_and_Segmentation",
            "https://www.researchgate.net/publication/263048918_Joint_Training_of_a_Convolutional_Network_and_a_Graphical_Model_for_Human_Pose_Estimation",
            "https://www.researchgate.net/publication/262568634_Descriptor_Matching_with_Convolutional_Neural_Networks_a_Comparison_to_SIFT",
            "https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks",
            "https://www.researchgate.net/publication/240308781_Learning_Hierarchical_Features_for_Scene_Labeling",
            "https://www.researchgate.net/publication/227211589_The_Gaussian_scale-space_paradigm_and_the_multiscale_local_jet",
            "https://www.researchgate.net/publication/221618184_Postal_Address_Block_Location_Using_a_Convolutional_Locator_Network"
        ]
    },
    "paper308": {
        "id": "317679203",
        "title": "Rethinking Atrous Convolution for Semantic Image Segmentation",
        "abstract": "In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation. To handle the problem of segmenting objects at multiple scales, we design modules which employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates. Furthermore, we propose to augment our previously proposed Atrous Spatial Pyramid Pooling module, which probes convolutional features at multiple scales, with image-level features encoding global context and further boost performance. We also elaborate on implementation details and share our experience on training our system. The proposed `DeepLabv3' system significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2012 semantic image segmentation benchmark.",
        "date": "2017",
        "authers": [
            "Liang-Chieh Chen",
            "George Papandreou",
            "Florian Schroff",
            "Hartwig Adam"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/320974965_Gated_Feedback_Refinement_Network_for_Dense_Image_Labeling",
            "https://www.researchgate.net/publication/317062328_Recurrent_Scene_Parsing_with_Perspective_Understanding_in_the_Loop",
            "https://www.researchgate.net/publication/315796330_Not_All_Pixels_Are_Equal_Difficulty-aware_Semantic_Segmentation_via_Deep_Layer_Cascade",
            "https://www.researchgate.net/publication/314115448_Understanding_Convolution_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/311769895_Beyond_Skip_Connections_Top-Down_Modulation_for_Object_Detection",
            "https://www.researchgate.net/publication/311223153_Speedaccuracy_trade-offs_for_modern_convolutional_object_detectors",
            "https://www.researchgate.net/publication/311222763_Wider_or_Deeper_Revisiting_the_ResNet_Model_for_Visual_Recognition",
            "https://www.researchgate.net/publication/310953445_Full-Resolution_Residual_Networks_for_Semantic_Segmentation_in_Street_Scenes",
            "https://www.researchgate.net/publication/310610877_RefineNet_Multi-Path_Refinement_Networks_with_Identity_Mappings_for_High-Resolution_Semantic_Segmentation",
            "https://www.researchgate.net/publication/309288645_Mixed_context_networks_for_semantic_segmentation"
        ]
    },
    "paper309": {
        "id": "319769910",
        "title": "Efficient piecewise training of deep structure models for semantic segmentation",
        "abstract": "Recent advances on semantic image segmentation are achieved by training deep\nconvolutional neural networks (DCNNs) on a large amount of labelled images. On\nthe other hand, structured models such as conditional random fields (CRFs) are\nan effective tool for labelling tasks, which play an important role in that\nCRFs can capture the global context of the image as well as local neighbourhood\ninformation. Here we explore contextual information to improve semantic image\nsegmentation by taking advantage of the strength of both DCNNs and CRFs.\nSpecifically, we train CRFs whose potential functions are modelled by fully\nconvolutional neural networks (FCNNs). The resulted deep conditional random\nfields (DCRFs) are thus able to learn complex feature representations; and\nduring the course of learning, dependencies between the output variables are\ntaken into account. As in conventional DCNNs, the training of our model is\nperformed in an end-to-end fashion using back-propagation. Different from\nDCNNs, however, inference may be needed at each gradient descent iteration,\nwhich can be computationally very expensive since typically millions of\niterations are required. To enable efficient training, we propose to use\napproximate training, namely, piecewise training of CRFs, avoiding repeated\ninference. We achieve very competitive results on the PASCAL VOC 2012 dataset\nfor semantic segmentation. Our model is trained on the VOC dataset alone with\nno extra data; and we achieve an intersection-over-union score of 70.7 on its\ntest set, which outperforms state-of-the-art results. Our superior results\nparticularly highlight the usefulness of the learnt pairwise neighbourhood\nrelations modelled by complex FCNNs.",
        "date": "2015",
        "authers": [
            "Guosheng Lin",
            "Chunhua Shen",
            "Ian Reid",
            "Anton van den Hengel"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/273388101_Fully_Connected_Deep_Structured_Networks",
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770268_Joint_Training_of_a_Convolutional_Network_and_a_Graphical_Model_for_Human_Pose_Estimation",
            "https://www.researchgate.net/publication/319770198_Learning_a_Deep_Convolutional_Network_for_Image_Super-Resolution",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/308849673_Feedforward_semantic_segmentation_with_zoom-out_features",
            "https://www.researchgate.net/publication/308820111_Deep_convolutional_neural_fields_for_depth_estimation_from_a_single_image",
            "https://www.researchgate.net/publication/301921832_Fully_convolutional_networks_for_semantic_segmentation",
            "https://www.researchgate.net/publication/273157570_BoxSup_Exploiting_Bounding_Boxes_to_Supervise_Convolutional_Networks_for_Semantic_Segmentation"
        ]
    },
    "paper310": {
        "id": "282179651",
        "title": "Vision-Based Offline-Online Perception Paradigm for Autonomous Driving",
        "abstract": "Autonomous driving is a key factor for future mobility. Properly perceiving the environment of the vehicles is essential for a safe driving, which requires computing accurate geometric and semantic information in real-time. In this paper, we challenge state-of-the-art computer vision algorithms for building a perception system for autonomous driving. An inherent drawback in the computation of visual semantics is the trade-off between accuracy and computational cost. We propose to circumvent this problem by following an offline-online strategy. During the offline stage dense 3D semantic maps are created. In the online stage the current driving area is recognized in the maps via a re-localization process, which allows to retrieve the pre-computed accurate semantics and 3D geometry in real-time. Then, detecting the dynamic obstacles we obtain a rich understanding of the current scene. We evaluate quantitatively our proposal in the KITTI dataset and discuss the related open challenges for the computer vision community.",
        "date": "2015",
        "authers": [
            "German Ros",
            "Sebastian Ramos",
            "Manuel Granados",
            "Amir Bakhtiary"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/310775931_The_DARPA_Urban_Challenge_Autonomous_Vehicles_in_City_Traffic",
            "https://www.researchgate.net/publication/284040965_Mean_shift_A_robust_approach_toward_feature_space_analysis",
            "https://www.researchgate.net/publication/269250272_Fast_and_Robust_ell_1-averaging-based_Pose_Estimation_for_Driving_Scenarios",
            "https://www.researchgate.net/publication/268733104_Speeded-up_robust_features_SURF",
            "https://www.researchgate.net/publication/262398911_Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation",
            "https://www.researchgate.net/publication/262284532_Experience-based_navigation_for_long-term_localisation",
            "https://www.researchgate.net/publication/261416457_SeqSLAM_Visual_route-based_navigation_for_sunny_summer_days_and_stormy_winter_nights",
            "https://www.researchgate.net/publication/261415992_Feature_Co-occurrence_Maps_Appearance-based_localisation_throughout_the_day",
            "https://www.researchgate.net/publication/261415967_Efficient_3-D_scene_analysis_from_streaming_data",
            "https://www.researchgate.net/publication/261263624_A_Video_Representation_Using_Temporal_Superpixels"
        ]
    },
    "paper311": {
        "id": "277334270",
        "title": "SegNet A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling",
        "abstract": "We propose a novel deep architecture, SegNet, for semantic pixel wise image\nlabelling. SegNet has several attractive properties; (i) it only requires\nforward evaluation of a fully learnt function to obtain smooth label\npredictions, (ii) with increasing depth, a larger context is considered for\npixel labelling which improves accuracy, and (iii) it is easy to visualise the\neffect of feature activation(s) in the pixel label space at any depth. SegNet\nis composed of a stack of encoders followed by a corresponding decoder stack\nwhich feeds into a soft-max classification layer. The decoders help map low\nresolution feature maps at the output of the encoder stack to full input image\nsize feature maps. This addresses an important drawback of recent deep learning\napproaches which have adopted networks designed for object categorization for\npixel wise labelling. These methods lack a mechanism to map deep layer feature\nmaps to input dimensions. They resort to ad hoc methods to upsample features,\ne.g. by replication. This results in noisy predictions and also restricts the\nnumber of pooling layers in order to avoid too much upsampling and thus reduces\nspatial context. SegNet overcomes these problems by learning to map encoder\noutputs to image pixel labels. We test the performance of SegNet on outdoor RGB\nscenes from CamVid, KITTI and indoor scenes from the NYU dataset. Our results\nshow that SegNet achieves state-of-the-art performance even without use of\nadditional cues such as depth, video frames or post-processing with CRF models.",
        "date": "2015",
        "authers": [
            "Vijay Badrinarayanan",
            "Ankur Handa",
            "Roberto Cipolla"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions",
            "https://www.researchgate.net/publication/319770305_Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition",
            "https://www.researchgate.net/publication/319770198_Learning_a_Deep_Convolutional_Network_for_Image_Super-Resolution",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/314100361_Indoor_Segmentation_and_Support_Inference_from_RGBD_Images",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/309076254_Gradientbased_learning_applied_to_document_recognition",
            "https://www.researchgate.net/publication/303432735_Recurrent_convolutional_neural_networks_for_scene_labeling",
            "https://www.researchgate.net/publication/302962450_Neural_decision_forests_for_semantic_image_labelling",
            "https://www.researchgate.net/publication/285990902_Dense_3D_semantic_mapping_of_indoor_scenes_from_RGB-D_images"
        ]
    },
    "paper312": {
        "id": "275588416",
        "title": "FlowNet Learning Optical Flow with Convolutional Networks",
        "abstract": "Convolutional neural networks (CNNs) have recently been very successful in a\nvariety of computer vision tasks, especially on those linked to recognition.\nOptical flow estimation has not been among the tasks where CNNs were\nsuccessful. In this paper we construct appropriate CNNs which are capable of\nsolving the optical flow estimation problem as a supervised learning task. We\npropose and compare two architectures: a generic architecture and another one\nincluding a layer that correlates feature vectors at different image locations.\nSince existing ground truth data sets are not sufficiently large to train a\nCNN, we generate a synthetic Flying Chairs dataset. We show that networks\ntrained on this unrealistic data still generalize very well to existing\ndatasets such as Sintel and KITTI, achieving competitive accuracy at frame\nrates of 5 to 10 fps.",
        "date": "2015",
        "authers": [
            "Philipp Fischer",
            "Alexey Dosovitskiy",
            "Eddy Ilg",
            "Philip H\u00e4usser"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation",
            "https://www.researchgate.net/publication/319770355_Generative_Adversarial_Nets",
            "https://www.researchgate.net/publication/319770269_Learning_to_Generate_Chairs_with_Convolutional_Neural_Networks",
            "https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks",
            "https://www.researchgate.net/publication/319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/310752533_Visualizing_and_understanding_convolutional_networks",
            "https://www.researchgate.net/publication/308854455_EpicFlow_Edge-preserving_interpolation_of_correspondences_for_optical_flow",
            "https://www.researchgate.net/publication/302579452_Optical_Flow_with_Geometric_Occlusion_Estimation_and_Fusion_of_Multiple_Frames",
            "https://www.researchgate.net/publication/301921832_Fully_convolutional_networks_for_semantic_segmentation",
            "https://www.researchgate.net/publication/289788943_Learning_the_local_statistics_of_optical_flow"
        ]
    },
    "paper313": {
        "id": "308830795",
        "title": "Multiclass semantic video segmentation with object-level active inference",
        "abstract": "",
        "date": "2015",
        "authers": [
            "Buyu Liu",
            "Xuming He"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/294282434_Learning_Where_to_Classify_in_Multi-view_Semantic_Segmentation",
            "https://www.researchgate.net/publication/261391832_Efficient_temporal_consistency_for_streaming_video_scene_analysis",
            "https://www.researchgate.net/publication/261116324_Describing_the_Scene_as_a_Whole_Joint_Object_Detection_Scene_Classification_and_Semantic_Segmentation",
            "https://www.researchgate.net/publication/224262409_Track_to_the_Future_Spatio-temporal_Video_Segmentation_with_Long-range_Motion_Cues",
            "https://www.researchgate.net/publication/221304854_Segmentation_and_Recognition_Using_Structure_from_Motion_Point_Clouds",
            "https://www.researchgate.net/publication/221304820_Learning_and_Incorporating_Top-Down_Cues_in_Image_Segmentation",
            "https://www.researchgate.net/publication/221304279_What_Where_and_How_Many_Combining_Object_Detectors_and_CRFs",
            "https://www.researchgate.net/publication/221111462_Segmentation_Ordering_and_Multi-Object_Tracking_using_Graphical_Models",
            "https://www.researchgate.net/publication/300358366_Joint_Semantic_Segmentation_and_3D_Reconstruction_from_Monocular_Video",
            "https://www.researchgate.net/publication/286690680_Scene_Understanding_by_Labeling_Pixels"
        ]
    },
    "paper314": {
        "id": "302305924",
        "title": "Feature Space Optimization for Semantic Video Segmentation",
        "abstract": "We present an approach to long-range spatio-temporal regularization in semantic video segmentation. Temporal regularization in video is challenging because both the camera and the scene may be in motion. Thus Euclidean distance in the space-time volume is not a good proxy for correspondence. We optimize the mapping of pixels to a Euclidean feature space so as to minimize distances between corresponding points. Structured prediction is performed by a dense CRF that operates on the optimized features. Experimental results demonstrate that the presented approach increases the accuracy and temporal consistency of semantic video segmentation.",
        "date": "2016",
        "authers": [
            "Abhijit Kundu",
            "Vibhav Vineet",
            "Vladlen Koltun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319769910_Efficient_piecewise_training_of_deep_structure_models_for_semantic_segmentation",
            "https://www.researchgate.net/publication/302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions",
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/281670982_Semantic_Video_Segmentation_Exploring_Inference_Efficiency",
            "https://www.researchgate.net/publication/277334270_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Robust_Semantic_Pixel-Wise_Labelling",
            "https://www.researchgate.net/publication/261391832_Efficient_temporal_consistency_for_streaming_video_scene_analysis",
            "https://www.researchgate.net/publication/256663526_Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials",
            "https://www.researchgate.net/publication/256663158_Parameter_Learning_and_Convergent_Inference_for_Dense_Random_Fields",
            "https://www.researchgate.net/publication/221303731_SuperParsing_Scalable_Nonparametric_Image_Parsing_with_Superpixels",
            "https://www.researchgate.net/publication/221259554_Combining_Appearance_and_Structure_from_Motion_Features_for_Road_Scene_Understanding"
        ]
    },
    "paper315": {
        "id": "283761983",
        "title": "Attention to Scale Scale-aware Semantic Image Segmentation",
        "abstract": "Incorporating multi-scale features to deep convolutional neural networks\n(DCNNs) has been a key element to achieve state-of-art performance on semantic\nimage segmentation benchmarks. One way to extract multi-scale features is by\nfeeding several resized input images to a shared deep network and then merge\nthe resulting multi-scale features for pixel-wise classification. In this work,\nwe adapt a state-of-art semantic image segmentation model with multi-scale\ninput images. We jointly train the network and an attention model which learns\nto softly weight the multi-scale features, and show that it outperforms\naverage- or max-pooling over scales. The proposed attention model allows us to\ndiagnostically visualize the importance of features at different positions and\nscales. Moreover, we show that adding extra supervision to the output of DCNN\nfor each scale is essential to achieve excellent performance when merging\nmulti-scale features. We demonstrate the effectiveness of our model with\nexhaustive experiments on three challenging datasets, including\nPASCAL-Person-Part, PASCAL VOC 2012 and a subset of MS-COCO 2014.",
        "date": "2015",
        "authers": [
            "Liang-Chieh Chen",
            "Yi Yang",
            "Jiang Wang",
            "Wei Xu"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319769910_Efficient_piecewise_training_of_deep_structure_models_for_semantic_segmentation",
            "https://www.researchgate.net/publication/304409176_Conditional_Random_Fields_as_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks",
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/278413297_ParseNet_Looking_Wider_to_See_Better",
            "https://www.researchgate.net/publication/273005574_Describing_Videos_by_Exploiting_Temporal_Structure",
            "https://www.researchgate.net/publication/272194536_Conditional_Random_Fields_as_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/269332682_2D_Human_Pose_Estimation_New_Benchmark_and_State_of_the_Art_Analysis",
            "https://www.researchgate.net/publication/269116202_Feedforward_semantic_segmentation_with_zoom-out_features",
            "https://www.researchgate.net/publication/268689640_Hypercolumns_for_Object_Segmentation_and_Fine-grained_Localization"
        ]
    },
    "paper316": {
        "id": "276923091",
        "title": "Learning Deconvolution Network for Semantic Segmentation",
        "abstract": "We propose a novel semantic segmentation algorithm by learning a\ndeconvolution network. We learn the network on top of the convolutional layers\nadopted from VGG 16-layer net. The deconvolution network is composed of\ndeconvolution and unpooling layers, which identify pixel-wise class labels and\npredict segmentation masks. We apply the trained network to each proposal in an\ninput image, and construct the final semantic segmentation map by combining the\nresults from all proposals in a simple manner. The proposed algorithm mitigates\nthe limitations of the existing methods based on fully convolutional networks\nby integrating deep deconvolution network and proposal-wise prediction; our\nsegmentation method typically identifies detailed structures and handles\nobjects in multiple scales naturally. Our network demonstrates outstanding\nperformance in PASCAL VOC 2012 dataset, and we achieve the best accuracy\n(72.5%) among the methods trained with no external data through ensemble with\nthe fully convolutional network.",
        "date": "2015",
        "authers": [
            "Hyeonwoo Noh",
            "Seunghoon Hong",
            "Bohyung Han"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/277334270_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Robust_Semantic_Pixel-Wise_Labelling",
            "https://www.researchgate.net/publication/272845640_Online_Tracking_by_Learning_Discriminative_Saliency_Map_with_Convolutional_Neural_Network",
            "https://www.researchgate.net/publication/269116202_Feedforward_semantic_segmentation_with_zoom-out_features",
            "https://www.researchgate.net/publication/268689640_Hypercolumns_for_Object_Segmentation_and_Fine-grained_Localization",
            "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions",
            "https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding",
            "https://www.researchgate.net/publication/256663526_Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials",
            "https://www.researchgate.net/publication/240308781_Learning_Hierarchical_Features_for_Scene_Labeling",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/220659463_The_Pascal_Visual_Object_Classes_VOC_challenge"
        ]
    },
    "paper317": {
        "id": "319770205",
        "title": "Monocular pedestrian detection survey and experiments",
        "abstract": "Pedestrian detection is a rapidly evolving area in computer vision with key applications in intelligent vehicles, surveillance, and advanced robotics. The objective of this paper is to provide an overview of the current state of the art from both methodological and experimental perspectives. The first part of the paper consists of a survey. We cover the main components of a pedestrian detection system and the underlying models. The second (and larger) part of the paper contains a corresponding experimental study. We consider a diverse set of state-of-the-art systems: wavelet-based AdaBoost cascade [74], HOG/linSVM [11], NN/LRF [75], and combined shape-texture detection [23]. Experiments are performed on an extensive data set captured onboard a vehicle driving through urban environment. The data set includes many thousands of training samples as well as a 27-minute test sequence involving more than 20,000 images with annotated pedestrian locations. We consider a generic evaluation setting and one specific to pedestrian detection onboard a vehicle. Results indicate a clear advantage of HOG/linSVM at higher image resolutions and lower processing speeds, and a superiority of the wavelet-based AdaBoost cascade approach at lower image resolutions and (near) real-time processing speeds. The data set (8.5 GB) is made public for benchmarking purposes.",
        "date": "2009IEEE",
        "authers": [
            "Markus Enzweiler",
            "Dariu M. Gavrila"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/319770820_Histograms_of_Oriented_Gradients_for_Human_Detection",
            "https://www.researchgate.net/publication/319770538_Low_level_recognition_of_human_motion",
            "https://www.researchgate.net/publication/313566497_Human_detection_via_classification_on_Riemannian_manifolds",
            "https://www.researchgate.net/publication/313425098_Distance_transformations_in_digital_images",
            "https://www.researchgate.net/publication/306353539_Dynamic_3D_scene_analysis_from_a_moving_vehicle",
            "https://www.researchgate.net/publication/288905811_Learning_to_detect_objects_in_images_via_a_sparse_part-based_representation",
            "https://www.researchgate.net/publication/261227389_A_Mixed_Generative-Discriminative_Framework_for_Pedestrian_Classification",
            "https://www.researchgate.net/publication/247487210_Sensation_and_Perception",
            "https://www.researchgate.net/publication/239059434_The_Hungarian_Method_for_the_Assignment_Problem",
            "https://www.researchgate.net/publication/232472619_Neocognitron_A_Self-Organizing_Neural_Network_Model_for_a_Mechanism_of_Visual_Pattern_Recognition"
        ]
    },
    "paper318": {
        "id": "311610893",
        "title": "Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation",
        "abstract": "",
        "date": "2016",
        "authers": [
            "Guosheng Lin",
            "Chunhua Shen",
            "Anton van den Hengel",
            "Ian Reid"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network",
            "https://www.researchgate.net/publication/273388101_Fully_Connected_Deep_Structured_Networks",
            "https://www.researchgate.net/publication/272845187_Learning_Depth_from_Single_Monocular_Images_Using_Deep_Convolutional_Neural_Fields",
            "https://www.researchgate.net/publication/272194536_Conditional_Random_Fields_as_Recurrent_Neural_Networks",
            "https://www.researchgate.net/publication/270454670_Image_Super-Resolution_Using_Deep_Convolutional_Networks",
            "https://www.researchgate.net/publication/269116202_Feedforward_semantic_segmentation_with_zoom-out_features",
            "https://www.researchgate.net/publication/268747978_Deep_Convolutional_Neural_Fields_for_Depth_Estimation_from_a_Single_Image",
            "https://www.researchgate.net/publication/268689640_Hypercolumns_for_Object_Segmentation_and_Fine-grained_Localization",
            "https://www.researchgate.net/publication/264975444_The_Role_of_Context_for_Object_Detection_and_Semantic_Segmentation_in_the_Wild",
            "https://www.researchgate.net/publication/264160686_Learning_Rich_Features_from_RGB-D_Images_for_Object_Detection_and_Segmentation"
        ]
    },
    "paper319": {
        "id": "311610196",
        "title": "Semantic Instance Annotation of Street Scenes by 3D to 2D Label Transfer",
        "abstract": "",
        "date": "2016",
        "authers": [
            "Jun Xie",
            "Martin Kiefel",
            "Ming-Ting Sun",
            "Andreas Geiger"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding",
            "https://www.researchgate.net/publication/294282434_Learning_Where_to_Classify_in_Multi-view_Semantic_Segmentation",
            "https://www.researchgate.net/publication/282187243_A_Multi-modal_Graphical_Model_for_Scene_Analysis",
            "https://www.researchgate.net/publication/279501215_3D_All_The_Way_Semantic_Segmentation_of_Urban_Scenes_From_Start_to_End_in_3D",
            "https://www.researchgate.net/publication/272422948_segDeepM_Exploiting_Segmentation_and_Context_in_Deep_Neural_Networks_for_Object_Detection",
            "https://www.researchgate.net/publication/271551255_SUN3D_A_Database_of_Big_Spaces_Reconstructed_Using_SfM_and_Object_Labels",
            "https://www.researchgate.net/publication/269935290_Object_detectors_emerge_in_Deep_Scene_CNNs",
            "https://www.researchgate.net/publication/269332657_Human_Pose_Estimation_with_Fields_of_Parts",
            "https://www.researchgate.net/publication/265878275_MoT_-Mixture_of_Trees_Probabilistic_Graphical_Model_for_Video_Segmentation",
            "https://www.researchgate.net/publication/264975660_Beat_the_MTurkers_Automatic_Image_Labeling_from_Weak_3D_Supervision"
        ]
    },
    "paper320": {
        "id": "308862494",
        "title": "Learning to segment under various forms of weak supervision",
        "abstract": "",
        "date": "2015",
        "authers": [
            "Jia Xu",
            "Alexander G. Schwing",
            "Raquel Urtasun"
        ],
        "refrences": [
            "https://www.researchgate.net/publication/273388101_Fully_Connected_Deep_Structured_Networks",
            "https://www.researchgate.net/publication/264975660_Beat_the_MTurkers_Automatic_Image_Labeling_from_Weak_3D_Supervision",
            "https://www.researchgate.net/publication/261336412_Multi-Class_Cosegmentation",
            "https://www.researchgate.net/publication/261116324_Describing_the_Scene_as_a_Whole_Joint_Object_Detection_Scene_Classification_and_Semantic_Segmentation",
            "https://www.researchgate.net/publication/235661797_Weakly_Supervised_Structured_Output_Learning_for_Semantic_Segmentation",
            "https://www.researchgate.net/publication/228095638_Efficient_Structured_Prediction_with_Latent_Variables_for_GeneralGraphical_Models",
            "https://www.researchgate.net/publication/221663066_Scene_Parsing_with_Multiscale_Feature_Learning_Purity_Trees_andOptimal_Covers",
            "https://www.researchgate.net/publication/221363954_Geodesic_Star_Convexity_for_Interactive_Image_Segmentation",
            "https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database",
            "https://www.researchgate.net/publication/221346088_Efficient_multiclass_maximum_margin_clustering"
        ]
    }
}
