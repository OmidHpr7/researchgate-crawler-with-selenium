{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pip install webdriver-manager==3.5.2\n",
    "!pip install -q pip install beautifulsoup4==4.10.0\n",
    "!pip install -q pip install selenium==3.141.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 97.0.4692\n",
      "Get LATEST chromedriver version for 97.0.4692 google-chrome\n",
      "Driver [C:\\Users\\Bassir\\.wdm\\drivers\\chromedriver\\win32\\97.0.4692.71\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4  import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.researchgate.net/publication/328230984_BERT_Pre-training_of_Deep_Bidirectional_Transformers_for_Language_Understanding'\n",
    "driver.get(url)\n",
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get ID and Title of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'328230984_BERT_Pre-training_of_Deep_Bidirectional_Transformers_for_Language_Understanding'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = url.split('/')\n",
    "id_name = temp[len(temp)-1]\n",
    "id_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id of paper is:  328230984\n",
      "id of paper is:  BERT Pre-training of Deep Bidirectional Transformers for Language Understanding\n"
     ]
    }
   ],
   "source": [
    "id = id_name.split('_')[0]\n",
    "print('id of paper is: ', id)\n",
    "\n",
    "name_part = id_name.split('_')[1:len(id_name.split('_'))]\n",
    "name = ' '.join(name_part)\n",
    "print('id of paper is: ', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Abstract of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract is: \n",
      " We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.\n"
     ]
    }
   ],
   "source": [
    "abstract_tag = soup.find('div' , attrs={'class':'nova-legacy-e-text nova-legacy-e-text--size-m nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-grey-800 research-detail-middle-section__abstract'})\n",
    "abstract = abstract_tag.getText()\n",
    "\n",
    "print('Abstract is: \\n' , abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Accept year of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept year is:  October 2018\n"
     ]
    }
   ],
   "source": [
    "ac_year = soup.find('div', attrs = {'class':'nova-legacy-e-text'}) \n",
    "year = ac_year.getText()\n",
    "\n",
    "print('Accept year is: ' , year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Authers of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jacob Devlin', 'Ming-Wei Chang', 'Kenton Lee', 'Kristina Toutanova']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = soup.findAll('div', attrs={'class':'nova-legacy-l-flex__item research-detail-author-list__item research-detail-author-list__item--has-image'})\n",
    "all_auther = []\n",
    "for line in main:\n",
    "    temp = line.find('a', attrs={'class':'nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-bare'})\n",
    "    all_auther.append(temp.getText())\n",
    "    \n",
    "all_auther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get References URL of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References URL is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.researchgate.net/publication/334116365_Universal_Language_Model_Fine-tuning_for_Text_Classification',\n",
       " 'https://www.researchgate.net/publication/304506026_Bridging_Nonlinearities_and_Stochastic_Regularizers_with_Gaussian_Error_Linear_Units',\n",
       " 'https://www.researchgate.net/publication/304018244_SQuAD_100000_Questions_for_Machine_Comprehension_of_Text',\n",
       " 'https://www.researchgate.net/publication/284576917_Glove_Global_Vectors_for_Word_Representation',\n",
       " 'https://www.researchgate.net/publication/279068396_Skip-Thought_Vectors',\n",
       " 'https://www.researchgate.net/publication/268079628_How_transferable_are_features_in_deep_neural_networks',\n",
       " 'https://www.researchgate.net/publication/259239818_One_Billion_Word_Benchmark_for_Measuring_Progress_in_Statistical_Language_Modeling',\n",
       " 'https://www.researchgate.net/publication/257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality',\n",
       " 'https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database',\n",
       " 'https://www.researchgate.net/publication/221346269_Extracting_and_composing_robust_features_with_denoising_autoencoders',\n",
       " 'https://www.researchgate.net/publication/220873681_Word_Representations_A_Simple_and_General_Method_for_Semi-Supervised_Learning',\n",
       " 'https://www.researchgate.net/publication/220355244_Class-Based_n-gram_Models_of_Natural_Language',\n",
       " 'https://www.researchgate.net/publication/335685749_Character-Level_Language_Modeling_with_Deeper_Self-Attention',\n",
       " 'https://www.researchgate.net/publication/334115545_SWAG_A_Large-Scale_Adversarial_Dataset_for_Grounded_Commonsense_Inference',\n",
       " 'https://www.researchgate.net/publication/334115222_Semi-Supervised_Sequence_Modeling_with_Cross-View_Training',\n",
       " 'https://www.researchgate.net/publication/325445489_Deep_Contextualized_Word_Representations',\n",
       " 'https://www.researchgate.net/publication/322590138_Supervised_Learning_of_Universal_Sentence_Representations_from_Natural_Language_Inference_Data',\n",
       " 'https://www.researchgate.net/publication/318849650_Learned_in_Translation_Contextualized_Word_Vectors',\n",
       " 'https://www.researchgate.net/publication/318741130_Semi-supervised_sequence_tagging_with_bidirectional_language_models',\n",
       " 'https://www.researchgate.net/publication/317558625_Attention_Is_All_You_Need',\n",
       " 'https://www.researchgate.net/publication/316859263_TriviaQA_A_Large_Scale_Distantly_Supervised_Challenge_Dataset_for_Reading_Comprehension',\n",
       " 'https://www.researchgate.net/publication/316235248_A_Broad-Coverage_Challenge_Corpus_for_Sentence_Understanding_through_Inference',\n",
       " 'https://www.researchgate.net/publication/283531914_Semi-supervised_Sequence_Learning',\n",
       " 'https://www.researchgate.net/publication/281227635_A_large_annotated_corpus_for_learning_natural_language_inference',\n",
       " 'https://www.researchgate.net/publication/232539913_Cloze_Procedure_A_New_Tool_For_Measuring_Readability',\n",
       " 'https://www.researchgate.net/publication/221345848_A_unified_architecture_for_natural_language_processing_Deep_neural_networks_with_multitask_learning',\n",
       " 'https://www.researchgate.net/publication/221251113_The_Winograd_Schema_Challenge',\n",
       " 'https://www.researchgate.net/publication/221012895_Domain_Adaptation_with_Structural_Correspondence_Learning',\n",
       " 'https://www.researchgate.net/publication/220319924_A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = soup.find('div', attrs={'class': 'js-target-reference'})\n",
    "my_div_ref = main.findAll('div' , attrs={'class': 'nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-e-text--clamp-2 nova-legacy-v-publication-item__title'})\n",
    "allref = []\n",
    "for line in my_div_ref:\n",
    "    try:\n",
    "        allref.append('https://www.researchgate.net/' + line.a['href'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "print('References URL is:')\n",
    "allref"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
