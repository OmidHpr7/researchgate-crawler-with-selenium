{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pip install webdriver-manager==3.5.2\n",
    "!pip install -q pip install beautifulsoup4==4.10.0\n",
    "!pip install -q pip install selenium==3.141.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 97.0.4692\n",
      "Get LATEST chromedriver version for 97.0.4692 google-chrome\n",
      "Driver [C:\\Users\\Bassir\\.wdm\\drivers\\chromedriver\\win32\\97.0.4692.71\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4  import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.researchgate.net/publication/335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation'\n",
    "driver.get(url)\n",
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get ID and Title of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'335463644_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = url.split('/')\n",
    "id_name = temp[len(temp)-1]\n",
    "id_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id of paper is:  335463644\n",
      "name of paper is:  Boundary-Aware Feature Propagation for Scene Segmentation\n"
     ]
    }
   ],
   "source": [
    "id = id_name.split('_')[0]\n",
    "print('id of paper is: ', id)\n",
    "\n",
    "name_part = id_name.split('_')[1:len(id_name.split('_'))]\n",
    "name = ' '.join(name_part)\n",
    "print('name of paper is: ', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Abstract of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract is: \n",
      " In this work, we address the challenging issue of scene segmentation. To increase the feature similarity of the same object while keeping the feature discrimination of different objects, we explore to propagate information throughout the image under the control of objects' boundaries. To this end, we first propose to learn the boundary as an additional semantic class to enable the network to be aware of the boundary layout. Then, we propose unidirectional acyclic graphs (UAGs) to model the function of undirected cyclic graphs (UCGs), which structurize the image via building graphic pixel-by-pixel connections, in an efficient and effective way. Furthermore, we propose a boundary-aware feature propagation (BFP) module to harvest and propagate the local features within their regions isolated by the learned boundaries in the UAG-structured image. The proposed BFP is capable of splitting the feature propagation into a set of semantic groups via building strong connections among the same segment region but weak connections between different segment regions. Without bells and whistles, our approach achieves new state-of-the-art segmentation performance on three challenging semantic segmentation datasets, i.e., PASCAL-Context, CamVid, and Cityscapes.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    abstract_tag = soup.find('div' , attrs={'class':'nova-legacy-e-text nova-legacy-e-text--size-m nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-grey-800 research-detail-middle-section__abstract'})\n",
    "    abstract = abstract_tag.getText()\n",
    "\n",
    "    print('Abstract is: \\n' , abstract)\n",
    "except:\n",
    "    print('This Paper dosent have abstract...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Accept year of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept year is:  October 2019\n"
     ]
    }
   ],
   "source": [
    "ac_year = soup.find('div', attrs = {'class':'nova-legacy-e-text'}) \n",
    "year = ac_year.getText()\n",
    "\n",
    "print('Accept year is: ' , year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Authers of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Henghui Ding', 'Xudong Jiang', 'Ai Qun Liu', 'Nadia Magnenat Thalmann']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = soup.findAll('div', attrs={'class':'nova-legacy-l-flex__item research-detail-author-list__item research-detail-author-list__item--has-image'})\n",
    "all_auther = []\n",
    "for line in main:\n",
    "    temp = line.find('a', attrs={'class':'nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-bare'})\n",
    "    all_auther.append(temp.getText())\n",
    "    \n",
    "all_auther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get References URL of Paper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top References URL is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.researchgate.net/publication/335463411_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation',\n",
       " 'https://www.researchgate.net/publication/339558864_Dynamic_Multi-Scale_Filters_for_Semantic_Segmentation',\n",
       " 'https://www.researchgate.net/publication/339558490_Unpaired_Image_Captioning_via_Scene_Graph_Alignments',\n",
       " 'https://www.researchgate.net/publication/339556516_Joint_Learning_of_Saliency_Detection_and_Weakly_Supervised_Semantic_Segmentation',\n",
       " 'https://www.researchgate.net/publication/339555830_Deep_Learning_for_Light_Field_Saliency_Detection',\n",
       " 'https://www.researchgate.net/publication/339555410_Adaptive_Context_Network_for_Scene_Parsing',\n",
       " 'https://www.researchgate.net/publication/339554650_Fast_Video_Object_Segmentation_via_Dynamic_Targeting_Network',\n",
       " 'https://www.researchgate.net/publication/338512016_Dual_Attention_Network_for_Scene_Segmentation',\n",
       " 'https://www.researchgate.net/publication/338509793_Scene_Graph_Generation_With_External_Knowledge_and_Image_Reconstruction',\n",
       " 'https://www.researchgate.net/publication/338506535_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    main = soup.find('div', attrs={'class': 'js-target-reference'})\n",
    "    my_div_ref = main.findAll('div' , attrs={'class': 'nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-e-text--clamp-2 nova-legacy-v-publication-item__title'})\n",
    "    allref = []\n",
    "    for line in my_div_ref:\n",
    "        try:\n",
    "            allref.append('https://www.researchgate.net/' + line.a['href'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "    print('Top References URL is:')\n",
    "    print(allref)\n",
    "except:\n",
    "    print('This Paper dosent have References...')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
